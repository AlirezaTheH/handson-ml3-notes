{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 11 \u2013 Training Deep Neural Networks\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/alirezatheh/handson-ml3-notes/blob/main/notebooks/11_training_deep_neural_networks.ipynb)\n",
    "[![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/alirezatheh/handson-ml3-notes/blob/main/notebooks/11_training_deep_neural_networks.ipynb)\n",
    "\n",
    "Problems of training deep neural networks:\n",
    "- We may be faced with the problem of gradients growing ever smaller or larger, when flowing backward through the DNN during training. Both of these problems make lower layers very hard to train.\n",
    "- We might not have enough training data for such a large network, or it might be too costly to label.\n",
    "- Training may be extremely slow.\n",
    "- A model with millions of parameters would severely risk overfitting the training set, especially if there are not enough training instances or if they are too noisy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanishing/Exploding Gradients Problem\n",
    "- Gradients often get smaller and smaller as the backpropagation progresses down to the lower layers. As a result, the gradient descent update leaves the lower layers\u2019 connection weights virtually unchanged, and training never converges to a good solution. This is called the *vanishing gradients* problem.\n",
    "- In some cases, the gradients can grow bigger and bigger until layers get insanely large weight updates and the algorithm diverges. This is the *exploding gradients* problem, which happens most often in recurrent neural networks. \n",
    "\n",
    "More generally, deep neural networks suffer from unstable gradients; different layers may learn at widely different speeds.\n",
    "\n",
    "It wasn\u2019t clear what caused the gradients to be so unstable until in a 2010 paper [\u201cUnderstanding the Difficulty of Training Deep Feedforward Neural Networks\u201d](https://homl.info/47), Xavier Glorot and Yoshua Bengio showed that with popular sigmoid activation function and the normal weight initialization (mean of 0 and a standard deviation of 1), the variance of the outputs of each layer is much greater than the variance of its inputs. Going forward in the network, the variance keeps increasing after each layer until the activation function saturates at the top layers. This saturation is actually made worse by the fact that the sigmoid function has a mean of 0.5, not 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glorot and He Initialization\n",
    "Glorot and Bengio point out that we need the signal to flow properly in both directions. They argue that we need the variance of the outputs of each layer to be equal to the variance of its inputs, and we need the gradients to have equal variance before and after flowing through a layer in the reverse direction. It is actually not possible to guarantee both unless the layer has an equal number of inputs and outputs (*fan_in* and *fan_out*), but they proposed a good compromise that work well in practice: the connection weights of each layer must be initialized randomly as described in the following equation. This initialization strategy is called *Xavier initialization* or *Glorot initialization*.\n",
    "\n",
    "**Equation 11-1** Glorot initialization (when using the sigmoid activation function)\n",
    "$$\n",
    "\\begin{split}\n",
    "&\\text{Normal distribution with mean 0 and variance}\\;\n",
    "\\sigma^2=\\frac{1}{fan_\\text{avg}}\n",
    "\\\\&\\text{Or a uniform distribution between $\u2212r$ and $+r$, with}\\;\n",
    "r=\\sqrt{\\frac{3}{fan_\\text{avg}}}\n",
    "\\end{split}\n",
    "$$\n",
    "- $fan_\\text{avg}=(fan_\\text{in}+fan_\\text{out})/2$\n",
    "\n",
    "If we replace $fan_\\text{avg}$ with $fan_\\text{in}$, we get an initialization strategy that Yann LeCun proposed in the 1990s. He called it *LeCun initialization*. In an 2015 paper, [\u201cDelving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\u201d](https://homl.info/48) Kaiming He et al. provided a similar strategy.\n",
    "\n",
    "| Initialization | Activation functions                     |  $\\sigma^2$ (Normal) |\n",
    "|----------------|------------------------------------------|----------------------|\n",
    "| Glorot         | None, tanh, sigmoid, softmax             | $1/fan_\\text{avg}$   |\n",
    "| He             | ReLU, Leaky ReLU, ELU, GELU, Swish, Mish | $2/fan_\\text{in}$    |\n",
    "| LeCun          | SELU                                     | $1/fan_\\text{in}$    |\n",
    "\n",
    "By default, Keras uses Glorot initialization with a uniform distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "dense = keras.layers.Dense(\n",
    "    50, activation='relu', kernel_initializer='he_normal'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "He initialization with a uniform distribution and based on $fan_\\text{avg}$ \n",
    "(rather than $fan_\\text{in}$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_avg_init = keras.initializers.VarianceScaling(\n",
    "    scale=2.0, mode='fan_avg', distribution='uniform'\n",
    ")\n",
    "dense = keras.layers.Dense(\n",
    "    50, activation='sigmoid', kernel_initializer=he_avg_init\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better Activation Functions\n",
    "After the 2010 paper It turns out that other activation functions behave much better in deep neural networks. In particular, the ReLU activation function, mostly because it does not saturate for positive values, and also because it is very fast to compute.\n",
    "\n",
    "But even ReLU suffers from a problem known as the *dying ReLUs*: during training, some neurons effectively \u201cdie\u201d, meaning they stop outputting anything other than 0. In some cases, we may find that half of our network\u2019s neurons are dead, especially if we used a large learning rate. A neuron dies when its weights get tweaked in such a way that the input of the ReLU function is negative for all instances in the training set. To solve this problem, we may want to use a variant of the ReLU function.\n",
    "\n",
    "#### Leaky ReLU\n",
    "The leaky ReLU activation function is defined as $\\text{LeakyReLU}_\\alpha(z)=max(\\alpha z,z)$. The hyperparameter $\\alpha$ defines how much the function \u201cleaks\u201d: it is the slope of the function for $z<0$. Having a slope for $z<0$ ensures that leaky ReLUs never die.\n",
    "\n",
    "<center>\n",
    "  <img \n",
    "    src=\"../images/11/leaky_relu.png\" \n",
    "    onerror=\"\n",
    "      this.onerror = null;\n",
    "      const repo = 'https://github.com/alirezatheh/handson-ml3-notes/blob/main';\n",
    "      this.src = repo + this.src.split('..')[1];\n",
    "    \"\n",
    "  >\n",
    "</center>\n",
    "\n",
    "There is also *randomized leaky ReLU* (RReLU), where $\\alpha$ is picked randomly in a given range during training and is fixed to an average value during testing. It acts as a regularizer.\n",
    "\n",
    "There is also *parametric leaky ReLU* (PReLU), where $\\alpha$ is being learned during training. It strongly outperform ReLU on large image datasets, but on smaller datasets it runs the risk of overfitting the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defaults to alpha=0.3\n",
    "leaky_relu = keras.layers.LeakyReLU(alpha=0.2)\n",
    "dense = keras.layers.Dense(\n",
    "    50, activation=leaky_relu, kernel_initializer='he_normal'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-16 11:22:41.636848: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential(\n",
    "    [\n",
    "        # [...]  # more layers\n",
    "        # No activation\n",
    "        keras.layers.Dense(50, kernel_initializer='he_normal'),\n",
    "        # Activation as a separate layer\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        # [...]  # more layers\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For PReLU, replace `LeakyReLU` with `PReLU`.\n",
    "\n",
    "ReLU, leaky ReLU, and PReLU all suffer from the fact that they are not smooth functions: their derivatives abruptly change (at $z=0$). This sort of discontinuity can make gradient descent bounce around the optimum, and slow down convergence.\n",
    "\n",
    "#### ELU and SELU\n",
    "In 2015, a paper [\u201cFast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\u201d](https://homl.info/50) by Djork-Arn\u00e9 Clevert et al. proposed a new activation function, called the *exponential linear unit* (ELU), that outperformed all the ReLU variants in the authors\u2019 experiments.\n",
    "\n",
    "**Equation 11-2** ELU activation function\n",
    "$$\n",
    "\\text{ELU}_\\alpha(z)=\\begin{cases}\n",
    "\\alpha(\\exp(z)\u22121)&\\text{if}\\;z<0\n",
    "\\\\z&\\text{if}\\;z\\geq0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Differences with ReLU:\n",
    "- It takes on negative values when $z<0$, which allows the unit to have an average output closer to 0 and helps alleviate the vanishing gradients problem. The hyperparameter $\\alpha$ defines the opposite of the value that the ELU function approaches when $z$ is a large negative number. It is usually set to 1, but we can tweak it like any other hyperparameter.\n",
    "- It has a nonzero gradient for $z<0$, which avoids the dead neurons problem.\n",
    "- If $\\alpha$ is equal to 1 then the function is smooth everywhere, including around $z=0$, which helps speed up gradient descent since it does not bounce as much to the left and right of $z=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = keras.layers.Dense(\n",
    "    50, activation='elu', kernel_initializer='he_normal'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a 2017 paper [\u201cSelf-Normalizing Neural Networks\u201d](https://homl.info/selu), G\u00fcnter Klambauer et al. introduced the *scaled ELU* (SELU) activation function: it is a scaled variant of the ELU activation function (about 1.05 times ELU, using $\\alpha\\approx1.67$). They showed that if we build a neural network composed exclusively of a stack of dense layers (i.e., an MLP), and if all hidden layers use the SELU activation function, then the network will *self-normalize*: the output of each layer will tend to preserve a mean of 0 and a standard deviation of 1 during training, which solves the vanishing/exploding gradients problem.\n",
    "\n",
    "<center>\n",
    "  <img \n",
    "    src=\"../images/11/elu_and_selu.png\" \n",
    "    onerror=\"\n",
    "      this.onerror = null;\n",
    "      const repo = 'https://github.com/alirezatheh/handson-ml3-notes/blob/main';\n",
    "      this.src = repo + this.src.split('..')[1];\n",
    "    \"\n",
    "  >\n",
    "</center>\n",
    "\n",
    "By default, the SELU hyperparameters (`scale` and `alpha`) are tuned in such a way that the mean output of each neuron remains close to 0, and the standard deviation remains close to 1 if these constraints are respected:\n",
    "- The input features must be standardized: mean 0 and standard deviation 1.\n",
    "- Every hidden layer\u2019s weights must be initialized using LeCun normal initialization.\n",
    "- plain MLPs.\n",
    "- No regularization techniques like $\\ell_1$ or $\\ell_2$ regularization, max-norm, batch-norm, or regular dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = keras.layers.Dense(\n",
    "    50, activation='selu', kernel_initializer='lecun_normal'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GELU, Swish and Mish\n",
    "GELU was introduced in a 2016 paper [\u201cGaussian Error Linear Units (GELUs)\u201d](https://homl.info/gelu) by Dan Hendrycks and Kevin Gimpel.\n",
    "\n",
    "**Equation 11-3** GELU activation function\n",
    "$$\n",
    "\\text{GELU}(z)=z\\Phi(z)\n",
    "$$\n",
    "\n",
    "- $\\Phi$: Standard Gaussian cumulative distribution function (CDF)\n",
    "- $\\Phi(z)$: The probability that a value sampled randomly from a normal distribution of mean 0 and variance 1 is lower than $z$.\n",
    "\n",
    "In practice, it often outperforms every other activation function discussed so far. However, it is a bit more computationally intensive, and the performance boost it provides is not always sufficient to justify the extra cost. That said, it is possible to show that it is approximately equal to $z\\sigma(1.702z)$: using this approximation also works very well, and it has the advantage of being much faster to compute.\n",
    "\n",
    "<center>\n",
    "  <img \n",
    "    src=\"../images/11/gelu_swish_mish.png\" \n",
    "    onerror=\"\n",
    "      this.onerror = null;\n",
    "      const repo = 'https://github.com/alirezatheh/handson-ml3-notes/blob/main';\n",
    "      this.src = repo + this.src.split('..')[1];\n",
    "    \"\n",
    "  >\n",
    "</center>\n",
    "\n",
    "The GELU paper also introduced *sigmoid linear unit* (SiLU) which is equal to $\\text{SiLU}(z)=z\\sigma(z)$.\n",
    "\n",
    "A 2017 paper [\u201cSearching for Activation Functions\u201d](https://homl.info/swish) by Prajit Ramachandran et al. rediscovered the SiLU by automatically searching for good activation functions. The authors named it *Swish*, and the name caught on. In their paper, Swish outperformed every other function, including GELU. They later generalized Swish by adding an extra hyperparameter $\\beta$ to scale the sigmoid function\u2019s input which is equal to $\\text{Swish}_\\beta(z)=z\\sigma(\\beta z)$. We can tune $\\beta$ or make it trainable.\n",
    "\n",
    "In a 2019 paper [\u201cMish: A Self Regularized Non-Monotonic Activation Function\u201d](https://homl.info/mish) Diganta Misra introduced *Mish*. It is defined as $\\text{mish(z)}=z\\tanh(\\text{softplus}(z))$ where $\\text{softplus}(z)=\\log(1+\\exp(z))$.\n",
    "\n",
    "**Tip**: Which one to use?\n",
    "- ReLU is a good default for simple tasks:\n",
    "  - It\u2019s often just as good as the more sophisticated activation functions.\n",
    "  - It\u2019s very fast to compute.\n",
    "  - Many libraries and hardware accelerators provide ReLU-specific optimizations.\n",
    "- Swish is probably a better default for more complex tasks.\n",
    "- Parametrized Swish with a learnable $\\beta$ for the most complex tasks\n",
    "- Mish may give us slightly better results, but it requires a bit more compute.\n",
    "- If we care a lot about runtime latency:\n",
    "  - leaky ReLU\n",
    "  - Parametrized leaky ReLU for more complex tasks\n",
    "- For deep MLPs, give SELU a try.\n",
    "\n",
    "Keras supports GELU and Swish out of the box; just use `activation='gelu'` or `activation='swish'`. However, it does not support Mish or the generalized Swish activation function yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization\n",
    "Although using He initialization along with ReLU (or any of its variants) can significantly reduce the danger of the vanishing/exploding gradients problems at the beginning of training, it doesn\u2019t guarantee that they won\u2019t come back during training.\n",
    "\n",
    "In a 2015 paper [\u201cBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\u201d](https://homl.info/51), Sergey Ioffe and Christian Szegedy proposed a technique called *batch normalization* (BN) that addresses these problems. We can do that just before or after the activation function of each hidden layer.\n",
    "\n",
    "The whole operation is summarized step by step in the following equation:\n",
    "\n",
    "**Eqautions 11-4** Batch normalization algorithm\n",
    "1. $\\;\\;\\;\\;\\;\\boldsymbol{\\mu}_B=\\dfrac{1}{m_B}\\displaystyle\\sum\\limits_{i=1}^{m_B}\\mathbf{x}^{(i)}$ \n",
    "<br/>\n",
    "\n",
    "2. $\\;\\;\\;\\;\\;{\\boldsymbol{\\sigma}_B}^2=\\dfrac{1}{m_B}\\displaystyle\\sum\\limits_{i=1}^{m_B}(\\mathbf{x}^{(i)}-\\boldsymbol{\\mu}_B)^2$\n",
    "<br/>\n",
    "\n",
    "3. $\\;\\;\\;\\;\\;\\widehat{\\mathbf{x}}^{(i)}=\\dfrac{\\mathbf{x}^{(i)}-\\boldsymbol{\\mu}_B}{\\sqrt{{\\boldsymbol{\\sigma}_B}^2+\\varepsilon}}$\n",
    "<br/>\n",
    "\n",
    "4. $\\;\\;\\;\\;\\;\\mathbf{z}^{(i)}=\\boldsymbol{\\gamma}\\otimes\\widehat{\\mathbf{x}}^{(i)}+\\boldsymbol{\\beta}$\n",
    "\n",
    "- $\\boldsymbol{\\mu}_B$: The vector of input means, evaluated over the whole mini-batch $B$ (one mean per input)\n",
    "- $m_B$: The number of instances in the mini-batch\n",
    "- $\\boldsymbol{\\sigma}_B$: The vector of input standard deviations\n",
    "- $\\widehat{\\mathbf{x}}^{(i)}$: the vector of zero-centered and normalized inputs for instance $i$\n",
    "- $\\varepsilon$: A tiny number that avoids division by zero and ensures the gradients don\u2019t grow too large (typically $10^{\u20135}$). This is called a *smoothing term*.\n",
    "- $\\boldsymbol{\\gamma}$: The output scale parameter vector for the layer\n",
    "- $\\boldsymbol{\\beta}$: The output shift (offset) parameter vector for the layer\n",
    "- $\\mathbf{z}^{(i)}$: The output of the BN operation\n",
    "\n",
    "So during training, BN standardizes its inputs, then rescales and offsets them. Good! What about at test time? we may need to make predictions for individual instances rather than for batches of instances: in this case, we will have no way to compute each input\u2019s mean and standard deviation. Moreover, even if we do have a batch of instances, it may be too small, or the instances may not be independent and identically distributed, so computing statistics over the batch instances would be unreliable. Solutions:\n",
    "- Wait until the end of training, then run the whole training set through the neural network and compute the mean and standard deviation of each input of the BN layer. These \u201cfinal\u201d input means and standard deviations could then be used instead of the batch input means and standard deviations when making predictions.\n",
    "- Estimate these final statistics during training by using a moving average of the layer\u2019s input means and standard deviations. This is what Keras does automatically when we use the `BatchNormalization` layer.\n",
    "\n",
    "Let\u2019s sum up, four parameter vectors are learned in each batch-normalized layer: $\\boldsymbol{\\gamma}$ and $\\boldsymbol{\\beta}$ are learned through regular backpropagation, and $\\boldsymbol{\\mu}$(the final input mean vector) and $\\boldsymbol{\\sigma}$(the final input standard deviation vector) are estimated using an exponential moving average.\n",
    "\n",
    "BN pros:\n",
    "- Solves vanishing\\exploiting gradients problem.\n",
    "- We can use saturating activation functions such as the tanh and even the sigmoid.\n",
    "- Networks are much less sensitive to the weight initialization.\n",
    "- We can use much larger learning rates, significantly speeding up the learning process.\n",
    "- Acts like a regularizer, reducing the need for other regularization techniques.\n",
    "\n",
    "BN adds some complexity to the model (although it can remove the need for  normalizing the input data).\n",
    "\n",
    "Also there is a runtime penalty: the neural network makes slower predictions due to the extra computations required at each layer. Solution: It\u2019s often possible to fuse the BN layer with the previous layer after training, thereby avoiding the runtime penalty. This is done by updating the previous layer\u2019s weights and biases so that it directly produces outputs of the appropriate scale and offset. e.g. if the previous layer computes $\\mathbf{X}\\mathbf{W}+\\mathbf{b}$ then the BN layer will compute $\\boldsymbol{\\gamma}\\otimes(\\mathbf{X}\\mathbf{W}+\\mathbf{b}-\\boldsymbol{\\mu})/\\boldsymbol{\\sigma}+\\boldsymbol{\\beta}$ (ignoring the smoothing term $\\varepsilon$ in the denominator). If we define $\\mathbf{W^\\prime}=\\boldsymbol{\\gamma}\\otimes\\mathbf{W}/\\boldsymbol{\\sigma}$ and $\\mathbf{b^\\prime}=\\boldsymbol{\\gamma}\\otimes(\\mathbf{b}\u2013\\boldsymbol{\\mu})/\\boldsymbol{\\sigma}+\\boldsymbol{\\beta}$, the equation simplifies to $\\mathbf{X}\\mathbf{W^\\prime}+\\mathbf{b^\\prime}$. So, if we replace the previous layer\u2019s weights and biases with the updated weights and biases, we can get rid of the BN layer (TFLite\u2019s converter does this automatically).\n",
    "\n",
    "**Note**: Each epoch takes much more time but convergence is much faster with  BN, because it will take fewer epochs to reach the same performance.\n",
    "\n",
    "#### Implementing batch normalization with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the name counters and set the random seed\n",
    "K = keras.backend\n",
    "K.clear_session()\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(\n",
    "            300, activation='relu', kernel_initializer='he_normal'\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(\n",
    "            100, activation='relu', kernel_initializer='he_normal'\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization/gamma:0', True),\n",
       " ('batch_normalization/beta:0', True),\n",
       " ('batch_normalization/moving_mean:0', False),\n",
       " ('batch_normalization/moving_variance:0', False)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5559 - accuracy: 0.8094 - val_loss: 0.4016 - val_accuracy: 0.8558\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.4083 - accuracy: 0.8561 - val_loss: 0.3676 - val_accuracy: 0.8650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5d11505b0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just show that the model works!\n",
    "fashion_mnist = keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]\n",
    "X_train, X_valid, X_test = X_train / 255, X_valid / 255, X_test / 255\n",
    "\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', optimizer='sgd', metrics='accuracy'\n",
    ")\n",
    "model.fit(X_train, y_train, epochs=2, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes applying BN before the activation function works better (there\u2018s a debate on this topic). Moreover, the layer before a `BatchNormalization` layer does not need to have bias terms, since the `BatchNormalization` layer some as well, it would be a waste of parameters, so we can set `use_bias=False` when creating those layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the name counters and set the random seed\n",
    "K.clear_session()\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.Dense(\n",
    "            300, kernel_initializer='he_normal', use_bias=False\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Activation('relu'),\n",
    "        keras.layers.Dense(\n",
    "            100, kernel_initializer='he_normal', use_bias=False\n",
    "        ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Activation('relu'),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.6063 - accuracy: 0.7993 - val_loss: 0.4296 - val_accuracy: 0.8418\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4275 - accuracy: 0.8500 - val_loss: 0.3752 - val_accuracy: 0.8646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5fdd309d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just show that the model works!\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy', optimizer='sgd', metrics='accuracy'\n",
    ")\n",
    "model.fit(X_train, y_train, epochs=2, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BN Hyperparameters:\n",
    "- `momentum`: This hyperparameter is used by the BN layer when it updates the exponential moving averages; given a new value. A good momentum value is typically close to 1; e.g. 0.9, 0.99, or 0.999. We want more 9s for larger datasets and for smaller mini-batches.\n",
    "- `axis`: It determines which axis should be normalized. It defaults to \u20131, meaning that by default it will normalize the last axis (using the means and standard deviations computed across the *other* axes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Clipping\n",
    "Another technique to mitigate the exploding gradients problem is to clip the gradients during backpropagation so that they never exceed some threshold. This is called *gradient clipping* by Razvan Pascanu et al. in a 2013 paper [\u201cOn the Difficulty of Training Recurrent Neural Networks\u201d](https://homl.info/52).\n",
    "\n",
    "All `keras.optimizers` accept `clipnorm` or `clipvalue` arguments:\n",
    "- This optimizer will clip every component of the gradient vector to a value between \u20131.0 and 1.0. It may change the orientation of the gradient vector. `[0.9, 100.0]` -> `[0.9, 1.0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- If we want to ensure that gradient clipping does not change the direction of\n",
    "  the gradient vector, we can use `clipnorm`. This will clip the whole gradient\n",
    "  if its $\\ell_2$ norm is greater than the threshold we picked. `[0.9, 100.0]`\n",
    "  -> `[0.00899964, 0.9999595]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipnorm=1.0)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: We can track the size of the gradients using TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Layers\n",
    "If we can find an existing neural network that accomplishes a similar task to the one we are trying to tackle, then we can generally reuse most of its layers, except for the top ones. This technique is called *transfer learning*. It will not only speed up training considerably, but also requires significantly less training data.\n",
    "\n",
    "**Note**: If the input pictures for our new task don\u2019t have the same size as the ones used in the original task, we will usually have to add a preprocessing step to resize them to the size expected by the original model.\n",
    "\n",
    "Some guidelines:\n",
    "- The output layer of the original model should usually be replaced because it is most likely not useful at all for the new task, and probably will not have the right number of outputs.\n",
    "- The upper hidden layers of the original model are less likely to be as useful as the lower layers, since the high-level features that are most useful for the new task may differ significantly from the ones that were most useful for the original task. We want to find the right number of layers to reuse.\n",
    "- The more similar the tasks are, the more layers we will want to reuse (starting with the lower layers). For very similar tasks, try to keep all the hidden layers and just replace the output layer.\n",
    "\n",
    "Common approach:\n",
    "1. Try freezing all the reused layers first, then train our model and see how it performs.\n",
    "2. Then try unfreezing one or two of the top hidden layers to let backpropagation tweak them and see if performance improves. The more training data we have, the more layers we can unfreeze. It is also useful to reduce the learning rate when we unfreeze reused layers: this will avoid wrecking their fine-tuned weights.\n",
    "4. If we still cannot get good performance, and we have little training data, try dropping the top hidden layer(s) and freezing all the remaining hidden layers again.\n",
    "5. We can iterate until we find the right number of layers to reuse.\n",
    "6. If we have plenty of training data, we may try replacing the top hidden layers instead of dropping them, and even adding more hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning with Keras\n",
    "Let\u2019s split the Fashion MNIST training set in two:\n",
    "- `X_train_A`: All images of all items except for T-shirts/tops and pullovers (classes 0 and 2).\n",
    "- `X_train_B`: A much smaller training set of just the first 200 images of T-shirts/tops and pullovers.\n",
    "\n",
    "The validation set and the test set are also split this way, but without restricting the number of images.\n",
    "\n",
    "We will train a model on set A (classification task with 8 classes), and try to reuse it to tackle set B (binary classification). We hope to transfer a little bit of knowledge from task A to task B, since classes in set A (trousers, dresses, coats, sandals, shirts, sneakers, bags, and ankle boots) are somewhat similar to classes in set B (T-shirts/tops and pullovers). However, since we are using `Dense` layers, only patterns that occur at the same location can be reused (in contrast, convolutional layers will transfer much better, since learned patterns can be detected anywhere on the image).\n",
    "\n",
    "Let\u2019s Split Fashion MNIST into tasks A and B, then train and save model A to `'my_model_A'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1376/1376 [==============================] - 1s 908us/step - loss: 1.1385 - accuracy: 0.6260 - val_loss: 0.7101 - val_accuracy: 0.7603\n",
      "Epoch 2/20\n",
      "1376/1376 [==============================] - 1s 869us/step - loss: 0.6221 - accuracy: 0.7911 - val_loss: 0.5293 - val_accuracy: 0.8315\n",
      "Epoch 3/20\n",
      "1376/1376 [==============================] - 1s 852us/step - loss: 0.5016 - accuracy: 0.8394 - val_loss: 0.4515 - val_accuracy: 0.8581\n",
      "Epoch 4/20\n",
      "1376/1376 [==============================] - 1s 852us/step - loss: 0.4381 - accuracy: 0.8583 - val_loss: 0.4055 - val_accuracy: 0.8669\n",
      "Epoch 5/20\n",
      "1376/1376 [==============================] - 1s 844us/step - loss: 0.3979 - accuracy: 0.8692 - val_loss: 0.3748 - val_accuracy: 0.8706\n",
      "Epoch 6/20\n",
      "1376/1376 [==============================] - 1s 882us/step - loss: 0.3693 - accuracy: 0.8782 - val_loss: 0.3538 - val_accuracy: 0.8787\n",
      "Epoch 7/20\n",
      "1376/1376 [==============================] - 1s 863us/step - loss: 0.3487 - accuracy: 0.8825 - val_loss: 0.3376 - val_accuracy: 0.8834\n",
      "Epoch 8/20\n",
      "1376/1376 [==============================] - 2s 1ms/step - loss: 0.3324 - accuracy: 0.8879 - val_loss: 0.3315 - val_accuracy: 0.8847\n",
      "Epoch 9/20\n",
      "1376/1376 [==============================] - 1s 1ms/step - loss: 0.3198 - accuracy: 0.8920 - val_loss: 0.3174 - val_accuracy: 0.8879\n",
      "Epoch 10/20\n",
      "1376/1376 [==============================] - 2s 1ms/step - loss: 0.3088 - accuracy: 0.8947 - val_loss: 0.3118 - val_accuracy: 0.8904\n",
      "Epoch 11/20\n",
      "1376/1376 [==============================] - 1s 1ms/step - loss: 0.2994 - accuracy: 0.8979 - val_loss: 0.3039 - val_accuracy: 0.8925\n",
      "Epoch 12/20\n",
      "1376/1376 [==============================] - 1s 837us/step - loss: 0.2918 - accuracy: 0.8999 - val_loss: 0.2998 - val_accuracy: 0.8952\n",
      "Epoch 13/20\n",
      "1376/1376 [==============================] - 1s 840us/step - loss: 0.2852 - accuracy: 0.9016 - val_loss: 0.2932 - val_accuracy: 0.8980\n",
      "Epoch 14/20\n",
      "1376/1376 [==============================] - 1s 799us/step - loss: 0.2788 - accuracy: 0.9034 - val_loss: 0.2865 - val_accuracy: 0.8990\n",
      "Epoch 15/20\n",
      "1376/1376 [==============================] - 1s 922us/step - loss: 0.2736 - accuracy: 0.9052 - val_loss: 0.2824 - val_accuracy: 0.9015\n",
      "Epoch 16/20\n",
      "1376/1376 [==============================] - 1s 835us/step - loss: 0.2686 - accuracy: 0.9068 - val_loss: 0.2796 - val_accuracy: 0.9015\n",
      "Epoch 17/20\n",
      "1376/1376 [==============================] - 1s 863us/step - loss: 0.2641 - accuracy: 0.9085 - val_loss: 0.2748 - val_accuracy: 0.9015\n",
      "Epoch 18/20\n",
      "1376/1376 [==============================] - 1s 913us/step - loss: 0.2596 - accuracy: 0.9101 - val_loss: 0.2729 - val_accuracy: 0.9037\n",
      "Epoch 19/20\n",
      "1376/1376 [==============================] - 1s 909us/step - loss: 0.2558 - accuracy: 0.9119 - val_loss: 0.2715 - val_accuracy: 0.9040\n",
      "Epoch 20/20\n",
      "1376/1376 [==============================] - 1s 859us/step - loss: 0.2520 - accuracy: 0.9125 - val_loss: 0.2728 - val_accuracy: 0.9027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 16:22:23.274500: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_A/assets\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "TensorLike = tf.types.experimental.TensorLike\n",
    "\n",
    "class_names = [\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle boot',\n",
    "]\n",
    "\n",
    "pos_class_id = class_names.index('Pullover')\n",
    "neg_class_id = class_names.index('T-shirt/top')\n",
    "\n",
    "\n",
    "def split_dataset(\n",
    "    X: TensorLike, y: TensorLike\n",
    ") -> tuple[tuple[TensorLike], ...]:\n",
    "    y_for_B = (y == pos_class_id) | (y == neg_class_id)\n",
    "    y_A = y[~y_for_B]\n",
    "    y_B = (y[y_for_B] == pos_class_id).astype(np.float32)\n",
    "    old_class_ids = list(set(range(10)) - {neg_class_id, pos_class_id})\n",
    "    for old_class_id, new_class_id in zip(old_class_ids, range(8)):\n",
    "        # Reorder class ids for A\n",
    "        y_A[y_A == old_class_id] = new_class_id\n",
    "    return (X[~y_for_B], y_A), (X[y_for_B], y_B)\n",
    "\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(\n",
    "    X_train, y_train\n",
    ")\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(\n",
    "    X_valid, y_valid\n",
    ")\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]\n",
    "\n",
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "model_A = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.Dense(\n",
    "            100, activation='relu', kernel_initializer='he_normal'\n",
    "        ),\n",
    "        keras.layers.Dense(\n",
    "            100, activation='relu', kernel_initializer='he_normal'\n",
    "        ),\n",
    "        keras.layers.Dense(\n",
    "            100, activation='relu', kernel_initializer='he_normal'\n",
    "        ),\n",
    "        keras.layers.Dense(8, activation='softmax'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_A.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "history = model_A.fit(\n",
    "    X_train_A, y_train_A, epochs=20, validation_data=(X_valid_A, y_valid_A)\n",
    ")\n",
    "model_A.save('my_model_A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let\u2019s Train and evaluate model B, without reusing model A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.7167 - accuracy: 0.5450 - val_loss: 0.7052 - val_accuracy: 0.5272\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6805 - accuracy: 0.5800 - val_loss: 0.6758 - val_accuracy: 0.6004\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6532 - accuracy: 0.6650 - val_loss: 0.6530 - val_accuracy: 0.6746\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6289 - accuracy: 0.7150 - val_loss: 0.6317 - val_accuracy: 0.7517\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6079 - accuracy: 0.7800 - val_loss: 0.6105 - val_accuracy: 0.8091\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5866 - accuracy: 0.8400 - val_loss: 0.5913 - val_accuracy: 0.8447\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5670 - accuracy: 0.8850 - val_loss: 0.5728 - val_accuracy: 0.8833\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5499 - accuracy: 0.8900 - val_loss: 0.5571 - val_accuracy: 0.8971\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5331 - accuracy: 0.9150 - val_loss: 0.5427 - val_accuracy: 0.9050\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5180 - accuracy: 0.9250 - val_loss: 0.5290 - val_accuracy: 0.9080\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.9350 - val_loss: 0.5160 - val_accuracy: 0.9189\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4903 - accuracy: 0.9350 - val_loss: 0.5032 - val_accuracy: 0.9228\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4770 - accuracy: 0.9400 - val_loss: 0.4925 - val_accuracy: 0.9228\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.9450 - val_loss: 0.4817 - val_accuracy: 0.9258\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4546 - accuracy: 0.9550 - val_loss: 0.4708 - val_accuracy: 0.9298\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.9550 - val_loss: 0.4608 - val_accuracy: 0.9318\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4330 - accuracy: 0.9600 - val_loss: 0.4510 - val_accuracy: 0.9337\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.9600 - val_loss: 0.4406 - val_accuracy: 0.9367\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4119 - accuracy: 0.9600 - val_loss: 0.4311 - val_accuracy: 0.9377\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4025 - accuracy: 0.9600 - val_loss: 0.4225 - val_accuracy: 0.9367\n",
      "63/63 [==============================] - 0s 728us/step - loss: 0.4317 - accuracy: 0.9185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.43168652057647705, 0.9185000061988831]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "model_B = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.Dense(\n",
    "            100, activation='relu', kernel_initializer='he_normal'\n",
    "        ),\n",
    "        keras.layers.Dense(\n",
    "            100, activation='relu', kernel_initializer='he_normal'\n",
    "        ),\n",
    "        keras.layers.Dense(\n",
    "            100, activation='relu', kernel_initializer='he_normal'\n",
    "        ),\n",
    "        keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_B.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "history = model_B.fit(\n",
    "    X_train_B, y_train_B, epochs=20, validation_data=(X_valid_B, y_valid_B)\n",
    ")\n",
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model B reaches 91.85% accuracy on the test set. Now let\u2019s try reusing the pretrained model A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model('my_model_A')\n",
    "model_B_on_A = keras.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `model_B_on_A` and `model_A` actually share layers now, so when we train one, it will update both models. If we want to avoid that, we need to build `model_B_on_A` on top of a *clone* of `model_A`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: `keras.models.clone_model()` only clones the architecture, not the weights. If we don\u2019t copy them manually using `set_weights()`, they will be initialized randomly when the cloned model is first used.\n",
    "\n",
    "Let\u2019s create `model_B_on_A` just like in the previous cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A = keras.Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(\n",
    "    loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: We must always compile our model after we freeze or unfreeze layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.7893 - accuracy: 0.5550 - val_loss: 1.3324 - val_accuracy: 0.5084\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.1235 - accuracy: 0.5350 - val_loss: 0.9199 - val_accuracy: 0.4807\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8836 - accuracy: 0.5000 - val_loss: 0.8266 - val_accuracy: 0.4837\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.8202 - accuracy: 0.5250 - val_loss: 0.7795 - val_accuracy: 0.4985\n",
      "Epoch 1/16\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.7348 - accuracy: 0.6050 - val_loss: 0.6372 - val_accuracy: 0.6914\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6055 - accuracy: 0.7600 - val_loss: 0.5283 - val_accuracy: 0.8229\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4992 - accuracy: 0.8400 - val_loss: 0.4742 - val_accuracy: 0.8180\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.8700 - val_loss: 0.4212 - val_accuracy: 0.8773\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3825 - accuracy: 0.9050 - val_loss: 0.3797 - val_accuracy: 0.9031\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3438 - accuracy: 0.9250 - val_loss: 0.3534 - val_accuracy: 0.9149\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3148 - accuracy: 0.9500 - val_loss: 0.3384 - val_accuracy: 0.9001\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3012 - accuracy: 0.9450 - val_loss: 0.3179 - val_accuracy: 0.9209\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2767 - accuracy: 0.9650 - val_loss: 0.3043 - val_accuracy: 0.9298\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2623 - accuracy: 0.9550 - val_loss: 0.2929 - val_accuracy: 0.9308\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2512 - accuracy: 0.9600 - val_loss: 0.2830 - val_accuracy: 0.9327\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2397 - accuracy: 0.9600 - val_loss: 0.2744 - val_accuracy: 0.9318\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2295 - accuracy: 0.9600 - val_loss: 0.2675 - val_accuracy: 0.9327\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2225 - accuracy: 0.9600 - val_loss: 0.2598 - val_accuracy: 0.9347\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2147 - accuracy: 0.9600 - val_loss: 0.2542 - val_accuracy: 0.9357\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2077 - accuracy: 0.9600 - val_loss: 0.2492 - val_accuracy: 0.9377\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(\n",
    "    X_train_B, y_train_B, epochs=4, validation_data=(X_valid_B, y_valid_B)\n",
    ")\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.001)\n",
    "model_B_on_A.compile(\n",
    "    loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']\n",
    ")\n",
    "history = model_B_on_A.fit(\n",
    "    X_train_B, y_train_B, epochs=16, validation_data=(X_valid_B, y_valid_B)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what\u2019s the final verdict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 667us/step - loss: 0.2546 - accuracy: 0.9385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2546142041683197, 0.9384999871253967]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We got a bit of transfer: the model\u2019s accuracy went up 2 percentage points, from 91.85% to 93.85%. This means the error rate dropped by almost 25%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24539877300613477"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (100 - 93.85) / (100 - 91.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we convinced? We shouldn\u2019t be: We cheated! What we did is called \u201ctorturing the data until it confesses\u201d. If we try to change the classes or the random seed, we will see that the improvement generally drops, or even vanishes or reverses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Unsupervised Pretraining\n",
    "Suppose we want to tackle a complex task for which we don\u2019t have much labeled training data, but also we cannot find a model trained on a similar task. It is often cheap to gather unlabeled training examples, but expensive to label them. If we can gather plenty of unlabeled training data, we can try to use it to train an unsupervised model, such as an autoencoder or a GAN. Then we can reuse the lower layers of the autoencoder or the lower layers of the GAN\u2019s discriminator, add the output layer for our task on top, and fine-tune the final network using supervised learning.\n",
    "\n",
    "It was this technique that Geoffrey Hinton and his team used in 2006 which led to the revival of neural networks and the success of deep learning.\n",
    "\n",
    "Until 2010, unsupervised pretraining (typically with restricted Boltzmann machines (RBMs)) was the norm for deep nets, and only after the vanishing gradients problem was alleviated did it become much more common to train DNNs purely using supervised learning.\n",
    "\n",
    "In the early days of deep learning it was difficult to train deep models, so people would use a technique called *greedy layer-wise pretraining*. They would first train an unsupervised model with a single layer, typically an RBM, then they would freeze that layer and add another one on top of it, then train the model again (effectively just training the new layer), then freeze the new layer and add another layer on top of it, train the model again, and so on.\n",
    "\n",
    "<center>\n",
    "  <img \n",
    "    src=\"../images/11/unsupervised_pretraining.png\" \n",
    "    onerror=\"\n",
    "      this.onerror = null;\n",
    "      const repo = 'https://github.com/alirezatheh/handson-ml3-notes/blob/main';\n",
    "      this.src = repo + this.src.split('..')[1];\n",
    "    \"\n",
    "  >\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraining on an Auxiliary Task\n",
    "If we do not have much labeled training data, one last option is to train a first neural network on an auxiliary task for which we can easily obtain or generate labeled training data, then reuse the lower layers of that network for our actual task. The first neural network\u2019s lower layers will learn feature detectors that will likely be reusable by the second neural network.\n",
    "\n",
    "For example:\n",
    "- To build a system to recognize faces, we may only have a few pictures of each individual. Gathering hundreds of pictures of each person would not be practical. We can gather a lot of pictures of random people on the web and train a first neural network to detect whether or not two different pictures feature the same person.\n",
    "- For NLP applications, we can download a corpus of millions of text documents and automatically generate labeled data from it. e.g. we could randomly mask out some words and train a model to predict what the missing words are.\n",
    "\n",
    "**Note**: *Self-supervised learning* is when we automatically generate the labels from the data itself, as in the text-masking example, then we train a model on the resulting \u201clabeled\u201d dataset using supervised learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster Optimizers\n",
    "Let\u2019s build a little function to test an optimizer on Fashion MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(seed: int = 42) -> keras.Model:\n",
    "    keras.utils.set_random_seed(seed)\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            keras.layers.Flatten(input_shape=[28, 28]),\n",
    "            keras.layers.Dense(\n",
    "                100, activation='relu', kernel_initializer='he_normal'\n",
    "            ),\n",
    "            keras.layers.Dense(\n",
    "                100, activation='relu', kernel_initializer='he_normal'\n",
    "            ),\n",
    "            keras.layers.Dense(\n",
    "                100, activation='relu', kernel_initializer='he_normal'\n",
    "            ),\n",
    "            keras.layers.Dense(10, activation='softmax'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def build_and_train_model(\n",
    "    optimizer: keras.optimizers.Optimizer,\n",
    ") -> keras.callbacks.History:\n",
    "    model = build_model()\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return model.fit(\n",
    "        X_train, y_train, epochs=10, validation_data=(X_valid, y_valid)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.6877 - accuracy: 0.7677 - val_loss: 0.4960 - val_accuracy: 0.8172\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 948us/step - loss: 0.4619 - accuracy: 0.8378 - val_loss: 0.4421 - val_accuracy: 0.8404\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 1s 868us/step - loss: 0.4179 - accuracy: 0.8525 - val_loss: 0.4188 - val_accuracy: 0.8538\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 1s 866us/step - loss: 0.3902 - accuracy: 0.8621 - val_loss: 0.3814 - val_accuracy: 0.8604\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 1s 869us/step - loss: 0.3686 - accuracy: 0.8691 - val_loss: 0.3665 - val_accuracy: 0.8656\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 925us/step - loss: 0.3553 - accuracy: 0.8732 - val_loss: 0.3643 - val_accuracy: 0.8720\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 908us/step - loss: 0.3385 - accuracy: 0.8778 - val_loss: 0.3611 - val_accuracy: 0.8684\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 926us/step - loss: 0.3297 - accuracy: 0.8796 - val_loss: 0.3490 - val_accuracy: 0.8726\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 893us/step - loss: 0.3200 - accuracy: 0.8850 - val_loss: 0.3625 - val_accuracy: 0.8666\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 886us/step - loss: 0.3097 - accuracy: 0.8881 - val_loss: 0.3656 - val_accuracy: 0.8672\n"
     ]
    }
   ],
   "source": [
    "history_sgd = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum\n",
    "Imagine a bowling ball rolling down a gentle slope on a smooth surface: it will start out slowly, but it will quickly pick up momentum until it eventually reaches terminal velocity (if there is some friction or air resistance). This is the core idea behind *momentum optimization*, proposed by Boris Polyak in 1964 in [\u201cSome Methods of Speeding Up the Convergence of Iteration Methods\u201d](https://homl.info/54).\n",
    "\n",
    "\u064bRegular gradient descent will take small steps when the slope is gentle and big steps when the slope is steep, but it will never pick up speed.\n",
    "\n",
    "Momentum optimization cares a great deal about what previous gradients were: at each iteration, it subtracts the local gradient from the momentum vector $\\mathbf{m}$ (multiplied by the learning rate $\\eta$), and it updates the weights by adding this momentum vector. The gradient is used as an acceleration, not as a speed. To simulate some sort of friction mechanism and prevent the momentum from growing too large, the algorithm introduces a new hyperparameter $\\beta$, called the *momentum*, which must be set between 0 (high friction) and 1 (no friction). A typical momentum value is 0.9.\n",
    "\n",
    "**Equation 11-5** Momentum algorithm\n",
    "1. $\\;\\;\\;\\;\\;\\mathbf{m}\\gets\\beta\\mathbf{m}\u2212\\eta\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})$\n",
    "2. $\\;\\;\\;\\;\\;\\boldsymbol{\\theta}\\gets\\boldsymbol{\\theta}+\\mathbf{m}$\n",
    "\n",
    "We can verify that if the gradient remains constant, the terminal velocity (i.e., the maximum size of the weight updates) is equal to that gradient multiplied by the learning rate $\\eta$ multiplied by $1/(1\u2013\\beta)$ (ignoring the sign). e.g. if $\\beta=0.9$, then the terminal velocity is equal to 10 times the gradient times the learning rate, so momentum optimization ends up going 10 times faster than gradient descent! This allows momentum optimization to escape from plateaus much faster than gradient descent.\n",
    "\n",
    "**Note**: In deep neural networks that don\u2019t use batch normalization, the upper layers will often end up having inputs with very different scales, so using momentum optimization helps a lot. It can also help roll past local optima.\n",
    "\n",
    "**Note**: Due to the momentum, the optimizer may overshoot a bit, then come back, overshoot again, and oscillate like this many times before stabilizing at the minimum. This is one of the reasons it\u2019s good to have a bit of friction in the system: it gets rid of these oscillations and thus speeds up convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 941us/step - loss: 0.6877 - accuracy: 0.7677 - val_loss: 0.4960 - val_accuracy: 0.8172\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 878us/step - loss: 0.4619 - accuracy: 0.8378 - val_loss: 0.4421 - val_accuracy: 0.8404\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 898us/step - loss: 0.4179 - accuracy: 0.8525 - val_loss: 0.4188 - val_accuracy: 0.8538\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 934us/step - loss: 0.3902 - accuracy: 0.8621 - val_loss: 0.3814 - val_accuracy: 0.8604\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 910us/step - loss: 0.3686 - accuracy: 0.8691 - val_loss: 0.3665 - val_accuracy: 0.8656\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 913us/step - loss: 0.3553 - accuracy: 0.8732 - val_loss: 0.3643 - val_accuracy: 0.8720\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 893us/step - loss: 0.3385 - accuracy: 0.8778 - val_loss: 0.3611 - val_accuracy: 0.8684\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 968us/step - loss: 0.3297 - accuracy: 0.8796 - val_loss: 0.3490 - val_accuracy: 0.8726\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 913us/step - loss: 0.3200 - accuracy: 0.8850 - val_loss: 0.3625 - val_accuracy: 0.8666\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 1s 858us/step - loss: 0.3097 - accuracy: 0.8881 - val_loss: 0.3656 - val_accuracy: 0.8672\n"
     ]
    }
   ],
   "source": [
    "history_momentum = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nesterov Accelerated Gradient\n",
    "The *Nesterov accelerated gradient* (NAG) method, also known as *Nesterov momentum optimization*, proposed in [\u201cA Method for Unconstrained Convex Minimization Problem with the Rate of Convergence $O(1/k^2)$\u201d](https://homl.info/55) by Yurii Nesterov in 1983, measures the gradient of the cost function not at the local position $\\boldsymbol{\\theta}$ but slightly ahead in the direction of the momentum, at $\\boldsymbol{\\theta}+\\beta\\mathbf{m}$.\n",
    "\n",
    "**Equation 11-6** Nesterov accelerated gradient algorithm\n",
    "1. $\\;\\;\\;\\;\\;\\mathbf{m}\\gets\\beta\\mathbf{m}\u2212\\eta\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta}+\\beta\\mathbf{m})$\n",
    "2. $\\;\\;\\;\\;\\;\\boldsymbol{\\theta}\\gets\\boldsymbol{\\theta}+\\mathbf{m}$\n",
    "\n",
    "This small tweak works because in general the momentum vector will be pointing in the right direction (i.e., toward the optimum), so it will be slightly more accurate to use the gradient measured a bit farther in that direction rather than the gradient at the original position.\n",
    "\n",
    "<center>\n",
    "  <img \n",
    "    src=\"../images/11/nesterov.png\" \n",
    "    onerror=\"\n",
    "      this.onerror = null;\n",
    "      const repo = 'https://github.com/alirezatheh/handson-ml3-notes/blob/main';\n",
    "      this.src = repo + this.src.split('..')[1];\n",
    "    \"\n",
    "  >\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(\n",
    "    learning_rate=0.001, momentum=0.9, nesterov=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 907us/step - loss: 0.6777 - accuracy: 0.7711 - val_loss: 0.4796 - val_accuracy: 0.8260\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 898us/step - loss: 0.4570 - accuracy: 0.8398 - val_loss: 0.4358 - val_accuracy: 0.8396\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 1s 872us/step - loss: 0.4140 - accuracy: 0.8537 - val_loss: 0.4013 - val_accuracy: 0.8566\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 902us/step - loss: 0.3882 - accuracy: 0.8629 - val_loss: 0.3802 - val_accuracy: 0.8616\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 913us/step - loss: 0.3666 - accuracy: 0.8703 - val_loss: 0.3689 - val_accuracy: 0.8638\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 882us/step - loss: 0.3531 - accuracy: 0.8732 - val_loss: 0.3681 - val_accuracy: 0.8688\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 958us/step - loss: 0.3375 - accuracy: 0.8784 - val_loss: 0.3658 - val_accuracy: 0.8670\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 895us/step - loss: 0.3278 - accuracy: 0.8815 - val_loss: 0.3598 - val_accuracy: 0.8682\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 878us/step - loss: 0.3183 - accuracy: 0.8855 - val_loss: 0.3472 - val_accuracy: 0.8720\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 921us/step - loss: 0.3081 - accuracy: 0.8891 - val_loss: 0.3624 - val_accuracy: 0.8708\n"
     ]
    }
   ],
   "source": [
    "history_nesterov = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaGrad\n",
    "Consider the elongated bowl problem again: gradient descent starts by quickly going down the steepest slope, which does not point straight toward the global optimum, then it very slowly goes down to the bottom of the valley. It would be nice if the algorithm could correct its direction earlier to point a bit more toward the global optimum. The *AdaGrad algorithm*, proposed in [\u201cAdaptive Subgradient Methods for Online Learning and Stochastic Optimization\u201d](https://homl.info/56) by John Duchi et al. in 2011, achieves this correction by scaling down the gradient vector along the steepest dimensions.\n",
    "\n",
    "**Equation 11-7** AdaGrad algorithm\n",
    "1. $\\;\\;\\;\\;\\;\\mathbf{s}\\gets\\mathbf{s}+\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})\\otimes\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})$\n",
    "2. $\\;\\;\\;\\;\\;\\boldsymbol{\\theta}\\gets\\boldsymbol{\\theta}-\\eta\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})\\oslash\\sqrt{\\mathbf{s}+\\varepsilon}$\n",
    "\n",
    "\n",
    "In this equation:\n",
    "1. The first step accumulates the square of the gradients into the vector $\\mathbf{s}$. This vectorized form is equivalent to computing $s_i\\gets s_i+(\\partial J(\\boldsymbol{\\theta})/\\partial\\theta_i)^2$ for each element $s_i$ of the vector $\\mathbf{s}$; in other words, each $s_i$ accumulates the squares of the partial derivative of the cost function with regard to parameter $\\theta_i$. If the cost function is steep along the $i^\\text{th}$ dimension, then $s_i$ will get larger and larger at each iteration.\n",
    "2. The second step is almost identical to gradient descent, but the gradient vector is scaled down by a factor of $\\sqrt{\\mathbf{s}+\\varepsilon}$ ($\\varepsilon$ is a smoothing term to avoid division by zero, typically set to $10^{\u201310}$).\n",
    "\n",
    "In short, this algorithm decays the learning rate, but it does so faster for steep dimensions than for dimensions with gentler slopes. This is called an *adaptive learning rate*. It helps point the resulting updates more directly toward the global optimum and requires much less tuning of the learning rate hyperparameter $\\eta$.\n",
    "\n",
    "<center>\n",
    "  <img \n",
    "    src=\"../images/11/adagrad.png\" \n",
    "    onerror=\"\n",
    "      this.onerror = null;\n",
    "      const repo = 'https://github.com/alirezatheh/handson-ml3-notes/blob/main';\n",
    "      this.src = repo + this.src.split('..')[1];\n",
    "    \"\n",
    "  >\n",
    "</center>\n",
    "\n",
    "AdaGrad frequently performs well for simple quadratic problems, but it often stops too early when training neural networks. We should not use it to train deep neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adagrad(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 1.0003 - accuracy: 0.6822 - val_loss: 0.6876 - val_accuracy: 0.7744\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 912us/step - loss: 0.6389 - accuracy: 0.7904 - val_loss: 0.5837 - val_accuracy: 0.8048\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 930us/step - loss: 0.5682 - accuracy: 0.8105 - val_loss: 0.5379 - val_accuracy: 0.8154\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 878us/step - loss: 0.5316 - accuracy: 0.8215 - val_loss: 0.5135 - val_accuracy: 0.8244\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 1s 855us/step - loss: 0.5076 - accuracy: 0.8295 - val_loss: 0.4937 - val_accuracy: 0.8288\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 1s 868us/step - loss: 0.4905 - accuracy: 0.8338 - val_loss: 0.4821 - val_accuracy: 0.8312\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 940us/step - loss: 0.4776 - accuracy: 0.8371 - val_loss: 0.4705 - val_accuracy: 0.8348\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 966us/step - loss: 0.4674 - accuracy: 0.8409 - val_loss: 0.4611 - val_accuracy: 0.8362\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 892us/step - loss: 0.4587 - accuracy: 0.8435 - val_loss: 0.4548 - val_accuracy: 0.8406\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 873us/step - loss: 0.4511 - accuracy: 0.8458 - val_loss: 0.4469 - val_accuracy: 0.8424\n"
     ]
    }
   ],
   "source": [
    "history_adagrad = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp\n",
    "The RMSProp algorithm fixes AdaGrad\u2019s issue by accumulating only the gradients from the most recent iterations, as opposed to all the gradients since the beginning of training. It does so by using exponential decay in the first step.\n",
    "\n",
    "**Equation 11-8** RMSProp algorithm\n",
    "1. $\\;\\;\\;\\;\\;\\mathbf{s}\\gets\\rho\\mathbf{s}+(1-\\rho)\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})\\otimes\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})$\n",
    "2. $\\;\\;\\;\\;\\;\\boldsymbol{\\theta}\\gets\\boldsymbol{\\theta}-\\eta\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})\\oslash\\sqrt{\\mathbf{s}+\\varepsilon}$\n",
    "\n",
    "This algorithm was created by Geoffrey Hinton and Tijmen Tieleman in 2012 and presented by Geoffrey Hinton in his Coursera class on neural networks (slides: https://homl.info/57; video: https://homl.info/58). Amusingly, since the authors did not write a paper to describe the algorithm, researchers often cite \u201cslide 29 in lecture 6e\u201d in their papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5138 - accuracy: 0.8135 - val_loss: 0.4413 - val_accuracy: 0.8338\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 942us/step - loss: 0.3932 - accuracy: 0.8590 - val_loss: 0.4518 - val_accuracy: 0.8370\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 948us/step - loss: 0.3711 - accuracy: 0.8692 - val_loss: 0.3914 - val_accuracy: 0.8686\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 949us/step - loss: 0.3643 - accuracy: 0.8735 - val_loss: 0.4176 - val_accuracy: 0.8644\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 970us/step - loss: 0.3578 - accuracy: 0.8769 - val_loss: 0.3874 - val_accuracy: 0.8696\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3561 - accuracy: 0.8775 - val_loss: 0.4650 - val_accuracy: 0.8590\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3528 - accuracy: 0.8783 - val_loss: 0.4122 - val_accuracy: 0.8774\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 989us/step - loss: 0.3491 - accuracy: 0.8811 - val_loss: 0.5151 - val_accuracy: 0.8586\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3479 - accuracy: 0.8829 - val_loss: 0.4457 - val_accuracy: 0.8856\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 1000us/step - loss: 0.3437 - accuracy: 0.8830 - val_loss: 0.4781 - val_accuracy: 0.8636\n"
     ]
    }
   ],
   "source": [
    "history_rmsprop = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam\n",
    "*Adam*, proposed in [\u201cAdam: A Method for Stochastic Optimization\u201d](https://homl.info/59) by Diederik P. Kingma and Jimmy Ba in 2014, which stands for *adaptive moment estimation*, combines the ideas of momentum optimization and RMSProp: just like momentum optimization, it keeps track of an exponentially decaying average of past gradients; and just like RMSProp, it keeps track of an exponentially decaying average of past squared gradients. These are estimations of the mean and (uncentered) variance of the gradients. The mean is often called the *first moment* while the variance is often called the *second moment*, hence the name of the algorithm.\n",
    "\n",
    "**Equation 11-9** Adam algorithm\n",
    "1. $\\mathbf{m}\\gets\\beta_1\\mathbf{m}\u2212(1-\\beta_1)\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})$\n",
    "2. $\\mathbf{s}\\gets\\beta_2\\mathbf{s}+(1-\\beta_2)\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})\\otimes\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})$\n",
    "</br>\n",
    "\n",
    "3. $\\widehat{\\mathbf{m}}\\gets\\dfrac{\\mathbf{m}}{1-{\\beta_1}^t}$\n",
    "</br>\n",
    "\n",
    "4. $\\widehat{\\mathbf{s}}\\gets\\dfrac{\\mathbf{s}}{1-{\\beta_2}^t}$\n",
    "</br>\n",
    "\n",
    "5. $\\boldsymbol{\\theta}\\gets\\boldsymbol{\\theta}-\\eta\\widehat{\\mathbf{m}}\\oslash\\sqrt{\\widehat{\\mathbf{s}}+\\varepsilon}$\n",
    "\n",
    "- $t$ represents the iteration number (starting at 1).\n",
    "- The only difference is that step 1 computes an exponentially decaying average rather than an exponentially decaying sum, but these are actually equivalent except for a constant factor (the decaying average is just $1\u2013\\beta_1$ times the decaying sum).\n",
    "- Steps 3 and 4 are somewhat of a technical detail: since $\\mathbf{m}$ and $\\mathbf{s}$ are initialized at 0, they will be biased toward 0 at the beginning of training, so these two steps will help boost $\\mathbf{m}$ and $\\mathbf{s}$ at the beginning of training.\n",
    "- The momentum decay hyperparameter $\\beta_1$ is typically initialized to 0.9, while the scaling decay hyperparameter $\\beta_2$ is often initialized to 0.999. As earlier, the smoothing term $\\varepsilon$ is usually initialized to a tiny number such as $10^{\u20137}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4949 - accuracy: 0.8220 - val_loss: 0.4110 - val_accuracy: 0.8428\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3727 - accuracy: 0.8637 - val_loss: 0.4153 - val_accuracy: 0.8370\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3372 - accuracy: 0.8756 - val_loss: 0.3600 - val_accuracy: 0.8708\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3126 - accuracy: 0.8833 - val_loss: 0.3498 - val_accuracy: 0.8760\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2965 - accuracy: 0.8901 - val_loss: 0.3264 - val_accuracy: 0.8794\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2821 - accuracy: 0.8947 - val_loss: 0.3295 - val_accuracy: 0.8782\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2672 - accuracy: 0.8993 - val_loss: 0.3473 - val_accuracy: 0.8790\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2587 - accuracy: 0.9020 - val_loss: 0.3230 - val_accuracy: 0.8818\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2500 - accuracy: 0.9057 - val_loss: 0.3676 - val_accuracy: 0.8744\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2428 - accuracy: 0.9073 - val_loss: 0.3879 - val_accuracy: 0.8696\n"
     ]
    }
   ],
   "source": [
    "history_adam = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaMax\n",
    "The Adam paper also introduced AdaMax. In step 5, if we ignore $\\varepsilon$ and steps 3 and 4 (which are technical details anyway), Adam scales down the parameter updates by the square root of $\\mathbf{s}$. In short, Adam scales down the parameter updates by the $\\ell_2$ norm of the time-decayed gradients.\n",
    "\n",
    "AdaMax replaces the $\\ell_2$ norm with the $\\ell_\\infty$ norm (a fancy way of saying the max). It replaces step 2 with $\\mathbf{s}\\gets\\max(\\beta_2\\mathbf{s},\\text{abs}(\\nabla_{\\boldsymbol{\\theta}}J(\\boldsymbol{\\theta})))$, it drops step 4, and in step 5 it scales down the gradient updates by a factor of $\\mathbf{s}$, which is the max of the absolute value of the time-decayed gradients.\n",
    "\n",
    "In practice, this can make AdaMax more stable than Adam, but it really depends on the dataset, and in general Adam performs better. So, this is just one more optimizer we can try if we experience problems with Adam on some task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adamax(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5327 - accuracy: 0.8151 - val_loss: 0.4402 - val_accuracy: 0.8340\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 935us/step - loss: 0.3950 - accuracy: 0.8591 - val_loss: 0.3907 - val_accuracy: 0.8512\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 933us/step - loss: 0.3563 - accuracy: 0.8715 - val_loss: 0.3730 - val_accuracy: 0.8676\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 942us/step - loss: 0.3335 - accuracy: 0.8797 - val_loss: 0.3453 - val_accuracy: 0.8738\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 993us/step - loss: 0.3129 - accuracy: 0.8853 - val_loss: 0.3270 - val_accuracy: 0.8792\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 926us/step - loss: 0.2986 - accuracy: 0.8913 - val_loss: 0.3396 - val_accuracy: 0.8772\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 939us/step - loss: 0.2854 - accuracy: 0.8949 - val_loss: 0.3390 - val_accuracy: 0.8770\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 949us/step - loss: 0.2757 - accuracy: 0.8984 - val_loss: 0.3147 - val_accuracy: 0.8854\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 952us/step - loss: 0.2662 - accuracy: 0.9020 - val_loss: 0.3341 - val_accuracy: 0.8760\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 957us/step - loss: 0.2542 - accuracy: 0.9063 - val_loss: 0.3282 - val_accuracy: 0.8780\n"
     ]
    }
   ],
   "source": [
    "history_adamax = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Nadam\n",
    "Nadam optimization, proposed in a report [\u201cIncorporating Nesterov Momentum into Adam\u201d](https://homl.info/nadam) by Timothy Dozat in 2016, is Adam optimization plus the Nesterov trick, so it will often converge slightly faster than Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.4826 - accuracy: 0.8284 - val_loss: 0.4092 - val_accuracy: 0.8456\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3610 - accuracy: 0.8667 - val_loss: 0.3893 - val_accuracy: 0.8592\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3270 - accuracy: 0.8784 - val_loss: 0.3653 - val_accuracy: 0.8712\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3049 - accuracy: 0.8874 - val_loss: 0.3444 - val_accuracy: 0.8726\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2897 - accuracy: 0.8905 - val_loss: 0.3174 - val_accuracy: 0.8810\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2753 - accuracy: 0.8981 - val_loss: 0.3389 - val_accuracy: 0.8830\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2652 - accuracy: 0.9000 - val_loss: 0.3725 - val_accuracy: 0.8734\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2563 - accuracy: 0.9034 - val_loss: 0.3229 - val_accuracy: 0.8828\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2463 - accuracy: 0.9079 - val_loss: 0.3353 - val_accuracy: 0.8818\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2402 - accuracy: 0.9091 - val_loss: 0.3813 - val_accuracy: 0.8740\n"
     ]
    }
   ],
   "source": [
    "history_nadam = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdamW\n",
    "AdamW, proposed in [\u201cDecoupled Weight Decay Regularization\u201d](https://homl.info/adamw) by Ilya Loshchilov, and Frank Hutter in 2017, is a variant of Adam that integrates a regularization technique called *weight decay*. Weight decay reduces the size of the model\u2019s weights at each training iteration by multiplying them by a decay factor such as 0.99. It can be shown mathematically that $\\ell_2$ regularization is equivalent to weight decay when using SGD. In practice, combining Adam with $\\ell_2$ regularization results in models that often don\u2019t generalize as well as those produced by SGD. AdamW fixes this issue by properly combining Adam with weight decay.\n",
    "\n",
    "**Warning**: Adaptive optimization methods (including RMSProp, Adam, AdaMax, Nadam, and AdamW optimization) are often great, converging fast to a good solution. However, a 2017 paper [\u201cThe Marginal Value of Adaptive Gradient Methods in Machine Learning\u201d](https://homl.info/60) by Ashia C. Wilson et al. showed that they can lead to solutions that generalize poorly on some datasets. So when we are disappointed by our model\u2019s performance, we can try using NAG instead: our dataset may just be allergic to adaptive gradients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.AdamW(\n",
    "    weight_decay=1e-5, learning_rate=0.001, beta_1=0.9, beta_2=0.999\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.4945 - accuracy: 0.8220 - val_loss: 0.4203 - val_accuracy: 0.8424\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3735 - accuracy: 0.8629 - val_loss: 0.4014 - val_accuracy: 0.8474\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3391 - accuracy: 0.8753 - val_loss: 0.3347 - val_accuracy: 0.8760\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3155 - accuracy: 0.8827 - val_loss: 0.3441 - val_accuracy: 0.8720\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2989 - accuracy: 0.8892 - val_loss: 0.3218 - val_accuracy: 0.8786\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2862 - accuracy: 0.8931 - val_loss: 0.3423 - val_accuracy: 0.8814\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2738 - accuracy: 0.8970 - val_loss: 0.3593 - val_accuracy: 0.8764\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2648 - accuracy: 0.8993 - val_loss: 0.3263 - val_accuracy: 0.8856\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2583 - accuracy: 0.9035 - val_loss: 0.3642 - val_accuracy: 0.8680\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2483 - accuracy: 0.9054 - val_loss: 0.3696 - val_accuracy: 0.8702\n"
     ]
    }
   ],
   "source": [
    "history_adamw = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<div style=\"border: 1px solid;\">\n",
    "\n",
    "#### Training Sparse Models\n",
    "All the optimization algorithms we just discussed produce dense models, meaning that most parameters will be nonzero. If we need a blazingly fast model at runtime, or if we need it to take up less memory, we may prefer to end up with a sparse model instead.\n",
    "\n",
    "- One way is to train the model as usual, then get rid of the tiny weights (set them to zero). However, this will typically not lead to a very sparse model, and it may degrade the model\u2019s performance.\n",
    "- A better option is to apply strong $\\ell_1$ regularization during training, as it pushes the optimizer to zero out as many weights as it can.\n",
    "- If these techniques remain insufficient, check out the [TensorFlow Model Optimization Toolkit (TF-MOT)](https://homl.info/tfmot), which provides a pruning API capable of iteratively removing connections during training based on their magnitude.\n",
    "</div>\n",
    "\n",
    "The following table compares all the optimizers we\u2019ve discussed so far (* is bad, ** is average, and *** is good):\n",
    "\n",
    "| Class                              | Convergence speed | Convergence quality |\n",
    "|------------------------------------|-------------------|---------------------|\n",
    "| `SGD`                              | *                 | ***                 |\n",
    "| `SGD(momentum=...)`                | **                | ***                 |\n",
    "| `SGD(momentum=..., nesterov=True)` | **                | ***                 |\n",
    "| `Adagrad`                          | ***               | * (stops too early) |\n",
    "| `RMSprop`                          | ***               | ** or ***           |\n",
    "| `Adam`                             | ***               | ** or ***           |\n",
    "| `AdaMax`                           | ***               | ** or ***           |\n",
    "| `Nadam`                            | ***               | ** or ***           |\n",
    "| `AdamW`                            | ***               | ** or ***           |\n",
    "\n",
    "Let\u2019s visualize the learning curves of all the optimizers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtgAAAHoCAYAAABzQZg1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAD0SElEQVR4nOzdd5gUVdbA4d+t6jzdk4c0wBBmQJAgoIiCSjChILqgIihmXOPnrqirmLMsxtXVlaC4LiYUs5hRMYEkRVByhsl5Ond9f3RPzzQzYKMwifM+zzx0Vd2qvl2Oevpy6hxlGAZCCCGEEEKIA0Nr7AkIIYQQQgjRkkiALYQQQgghxAEkAbYQQgghhBAHkATYQgghhBBCHEASYAshhBBCCHEASYAthBBCCCHEAdSgAbZS6lSl1G9KqfVKqX/Uc/xGpdSKyM8qpVRQKZXakHMUQgghhBDiz1ANVQdbKaUDa4GTgO3AEuA8wzBW72X8aOBvhmEMb5AJCiGEEEIIcQA05Ar2QGC9YRgbDcPwAa8AY/Yx/jzg5QaZmRBCCCGEEAdIQwbYmcC2WtvbI/vqUEo5gFOBNxpgXkIIIYQQQhwwpgZ8L1XPvr3lp4wGvjEMo6jeCyk1GZgMYLPZBnTs2PHAzLAZ0Coq0QsLATBsVgKtW8d9bigUQtPkudbfI/cpPnKf4if3Kj5yn+In9yo+cp/iI/cpfmvXri0wDCPj98Y1ZIC9HehQa7s9sHMvY8ezj/QQwzCeA54D6N69u/Hbb78dqDk2ef68PNYff0J4w2ym23ffoTsT4jp34cKFDB069OBNroWQ+xQfuU/xk3sVH7lP8ZN7FR+5T/GR+xQ/pdSWeMY15NeVJUCOUqqzUspCOIh+Z89BSqkk4ATg7QacW7NhbtUKa48e4Q2/n6rvv2vcCQkhhBBCiBgNFmAbhhEArgE+AtYArxmG8YtS6q9Kqb/WGnoW8LFhGJUNNbfmxnnccdHXFV8vasSZCCGEEEKIPTVkigiGYXwAfLDHvmf32H4BeKHhZtX8OI8bQuFzzwFQ8fVXGIaBUvWluAshhBBCiIYmGe3NkP2II9CcTgACO3fh27ChkWckhBBCCCGqNf8Au4Ea5TQlymwm4dhjo9uSJiKEEEII0XQ0aIrIwWCv2MKviz/hsIEn1Xu8rKyMvLw8/H5/A8/s4ApNuoDgmDMA2Gm1krdmze+ek5SUxJo4xrUkCQkJtG/fXsoPCSGEEKLBNPsA20QA95ePQz0BdllZGbm5uWRmZmK321tUnnLI78dbXZ5QKWzduqF0fZ/nlJeX43K5GmB2TUMoFGLHjh0UFBTQqlWrxp6OEEIIIQ4RLWJZr2/FN2xbt7LO/ry8PDIzM3E4HC0quAbQzGY0qy28YRiEKqXoyp40TaN169aUlpY29lSEEEIIcQhpEQG2pgx2Lni0zn6/34/dbm+EGTUMzeWMvg5VVDTiTJous9lMIBBo7GkIIYQQ4hDSIgJsgL4F71OYu73O/pa2cl1bdSURgGB5BcYh+MDn72nJ//yFEEII0TQ1+wDbgxUAm/Kz9r3HG3cyDUxzOFCRh/cMvw/D52vkGQkhhBBCiOYfYJuTo68P2/YK7sryxptMA1OahpZQK02k/ND57EIIIYQQTVWzD7CLTB6WmcIVIlIo56f3n2nkGR0Y+fn5XHXVVXTq1Amr1Urr1q0ZMWIEn3zySXTMxo0b+ettU+l+8skk9+9Px8MPZ9iwYcyZMwdfrdVspRRKKRITE3E4HHTp0oUJEyawaJHUzxZCCCGEONCafZk+d8jNC1m96L/hcwAy18wmGPg7uql5f7SxY8dSVVXFrFmzyM7OJi8vjy+//JLCwkIAfvzxR0aMGEGPww7jkVtuoXvnzlR5vWz0eJgZOWfw4MHR682YMYOhQ4diNpvZuHEjc+bM4fjjj+fhhx/mxhtvbKyPKYQQQgjR4jTvKDTiW7ayRXOSFaqgvbGL5Z/9j36nXNjY0/rDSkpK+Prrr/nkk08YMWIEAFlZWRx11FEAGIbBhRdeSE5ODt9+9x2+DRswvF4AjsrKYsLEiXUeeExOTqZ169a4XC6ysrIYNmwY7dq145ZbbuGss84iOzu7YT+kEEIIIUQL1exTRAC8IR/PZPaLbtuXNO80EafTidPp5J133sHj8dQ5vmLFClavXs2UKVPQNA3dWTsPO1yuL57qGTfccAOhUIi33nrrgM1dCCGEEOJQ1yJWsAG+shVSgplk/BwWWMOvP3wMiR3qjOv0j/cbYXZhmx86Pa5xJpOJF154gcsvv5znnnuOfv36MXjwYM4++2yOPvpo1q5dC0D37t0B0FwuSjdvJnvECFAKlOLWW2/l1ltv3ef7pKWl0apVKzZu3PjnPpgQQgghhIhq9ivYJhX+jlAeqOCp1jWr2O4vH2+kGR0YY8eOZefOnbz77ruMHDmSb7/9lkGDBvHAAw/UGas5HLhcLr6fN4/vX3+ddm3bxjzkuC+GYUitaCGEEEKIA6jZB9iJemL09WfJXvyR130rvyXgb951oW02GyeddBJ33HEH3377LZdeeil33XUXnTp1AuDXX38FwuX6zC4XXTt2pGvHjljifMCzoKCA/Px8unTpcrA+ghBCCCHEIafZp4gkaAmk2lIp8hRR4Cvm2ZTeXFv8M5oyCLrL6oyPN02jKerZsyeBQIDDDjuMHj16MG3aNM455xx0XUdzOglG6mAboVBc13vkkUfQNI0xY8YczGkLIYQQQhxSmv0KtkJxfo/zo9sftLJSHV5aQu5muYpdWFjI8OHDeemll/jpp5/YtGkTr7/+OtOmTWPEiBEkJSXxwgsvsGHDBo455hjefvtt1u/axa8bN/L8G2+wY9cuNC32H21JSQm5ubls3bqVL774gosuuoiHH36Yhx56SCqICCGEEEIcQM1+BRvgnO7nMPPnmVQFqtjuy+MVZxcmVGxEYeApycWZUfdhx6bM6XQyaNAgnnjiCdavX4/X6yUzM5MJEyZw2223ATBw4ECWLVvGgw8+yLXXXsvu3buxW6306taNO6+9liuuujrmmpdffjkAVquVtm3bMmjQIBYuXMjxxx/f4J9PCCGEEKIlaxEBdpI1ibO7nc2c1XMAmNc2gwnrwpUxbP4iQsF2aLremFPcL1arlQceeKDeBxpry87OZtasWdFt/65dBCKNaEy1Vu6ra2KXl5fjcrkOwoyFEEIIIUS1Zp8iUu2Cnhdg0sLfF9YFdvGptTUAJkJUleY15tQajFarHnYwUg9bCCGEEEI0rBYTYLdOaM2oLqOi2y9kdo6+tngK63Q2bIm0hIRwHWzA8HkJxVmqTwghhBBCHDgtJsAGuPjwi1GEA8yVxk58KvzxLPipKitszKk1CKVp4SA7IhSpKiKEEEIIIRpOiwqwuyR3YViHYdHtct0cfa1X5h8Sq9h6rRzrUIWkiQghhBBCNLQWFWADXNL7kuhrHyG8kRVtGx48lXXrYrc0MXnYlZVx18QWQgghhBAHRosLsPtm9GVA6wEAGBjkme3RY0ZFbmNNq8FoVivKYglvhEKEqqoad0JCCCGEEIeYFhdgA1zSq2YVu1wLEoi8tgcr8XpafsCp11rFDkk1ESGEEEKIBtUiA+zjMo8jJyUHCNeAzjPZgHCBDX/p7sacWoPQauVhByvkQUchhBBCiIbUIgNspRQXH35xdLtUJ9o+3REoa5bt0/dHTLk+r5TrE0IIIYRoSC0ywAY4tfOp6Fq4e2PICJGvWwHQVLh9ektWp1yfVBMRQgghhGgwLTbANmtmnOaaXOQSk0Z1kb5w+/Rg40wsDhdddBFKKS677LI6x2666SaUUowaNaqeM2vE5GE3YoCtlGLevHmN9v5CCCGEEA2txQbYAHaTPbqKHTCCFGnhutjNoX16hw4dePXVV6msrIzuCwQC/Pe//6Vjx46/e762Rz1sKdcnhBBCCNEwWnSArSmNVFtqdLvQZIquYjf19ul9+vQhJyeH1157Lbrv/fffx2azMXTo0Oi+UCjEvffeS4cOHbBarfTu3Zu3334bZbGgzGa27NiB/fDDefnFFxk5ciR2u51+/frx008/sWrVKo499lgSEhIYMmQImzZtipnDu+++y4ABA7DZbHTu3JmpU6fiq5XP3alTJ+677z6uuOIKEhMTad++Pf/85z9jjgOcffbZKKWi23fddRe9evWKea8XXngBZ61V9+oxc+bMoVOnTjidTi6++GJ8Ph///ve/6dChA2lpafz9738nJF8ehBBCCNGEtOgAGyDVloqKPPDnJ0iZCq9oN4f26ZdeeimzZ8+Obs+ePZuLL744+nkAnnjiCf75z3/y8MMP8/PPP3PWWWfxl7/8hZUrV8asYt91331cf/31LF++nOTkZCZMmMC1117L/fffz+LFi/F4PFx33XXR8R999BETJ07kmmuu4ZdffmH27NnMmzePW2+9NWaOjz32GL1792bZsmXcfPPN3HTTTXz33XcALFmyBIAZM2awa9eu6Ha8Nm/ezNtvv817773HG2+8weuvv86YMWNYsmQJH3/8MTNnzuRf//oX8+fP36/rCiGEEEIcTKbGnsDBZtJMpFhTKPIUAZD0n+OixxL2dtLBclfpfg2fMGECU6ZMYd26dbhcLhYsWMC//vUv7rjjjuiY6dOnM2XKFCZMmADAPffcw1dffcX06dOZ8+9/R8ddd+GFnHLKKbhcLm644QZGjx7NG2+8wbBh4dby11xzDddcc010/P3338+NN97IxReHq7F07dqVhx9+mPPPP59//vOf0SD/5JNPjp537bXX8uSTT/LZZ59xzDHHkJGRAUBycjJt2rTZ37tFMBjk+eefJykpiV69enHqqafy5ZdfsmPHDiwWCz169GDw4MF88cUXjB07dr+vL4QQQghxMLT4ABsgzZ4WDbCbk5SUFM466yxmz55NcnIyQ4cOjcm/LisrY+fOnQwePDjmvCFDhvDBBx/ElOvr1bkzBMItd1q3bg1A7969o+e0bt2ayspKqqqqcDgcLF26lMWLF/Pwww9Hx4RCIdxuN7t376Zt27ZAOJWltnbt2pGXd2Dy2zt27EhSUlLMHLt164alulNlZN+Bej8hhBBCiAPhkAiwLbqFJGsSpd79W0FuCi655BIuvPBCnE4n99xzT71jaqeM1N6ndB1lD7eKN5nNKI8nZrzZbK5zjep85lAoxJ133snZZ59d59rVK9N7XqP6Or+XE61pWp38d7/fX2dcfdeub1+wCVeEEUIIIcSh55AIsAHS7emUekv55ZpvAcj2+bFiYBjgS+uO1eZo5BnWb8SIEVgsFgoKCjjzzDNjjiUmJtKuXTsWLVrE8OHDo/sXLVpEz549AdAdNYkwmtsd9/v279+fX3/9lezs7D81f7PZXCcAzsjIIDc3F8MwooH9ihUr/tT7CCGEEEI0FYdMgG0z2XBanFT4wjWhc01WOgY80fbpVluXRp5h/ZRS/PTTTxiGgdVqrXP8xhtv5I477iAnJ4cBAwbw0ksv8fXXX7N06VIANGdNgK3cboJlZXG97x133MGoUaPIysrinHPOwWQysWrVKhYvXsy0adPinn+nTp347LPPOOGEE7BaraSkpDB06FCKiop44IEHGD9+PAsXLpRa2UIIIYRoMVp8FZHa0u3p0dcVWojqpARHoAx/E26f7nK5SExMrPfYddddx4033shNN91Er169mD9/Pm+88QZHHHEEAKpWvjKGgW/rVvxx5CyfcsopvP/++3zxxRcMHDiQgQMH8tBDD8VVg7u2Rx55hC+++IIOHTrQr18/AHr06MEzzzzDc889R58+ffjkk0/qVCcRQgghhGiuVFOuBR2P7t27G7/99lu9x9asWUOPHj2i24ZhsKlsE25/OFUiOQiZwXBgXWFOx5nR4eBPuBGEqqrwbd2KEXnIEUCZLZjbZ6InNHgtlQa35+/B71m4cGFMrXFRP7lP8ZN7FR+5T/GTexUfuU/xkfsUP6XUUsMwjvy9cYfUCrZSinRbzSp2ma6ozg62+YsIBgP1n9jMaQ4H1uxsDEdNnrnh9+HbtAn/7t3S5VEIIYQQ4gA6pAJsAJfFhUUPp02EMCjQa9qnu0vzG3NqB5UymQimp2Nu3x6l69H9gYICfBs2ENqPByCFEEIIIcTeHXIBtlIqJhe7WNeoXr+1eAqadPv0P00pTMnJWLKz0Wq1JQ95vXg3bsSfn9+yP78QQgghRAM45AJsgCRrEiYtXEAliEGxVt0+PdDk26cfCJrZjCUrC3PbtqAivwKGQSA3F9/GTYS83sadoBBCCCFEM3ZIBtia0kizp0W3C0xmqtdt9cq8Q2IVVymFKS0Na3ZXtEgzGoCQuwrvhg0EiooOifsghBBCCHGgHZIBNkCKNQUtsnobIESZFn5tw4unMr5a0S2BZrVi6dIFU6tW0bbqhEL4d+7Et2ULoXo6LAohhBBCiL07ZANsXdNJtaVGt/N0S3QV26jIbZxJNRKlFOZWrbB26YKq1cwmVFGBb/16gqXNr8W8EEIIIURjOWQDbIBUe2q0VbdPhaiKvHaEKvF6qhpzao1Cs9uxdu2KKa0mfcYIBvFt24Zv27aYOtpCCCGEEKJ+h3SAbdbMJFuTo9u5ppquh4HS3Y0wo8anNA1z27ZYOnVGmc3R/cHSUrzr1xMsL2/E2QkhhBBCNH2HdIANxDzs6FYG7sgqtr2Jt08/2HRnAtbsbPTklOg+IxDAt2ULvp07MYLBfZwthBBCCHHoOuQDbKtuJdGaGN3OizSe0ZSBt6RxcrEvuugilFLcd999MfsXLlyIUoqCgoI//R7xXEvpOpb2mVg6dkTppuj+YFER3g0bCFYdemk0QgghhBC/55APsIGYxjMVGlSvWzdm+3Sbzca0adPIz2/87pJ6YiLWnGz0xJovIobPh2/jRvy5ufikbrYQQgghRJQE2IDdZCfBnBDdzmsC7dOHDRtGp06duPfee/c6ZvXq1Zx++um4XC5atWrFeeedx+7dNbnjP//8MyNGjCAxMRGXy8Wxxx7LF198webNmxk2bBgAGRkZKKW46KKLADAMg2nTptG1a1fsdju9e/fmpZdeQplMmDt0YEcwiKN3b1774ANGXnopiVlZ/PuBBwhUVXHvvffSoUMHrFYrvXv35u23347O5ZhjjuGGG26ImX9ZWRl2u5358+cfwDsnhBBCCNG4JMCOqL2KXaYrqtetG6t9uqZpPPTQQzz77LNs2LChzvFdu3Zx/PHH06tXLxYvXsynn35KRUUFZ5xxBqFQuPn7hAkTaNu2LYsXL2b58uXccsst2Gw2OnTowBtvvAHAL7/8wq5du3jiiScAuO2225g1axZPP/00q1ev5pZbbuGKK67g/fffDzenSUoC4I4nn2Tyueey7K23OP2443j07rv557RpPPTQQ/z888+cddZZ/OUvf2HFihUAnH/++bzyyivRuQG88cYb2O12Tj/99IN5K4UQQgghGpTp94e0LL3n9G609/75wp/3a/xpp53G4MGDmTp1Kq+88krMsWeeeYa+ffvy8MMPR/e9+OKLpKam8uOPPzJw4EC2bNnClClTOOywwwBo3bo1LpcLgNTUcA3wVq1akZ4e/nJRWVnJo48+yscff8xxxx0HQOfOnVm8eDFPP/10TCB87fXXc86kSfhzc8EwePyFF/i/SZMYd8wxmNu355577uGrr75i+vTpvPTSS4wfP56//e1vfPHFF4wYMQKA//3vf5x99tlYLDXVW4QQQgghmjtZwW7ipk2bxuuvv86PP/4Ys3/p0qV89dVXOJ3O6E+HDh0Aoivef//737nssssYPnw4999/P2vXrt3ne61evRqPx8Opp54ac91nnnmmzir6UUcdhSk9HWvXrlT4A+zKy+OYfv0IVVXhW7+eQFERgwcPZvXq1QCkpaVxyimn8L///Q8Ir8B/8cUXnH/++QfkPgkhhBBCNBUSYDdxRx11FGPHjuXmm2+O2R8KhTj99NNZsWJFzM+6desYNWoUAHfddRerV6/mzDPP5Ntvv+WYY45h9uzZe32v6vSNd999N+aav/zyCx9//HHM2ISEcM66ZrNh6dwJABVpPW9EWq2HyspQtc45//zzeeONN/B4PLz88st06NCBIUOG/JnbI4QQQgjR5BxyKSK/l6ZR5CliV8UuAHQU3XxeNKBKS8DRplsDzLCuBx54gJ49e7JgwYLovv79+/Paa6+RlZWFuVZDmD3l5OSQk5PDddddx2WXXcbMmTO55JJLomkZwVr1rHv27InVamXLli0MHz487vklJSfTrl07Fm/exLDjhmD4wnVYvvn+e7q3b0+wtBQ9KYkxY8YwefJk3nvvPf73v/8xceLEaCdNIYQQQoiWQlaw95BsTUbXdACCGJRp4VvUmO3Ts7OzmTx5cvRBRICrr76a0tJSzj33XH744Qc2btzIp59+yuTJkykvL8ftdnP11VezcOFCNm/ezA8//MB3331Hz549AcjKykIpxfvvv09+fj4VFRW4XC6mTJnClClTmD17NuvXr2fFihU8++yzPPfcc/uc44033sgjTzzBm0uWsLG4hHueeopvli3jukmTwq3Wt2/Hajbzl7/8hfvuu49ly5ZJeogQQgghWiQJsPegKY00W013xzzdTHUNkcZsn37HHXdgMtX8hUO7du345ptv0DSNU089lcMPP5yrr74aq9WK1WpF13WKi4u58MIL6d69O2eddRYDBw7k0UcfBSAzM5O7776bqVOn0rp1a6655hoA7r33Xu666y6mT5/O4YcfzkknncQbb7xB586d9zm/6667jhtvvJGb//EP+o0Yzntff83LTz5J38gDlsGSErzr1zNh3DhWrlxJ//796dGjx0G6W0IIIYQQjeeQSxGJR4othQJ3ASEjhF8ZVCgNlxGKtE/3YjZbD+r7v/DCC3X2tWrVivLy8ph9OTk5zJs3b6/XmTt3bsx2eXl5tIoIwO23387tt98eM0YpxbXXXsu1115b7zU7depUb9lCTdPqXM8IBvHv2kWwpCS87fczJCsL386dmFq33uu8hRBCCCGaM1nBrodJM5FiS4lu50VWjsPt0/Maa1rNTrjVenssHTqgdD26P1BYiHfDBkLSal0IIYQQLZAE2HuRZkuLPoDnUVAVed2Y7dObKz0pCUt2Nnqt1XPD68W7cRP+3DyMWs1nhBBCCCGauwYNsJVSpyqlflNKrVdK/WMvY4YqpVYopX5RSn3ZkPOrzaybSbImRbfz9PAqdmO2T2/ONLMZc8eOmNu1Q2nVv3YGgfw8fJs2EfJ6G3V+QgghhBAHSoMF2EopHXgaGAn0BM5TSvXcY0wy8G/gDMMwDgfObqj51SfdVtM+vVJTeCKr2BZPgay6/gFKKUypqViys9Ecjuj+kNuNd/16AgWN05ZeCCGEEOJAasgV7IHAesMwNhqG4QNeAcbsMWYC8KZhGFsBDMNo1IRnq8mKy1KT1pAfySO2EKCqvKixptXsaRYLls6dMbduDdV1sA0D/+7d+DZvJhSpoy2EEEII0RyphloxVEqNA041DOOyyPYFwNGGYVxTa8zjgBk4HHABTxiG8WI915oMTAbIyMgY8Nprr9X7nklJSWRnZ/+peXtDXnL9udHtHJ8PC+DGit/Zvlk1SgkGg+i1HjZsEnw+9IJClL9WUK00gqkpGAkJNQH4n7B+/XpKS0vjHl9RUYHT6fzT79vSyX2Kn9yr+Mh9ip/cq/jIfYqP3Kf4DRs2bKlhGEf+3riGLNNXX6S0Z3RvAgYAIwA78J1S6nvDMNbGnGQYzwHPAXTv3t0YOnRovW+4Zs2amLJ0f4QLF+Wl5VT5wxUvCnWdtsEgdrygGdidiX/q+g1pzzJ9TYWRkkIgL59AQSS33QihFxai+/3hnG3Tn/s1tdls9OvXL+7xCxcuZG+/U6KG3Kf4yb2Kj9yn+Mm9io/cp/jIfTrwGjJFZDvQodZ2e2BnPWMWGIZRaRhGAfAV0LeB5rdX6faaXOxiXae6hohRkVv/CWK/KE3D3KY1ls5dUJEW7gDBsjK869cTLCtrxNkJIYQQQuyfhgywlwA5SqnOSikLMB54Z48xbwPHKaVMSikHcDSwpgHnWC+n2YnVFG4uYwBFkTQLR6gSr7uyEWfWsugJDqxdu6Knpkb3GYEAvq1b8e3YgREMNuLshBBCCCHi02ABtmEYAeAa4CPCQfNrhmH8opT6q1Lqr5Exa4AFwE/AYmCmYRirGmqOe6OUiqkoUqjrVNcQCZQ1jVXsefPmNZt88FGjRnHRRRfVe0zpOpZ27bBkZcWkhgSLi8Or2ZXyhUYIIYQQTVuD1sE2DOMDwzC6GYbR1TCM+yP7njUM49laY/5pGEZPwzB6GYbxeEPOb18SrYmYNTMAIaA4Usu5un36wbB8+XJ0XWfw4MEH5foAGzdu5LLLLiMrKwur1Uq7du0YNmwYc+bMwdeI1Tx0lwtrdjZ6Uk0tcsPvx7dpE/5du6VMohBCCCGaLOnkGCdNaaTZ06LbBboJg+r26QdnFXvGjBlcddVVrFq1ijVrDnymzI8//ki/fv1YtWoV//rXv/j555/54IMPmDx5MnPmzGHJkiV7Pdfv9x/w+exJmUxYOnTA3L79Hq3WC/Bt2EDI7T7ocxBCCCGE2F8SYO+HZGsyuhYO9AIKyiKr2DZ/8QFvn+52u5k7dy6XX34548aNY9asWTHHX3zxRbKysnA4HIwaNYrc3Nggf8OGDYwZM4Y2bdqQkJBA//79+fDDD6PHDcPgwgsvJCcnh2+//ZYzzjiDbt26ccQRR3Deeefx+eefc+yxxwKwefNmlFK8/PLLDB8+HLvdzn/+8x8KCws577zzaN++PXa7ncMPP5znn38+Zh5VVVVcdNFFOJ1OWrduzQMPPLDf98KUnBxuTlOrhFDI68W7cSP+vHxpTiOEEEKIJkUC7P2gazqptpoH8PJ1HYNI+/SSA9s+fd68eWRlZdGnTx8uuOACXnzxxeiq8Q8//MBFF13E5MmTWbFiBaNHj+aOO+6IOb+iooKRI0fyySefsHLlSsaOHcv555/Pr7/+CsCKFStYvXo1U6ZMQdPq/zXYM6f7lltu4aqrrmL16tWceeaZeDwe+vfvz3vvvccvv/zC//3f/3HFFVfw2WefRc+ZMmUKn3zyCW+88QafffYZy5cv56uvvtrv+6GZzViysjC3bQvV8zUMAnm5+DZulFbrQgghhGgyGrIOdpOw5rAef/oa1eGoH/h1P87r8Wv8aR4zZ87kggsuAOCEE07A4XDwzjvvMHbsWJ544glGjBjB1KlTAejWrRtLliyJWeXu27cvffvWVDicOnUqb731FvPmzeO2225j7dpwafHu3btHx5SWlpKZmRndvvXWW7n11luj29deey3jxo2LmeeNN94YfT158mQ+//xzXn75ZUaMGEFFRQWzZs1i9uzZnHLKKQA8//zztG/fPu77UJtSClNaGprTiX/79miKSMjtxrthA+bWrdFTU5vNw55CCCGEaJlkBbsJWr9+Pd988w0TJkwAwoHlxIkTmTlzJhBuoHPMMcfEnLPndmVlJTfddBM9e/YkJSUFp9PJ8uXL2bp1617f1+VysWLFClasWEG7du3qPOR45JGxjYuCwSD3338/ffr0IS0tDafTyZtvvhl9jw0bNuDz+WLm5nQ66d27937ekVia1YqlSxdMrWq1Wg+F8O/ahW/LFkINkB8uhBBCCLE3h9wKdnMwc+ZMgsEgHTt2jO6rzjPetm1bXDnHU6ZMYcGCBUyfPp2cnBwcDgcTJ06MBs3dunUD4Ndff412OdQ0Ldpa3lKr4Uu1hISEmO3p06fzyCOP8MQTT9C7d2+cTie33noreXl5MXM+GJRSmFtloLsiq9mRFJFQRQW+9esxtW2LKTn5oL2/EEIIIcTeHHIB9v6kaezL9vLtlHpLAXCFQnQMhB9ydCd2we5M2tep+xQIBJgzZw4PPvggo0aNijl2wQUX8Pzzz9OzZ0++//77mGN7bi9atIhJkyYxduxYADweD5s2baJHj3CKzBFHHEGPHj2YNm0a55xzDnqtKh3xWrRoEaNHj46mshiGwdq1a0mOBLbZ2dmYzWa+//57unTpAoRX1letWkXXrl33+/3qo9ntWLp2JZCXR6CgIDyPYDAcdJeXh3O2hRBCCCEa0CEXYB8o6fb0aIBdrml4UVgxMMpz4U8E2O+//z4FBQVcfvnlpKWlxRwbP348zzzzDHPnzmXIkCE8+OCDjBs3joULFzJ//vyYsd26dWP+/PmMGTMGs9nM3XffjbfWg4BKKV544QVOPPFEjjnmGKZOnUqPHj0IBoN88803bN++/XeD7m7duvHqq6+yaNEi0tPT+de//sWmTZuiK+JOp5NLL72Um2++mYyMDNq1a8c999xD8AB3ZAy3Wm+D5nLh374dI5IiEiwtJVRZScjjOaDvJ4QQQgixL5KD/QfZTDaclpqycYWm8K10GH+uffqsWbMYNmxYneAa4Oyzz2bLli3RhwefeeYZ+vTpw5tvvsldd90VM/bRRx+lVatWHHfccYwcOZJBgwbVydMeOHAgy5Yto3fv3lx77bX06tWLQYMGMWfOHO6//35uuummfc71tttuY+DAgYwcOZLjjz+ehIQEJk6cGDNm+vTpDBs2jLPOOothw4bRq1cvjj/++D92c36HnpAQbk6TkhLdZwQCBIuK2HXXXYSkC6QQQgghGoCsYP8J6fZ0KnwVAJRoOhkEMRNun261d/lD13znnXf2eqxLly4xec0XX3xxzPFrrrkm+jorK4tPP/005vgVV1yBy+WK2ZednV2nxvaeOnXqVG8+dUpKCm+++eY+z01ISODFF1/kxRdf3Oe4A0XpOpbMTIIuF/6dOzEiqTslr7xK5bff0e6hh3D079cgcxFCCCHEoUlWsP8Eh8mB3WwHwAAKIykVB7N9uoiPnpgYXs1OTIzu82/dypbzzyfv0ccwGrENvBBCCCFaNgmw/wSlFOm29Oh2sa4T5OC2TxfxUyYT5g4d0JOTa7pAhkIUPvccm845F89vaxt3gkIIIYRokSTA/pNcFhcWPVzSLgQU6QevfbrYf0opNIeDLu+8jWPQoOh+76+/snncOApnzcI4wA9dCiGEEOLQJgH2n6SUIt1es4pdqJkIcXDap4s/ztyuHR1nz6L1rbeirFYADL+fvH9OZ8ukC/Ft29bIMxRCCCFESyEB9gGQZE3CpIWfFw0qKNHCt9XiLcAIhRpzaqIWpWmkTrqAzm++ga1Xr+h+99KlbBpzJsWvv35Qm+MIIYQQ4tAgAfYBoCmNNHtNWb0CXccALASoKi9svImJelm7dqXTy3NJv+YaiDyYGqqqYvftd7D9yqvQSksbeYZCCCGEaM4kwD5AUqwpaCp8O/1KUR5ZxdYr82VVtAlSZjMZ11xNp1dextK5c3R/xcKFpN11N7vuuJOqJUvkbyCEEEIIsd8kwD5AdE0n1ZYa3c6PrGLb8OKpLGu8iYl9svfuTef5b5Iy6YLoPs3tpuS119hywSTWn3gieY88gmetVBwRQgghRHwkwD6AUu2pKKUA8ChFVeS1US4l+5oyzWajza230vGF5zFndYw5Fti5i8IZM9l0xhg2jjmTwpkz8e/a1UgzFUIIIURzIAH2AWTWzCRbk6PbBZH83j/bPl00jIRBg+j64YcUTbmB5HPPRU9Kijnu/e038qY/wvrhI9hywSSKX3uNoORrCyGEEGIPEmAfYLUfdqzQNNyRVexAWfyr2BdddBFKKZRSmEwmOnbsyJVXXklxcXF0TKdOnVBK8dJLL9U5f+DAgSilmD59enTfpk2buOyyy2jfvj1Wq5V27dpx+umns3z58jrXVErhcDjo1asX//nPf/br8zd3StPwZ2fT9u67yPn6K9r/+2lcI0+NlvYDwDCoWrKE3Xfcybohx7HtmmsoW/ARIa907xRCCCGEBNgHnFW3kmitac8d0z7dF38AduKJJ7Jr1y42b97MzJkzeffdd7nqqqtixnTo0IFZs2bF7Fu1ahW//PILaWk1gb7f7+ekk06ioKCA1157jbVr1zJv3jwGDhxIUVFRzPl33HEHu3bt4qeffuLMM8/kr3/9K6+++mq9c/S18HbjymLBNXw47R97jJxvFtH2wQdJOPZY0Gr+tTH8fio+/Ywd11/PuiHHsXPqVCq//16a1wghhBCHMAmwD4LajWdKNQ0fkfbppfGvYlutVtq0aUP79u05+eSTOffcc/n4449jxkyYMIHvvvuOjRs3RvfNmjWLcePG4axuDQ788ssvbNiwgUceeYRjjz2WrKwsjj32WO68805GjBgRc02Xy0WbNm3Izs7mvvvuIycnh7feeguAoUOHcuWVVzJlyhQyMjIYPHgwAF999RVHH300NpuN1q1b87e//S0m+B46dCh//etf+b//+z9SUlJISUnhxhtvJNSMKnToTifJZ51Jx9mzyF74Ba1v+Qe2ww+PGRMqL6f0jTfZetHFrB82nNyHp+FZvVqqyAghhBCHGAmwDwK7yU6COSG6XZ2L/Ufbp2/cuJEFCxZgNptj9qenpzN69Gief/55ILyi/NJLL3HppZfGjMvIyEDTNN555x0Cgf17f5vNht/vj26/9NJLGIbB119/zYsvvsiOHTsYOXIk/fr1Y/ny5cyaNYuXX36ZW265JeY6//vf/wiFQnz33Xf85z//4bnnnuPxxx/fr7k0FeZWrUi98EI6vzGPLh98QPpVV2Lu0CFmTCAvj6Lnn2fTX8aycdRoCp59Ft/27Y00YyGEEEI0JFNjT6ChPf3Xzxvtva++I4WKknycaW1/d+yCBQtwOp0Eg0E8Hg8Ajz76aJ1xl1xyCVdccQV3330377zzDsnJyRx//PExYzIzM3nyySe56aabmDZtGgMGDOD4449n/PjxHL7HKmy1QCDASy+9xM8//8yVV14Z3d+5c2ceeeSR6PbUqVNp27Yt//73v9E0jR49evDQQw9xxRVXcO+99+JwOABo27YtTz75JEopDjvsMNauXcujjz7K3//+99+/cU2YtUtnMq67jvRrr8WzciWl775H2YcfEqyVeuPbsIH8x58g//EnsPfrR+LoUSSOHIkpJaURZy6EEEKIg0VWsBtYvO3Tjz/+eFasWMHixYu59tprOe2007juuuvqjDvllFMwDINPPvmEWbNmcckll9R7vauvvpp169Yxd+5chgwZwttvv80RRxzBf//735hxU6dOxel0Yrfbufrqq7nxxhu54ooroscHDBgQM37NmjUcc8wxaLXykocMGYLP52P9+vXRfYMGDYqWMAQ45phj2LFjB2VlLaNGuFIK+xFH0Ob228j5ciEdnvsPiaNHo+z2mHHu5cvJvede1h13PNv+eiWl779PyO1upFkLIYQQ4mCQALsBBYm0Ty/7/fbpDoeD7OxsevfuzZNPPklVVRX33ntvnXGapnHhhRfywAMP8Pnnn3PhhRfu9Zoul4szzjiD+++/n5UrVzJs2DBuv/32mDF///vfWbFiBVu2bKGiooJp06bFBM8JCQkx4w3DiAmca9vb/pZOmc04jz+ezH9Oo9uir2n3z2kkHH9ctC07AIEAFQsXsvOGKawbPISdN99MxdeLMPYzhUcIIYQQTc8hlyJy9bPDG+y9DMNgfcl6fMHwA3/FgQDpoRB6VT5GUvp+BaB33nknI0eOZPLkybRr1y7m2CWXXMIDDzzAaaedVufY3lSnaixbtixmf1paGtnZ2XHPq2fPnrz22muEQqFoIL5o0SIsFgtdu3aNjvvhhx9igvHvv/+edu3akZiYWO91WwotIYGk0aNJGj2aQGEhZR8uoOzdd3GvXBkdE6qqovTtdyh9+x309HQSR44kafQobL17H7JfUoQQQojmTFawDyKlVExd7EJdJ0R1+/T9a1AydOhQDj/8cO677746x7p06UJBQQGvv/56veeuWLGCMWPG8NZbb7F69WrWr1/PrFmzmD17NmedddZ+zWNPV111FTt37uSqq65izZo1vP/++/zjH//gmmuuieZfA+zcuZPrr7+e3377jXnz5vHPf/6Tv/3tb3/qvZsbU1oaqedPpNOrr9D1449Iv+5aLJ07x4wJFhRQ/N//svmcc9l46kjyn3oa35YtjTRjIYQQQvwRh9wKdkNLtiaTV5VHMBQkoBRlmkZyKIRRngfO5P261t///ncuvvhibr755jrHUlNT93pe+/bt6dKlCw8//DBbt24lFArRsWNHpkyZwj/+8Y/9/UgxMjMz+fDDD7nxxhs54ogjSE5OZsKECTzwwAMx4yZOnEgwGOToo49GKcWll156yAXYtVk6diTjqqtIv/JKPL+spuzddyn94H2C+QXRMb4tWyh46ikKnnoKW58+JI0aReJpIzGlp+/jykIIIYRobBJgH2Sa0kizpZFXlQeES/YlhULR9ulWe0Kdc1544YV6rzVhwgQmTJgAwObNm/f5vrWPp6en89hjj1FeXo7L5YrrnPosXLiw3v3HH388P/zwwz7PNZlMPPXUUzz11FP7HHeoUUph73U49l6H0+qmG6n8/nvK3n2P8k8+IVRZGR3n+eknPD/9RO7DD5NwzDEkjR6F68QT0RLq/v4IIYQQonFJgN0AUmwpFLgLCBkhvEpRoTRcRohAWS5We5fGnp5oIpSu4xw8GOfgwYTuupOKL76g9N33qPj6a6iuRR4MUrloEZWLFqFsNlwjRpA4ehTOwYNRe9RJF0IIIUTjkAC7AZg0Eym2FArd4eohBSYNlz8UbZ9utlgbeYaiqdFsNhJHjiRx5EgCxcWUf/Qxpe+9i/vHpdExhsdD2fvvU/b+++gpKSSOPJXEUaOx9ztCHo4UQgghGpEE2A0kzZZGkacIwzCoUhpVSuHAoKo0F3NGx8ae3kG1t9QSER9TSgop488lZfy5+HfsoPS99yl7712862rqjAeLiyme+zLFc1/G3L49iaNOJ2n0aKy1KrkIIYQQomFIFZEGYtbNJFmTotvV7dPtf7B9ujg0mTMzSb9iMp3feYfOb80n9dJLMLVpEzPGv307hc/+h42nj2LjX/5C4ezn8efmNdKMhRBCiEOPBNgNKN1WU/2hXNPwKIVOCHeJBD9i/yilsB12GK1vvJHszz+j45w5JJ89Dm2Ph1i9q9eQN20a64cOZcvFF1PyxpsEy8sbadZCCCHEoUEC7AZkNVlxWWoCoEI9fPst3sK42qcLUR+laSQcPZC2995LzjeLyPzXk7hOPhllsdQMMgyqvvueXVOnsm7wELb/3/WUf/opIZ+v8SYuhBBCtFCSg93A0u3plPvCK4glmk4GQSwEqCwrJCE5o5FnJ5o7zWIh8aSTSDzpJIJlZZR//DGl775H1eLFYBgAGD4f5R99RPlHH6ElJZF48skkjh6F48gjUZp85xZCCCH+LAmwG5jD7MBhdlDlrwLC3R3bBoN/qH26EPuiJyaSPG4cyePG4d+9m7L3P6D0vffwrlkTHRMqLaXk9dcpef11TG3bkjTqdBJHjcbWvVsjzlwIIYRo3mS5qhGk22tysUt0jQB/rH26EPEyt2lD2qWX0GX+m3R5713SrrgCc2ZmzJjArl0UzpjJpjFj2HjGGApmzMC/c2cjzVgIIYRoviTAbgROsxOrKVz7OoSiKFJRxCj/4w87zps3T1a/RVys2dm0+tv1dP30E7Lm/o/k8eeiJyXFjPGuXUv+I4+yfvgItpx/AcWvvkawVL4ACiGEEPFo9gG22Q1GsHk9IKiUiqkoUqRrhCDaPr3a8uXL0XWdwYMHN8IsRUunlMLRvz9t77qLnK+/ov2//03iaSNRNlvMuKoff2T3nXeydshxbLv6GsoWLCDk8TTSrIUQQoimr9nnYGt+RelHm0k+rXm1HE+0JpJXlYc/5CeIoljTSAvFtk+fMWMGV111FS+++CJr1qyhR48ejTxr0VIpiwXX8GG4hg8jWFFJ+aefUPbue1R+9x1UV7jx+6n47DMqPvsMzekksXdvSisrcQwYgHmPWtxCCCHEoazZr2ADVHy1A/evRY09jf2iKY00e1p0u1DXMQB7oBS/z4vb7Wbu3LlcfvnljBs3jlmzZsWc/+KLL5KVlYXD4WDUqFHk5ubGHN+wYQNjxoyhTZs2JCQk0L9/fz788MOYMZ06deKee+7hoosuwuVy0aFDB1599VVKSkoYP348TqeTnJwcPv7444N2H0TTozsTSD7zTDrOmknOlwtpfest2Hr1ihkTqqjA/t137LxhCuuHDmP98BHsuPEmil95Bc/atVJ2UgghxCGtRQTYAMWv/UagxNvY09gvydZkdC2cf+1XijJNQ1PgLc1l3rx5ZGVl0adPHy644AJefPFF/H4/AD/88AMXXXQRkydPZsWKFYwePZo77rgj5toVFRWMHDmSTz75hJUrVzJ27FjOP/98fv3115hxjz/+OAMHDmTZsmWcc845XHjhhUyYMIHTTjuNFStWcPzxx3P++efjkZSAQ5IpI4PUSZPoPO91unz4AelXXYW5Y8c64/w7d1L27rvsvutuNp0xhrWDjmHbFX+l4LkZVC1dSsjbvP7dFEIIIf6MZp8iQuS5vlBVgKKXfyVjcm+UvvfvDY+cO6qBJlbXDa++F7OtazqptlTyq/KBcPv0xFAIu7+YGTNmcMEFFwBwwgkn4HA4eOeddxg7dixPPPEEI0aMYOrUqQB069aNJUuWxKxy9+3bl759+0a3p06dyltvvcW8efO47bbbovtPOeUUrrrqKgDuvvtuHn30UbKzs5k0aRIAt99+O7Nnz2bVqlUceeSRB+GuiObC2rkzGdddS/q11+D56SdWzXmRVkVFuFeuxHC7Y8aGysqo+PJLKr78EgBlNmPr1QvHgP7Y+w/A3u8ITCkpjfExhBBCiIOu2QfYfocRXocPgW9LGWWfbCHp1M6NPa24pdpSKXAXYBgGHqWoVIrdGzfz7bff8sorrwDhh9EmTpzIzJkzGTt2LGvWrGH06NEx1znmmGNiAuzKykruvvtu3nvvPXbt2oXf78fj8dCvX7+Y8/r06RN97XQ6cTgc9O7dO7qvdevWAOTlSTt3EaaUwt63L5VnjCZr6FAMvx/Pr79StXQp7qXLqFq2jGBhYcw5ht+Pe/ly3MuXA+HfU0t2Vxz9B4SD7gEDMGdmSiUcIYQQLUKzD7BDOiSelEXZR1sAKF+4HWvnJGzdUxt5ZvExaSZSrCkUecI55AW6zsyX3yIYDNKx1l/FG5EufNu2bYu+3pcpU6awYMECpk+fTk5ODg6Hg4kTJ+LbozW22WyO2VZKxeyrDnhCklMr9kKZzdh798beuzdcdBGGYeDfsoWqpcuoWrYU97Ll+DZtqnOeb/0GfOs3UPLaawCYWrXCPqB/NOi2duuGMjX7/0QJIYQ4BLWI/3u5TuiAd2Mp3nUlABS99hut/69/vWP3TNNoCtLsadEAuzQU4oXX3+PBW65l+KhxOBJrvihccMEFPP/88/Ts2ZPvv/8+5hp7bi9atIhJkyYxduxYADweD5s2bZJKJOKgU0ph6dQJS6dOJI/9CwCBwkLcy5dHg27PL6shEIg5L5CXR/mHCyj/cAEAmsOB/YgjwkH3gAHY+/RBczga/PMIIYQQ+6tFBNhKU6Se253cJ5YTKvcRqgxQ+PJvcJz5909uAiy6hSRrEqXeUr765CsKi0q4fMJZJKSmY23bI7qKPH78eJ555hnmzp3LkCFDePDBBxk3bhwLFy5k/vz5Mdfs1q0b8+fPZ8yYMZjNZu6++2688qCZaCSmtDRcJ56I68QTAQi53bh/+hn3sqVULV2Ge/lyQpWVMeeEqqqo/PZbKr/9NrxD17H17Imjf//ISnd/TOnpe76VEEII0ehaRIANoDstpI7vTsHMn8EA36ZSQkclN/a04pZuT6fUW8qb/3uTo4YchTMtBavhxV1Zit2ZDMDZZ5/NP/7xDyoqKpg1axZ33nkn99xzD0OHDuWuu+7i2muvjV7v0Ucf5dJLL+W4444jJSWF66+/noqKikb6dELE0ux2Eo4eSMLRAwEwgkG8a9eGg+1lS6n6cSmBPfP+g0E8P/+M5+efYc4cACxZWdgHRPK4+/fH0qmT5HELIYRodC0mwAawdU0mcURHyj7dCkDIEyDkCaDZmv7HtJlsOC1OnnrpKQAKQ0HaBYIY5bkQCbC7dOkSk3998cUXx1zjmmuuib7Oysri008/jTl+xRVX4HK5otubN2+uM489g3CbzRZXzrcQf4bSdWw9emDr0QPOnxjO496xMxxsL1uGe+kyvOvW1TnPt2ULvi1bKH3zTQD01FTs/ftF87htPXqgLJaG/jhCCCEOcU0/8txPruEd8W4qxbuhFIBAkQdza8c+S/c1Fen2dCp84QC3RNPJIIjDqMLrrsRqT2jk2QnRcJRSWNpnYmmfSdIZZwAQLCmhasWKaKUSz08/YURqw1cLFhVR8elnVHz6Wfg6Nhv2Pn2iD0/a+x2B7nQ2+OcRQghxaGlxAbbSFKnjDyP3iWXhHSGDQJEHU7q9yf/VscPkwG624/a7MQh3d2wTDBIo243V3rWxpydEo9KTk3ENHYpr6FAAQl4vnl9+qSkPuHw5odLSmHMMj4eqxYupWryYQgBNw9q9O47+/WvKA0ZKUQohhBAHSvMPsOvJXtBdFlLP7U5h/ubwEG+QULkPPdHasHPbT0op0m3pbPNvA6BY18gIBrEHyvD7vJgtTXv+QjQkzWoNB8r9+8PlYIRC+DZsqCkPuHQZ/h07Yk8KhfCuWYN3zRqK//c/AMyZmdGHJu39+2PNzkZpTf9vvIQQQjRdzT7A9pRCRbEHZ4otZr8tJwWtfHt0O1jmQ1n0Jp+P7bK4sOgWfEEfIRRFukZGMERVaS7mjLotqoUQYUrTsObkYM3JIWX8uQD4c3NxL1sWDbq9v/4Ge9R09+/YgX/HDsreeRcALTERR79+0Ycnbb16oVnly60QQoj4Ne1oMw5GCN57+if+MqU/lj2CZ81mQll1DG8QgECxB3Orpp2PrZQi3Z7OzoqdABRpOmnBcPv0YLAdut7s/5EJ0WDMrVtjHjmSxJEjAQhWVOBesbKmPODKlRgeT8w59bZ57907WqnE0a8fenJyQ38UIYQQzUiLiNYKt1fwyaxfGHllHzStVp61AlOKDX9eFYQMCDaPfOwkaxJ5VXkEQgECSlGiaaSGQlSU5OFMa9fY0xOi2dKdTpxDBuMcMhgIt3D3rFlTUx5w6TKCRUUx5xh+P+5ly3AvWxbdZ83Jxl7d5r3/AMyZ7Zr0f1OEEEI0rBYRYANs/rmQb+etZ8g5OTH7lUnDlGojUOAGqvOx/eiJTbd0l6Y00uxp5FbmAuGHHVNCIazeQkKhNmiSHyrEAaHM5nCVkT594OJwm3ff5s3RtBL30qX4tmypc5533Xq869ZT8uqrAJhat44pD2jt3h2l6w39cYQQQjQRzT7ANtVKvV75+TaSW9vpdUL7mDGazYTmshAq9wEQLPOirBqatel+/BRrCvlV+YSMED6lKNc0EkMBKssKSUjOaOzpCdEiKaWwdu6MtXNnkseOBSBQUEDV8uU15QFX19PmPTc3ts17QkJNm/f+A1B7pKEIIYRo2ZpuhBknswO69Mtg4/J8AL56dR2J6XY6Hp4WM05PtGB4gxi+SD52UdPOx9Y1nVRbKgXuAgAKdA1XKIRelY+RlC5/HS1EAzGlp5N40kkknnQSEG7h7v7p52ilEvfy5YSqqmLOCVVWUvnNN1R+8w0ArYB1badhzc6u9dMVS9dsdKfUuBdCiJam2QfYACde3JO3ipaRt6UcI2Tw0YxV/OXGATFjlFKYUvfIxy72YkqzNdlgNdWeSqGnEMMwcCuNKqVIMLy4K0qxu5Jjxs6bN4+zzz5bui4KcZBpDgcJg44mYdDRABiBQLTNe3XQXafNOxDYtYvArl1Ufv11zH5Tu7ZYu0rgLYQQLUmLCLDNFp3TrurDvId+pKLYi88T5P2nf2LAxOSYccqkYUqxESiM5GN7AoQq/OiuppmPvWrlKo488kj6DOjDSx+8RIGukxAIYFTkwh4BthCicSiTCVvPnth69iT1gvMjbd531ORxL1uGZ8MG1B7lAasFdu4isHMvgXd2dk3wnZONpUtXCbyFEKIZaNAAWyl1KvAEoAMzDcN4aI/jQ4G3gU2RXW8ahnFPPNdOSLJy+tV9ePOfy/B7g5QXefCU+zBCBqpWZRHNbkJzWghVRPKxS73h+tjWpvdA0owZM7jiyiv474v/ZcPaDXTt1hW3UtI+XYgmLNzmvT2W9u2jbd4Xfvopx3TqhHd9+OFI74YNeNevw7d5S5187mrRwPurvQTe2TlYu3bFmpONtWtXtAT574EQQjQVDZaArJTSgaeBkUBP4DylVM96hn5tGMYRkZ+4gutq6e1dnHzZ4VRnfAQDBmWFnjppE3qSBWWpCagDRR6MYP2rS43F7XYzd+5c/jr5r5x+5um8+b83gXBFEYAXZz5DVlYWDoeDUaNGkZubG3P+hg0bGDNmDG3atCEhIYH+/fvz4Ycfxozp1KkT99xzDxdddBEul4sOHTrw6quvUlJSwvjx43E6neTk5PDxxx9HzwkGg1x66aV07twZu91OTk4O06ZNIxRZnfN4PPTq1YtLLrkkes7OnTtJT09n+vTpB+VeCdHkmUxYs7NJPPVUMq69hvaPP0bX997jsGVL6fLeu2Q+/hjpV1+N65RTsGR3BdPe1z6qg+6i2bPZNXUqm885l98GHMn64SPYOnkyudP+Scmb83H/9BOhysoG/JBCCCGqNeQK9kBgvWEYGwGUUq8AY4DVB/JNOvVOZ/DZOSx6bR0A3io/laUazuSaTmx187FDTS4fe968eWRlZdGnTx8uvvBiJoyfwPW3XU+p2czmZT9zxf/dxF133cn48efxxRdfcOutt8acX1FRwciRI7nvvvuw2+28+uqrnH/++fTp04fDDjssOu7xxx/nvvvuY+rUqTz77LNceOGFDB8+nPHjx3Pffffx4IMPcv7557N161ZsNhuhUIjMzExee+01MjIyWLx4MZMnTyYtLY1LL70Um83G3LlzGThwICNHjmTcuHFMmjSJvn37csMNNzT0bRSiSVMWSzT3mlNr9hs+H74tW8Ir3evWh1e+N6zf54q3f+dO/Dt31lnxNrdrhyUnNtXE2qWLrHgLIcRB1JABdiawrdb2duDoesYdo5RaCewEphiG8cv+vlGfYe0pza0Cwk/2V5V60U0Ku9PC9n98ve+TD6L2Dx0X99iZM2dywQUXAHDy8JOx2+0sXLCQk0afxCOzX2HEkIH8/cqLcWZ0pFu3bixZsoRZs2ZFz+/bty99+/aNbk+dOpW33nqLefPmcdttt0X3n3LKKVx11VUA3H333Tz66KNkZ2czadIkAG6//XZmz57NqlXhfHCz2cw999T8xUKnTp1YtmwZL7/8MpdeeikAffr04aGHHmLy5Ml89913LF++nJ9++qnJfHkRoqlTFku07Xu9gff69XjXb4j8uT5cq/v3Au8vv4rZHw28q/O8JfAWQogDpiED7Pqiqz1LXiwDsgzDqFBKnQa8BeTseZJSajIwGSAjI4OFCxfWvXBrA6UnR7fLCz14fY1bi7a8vDyucRs2bOCbb75hxowZ0XPGnTOON156g5NGn8Sv6zYx9sTjsPuKKS1NQtM0+vXrF/MelZWVPPTQQyxYsIDc3Fz8fn80faN6jGEYdO/ePWZeDoeDnJyc6D6HwwHA5s2b6d69OwCzZs3ixRdfZOvWrXg8Hvx+Px06dIi5ziWXXML8+fN57LHHmDNnDomJiXF//gPN4/HU+zuyNxUVFfs1/lAl9yl+B/xe2e3Qu1f4ByAQQM/Lw7RzF6ZdOzHt2o1p5070vLy9Ply5t8A7mJZGoG3b8E+78J/BNm0wbLZ6r3Mgye9U/ORexUfuU3zkPh14DRlgbwc61NpuT3iVOsowjLJarz9QSv1bKZVuGEbBHuOeA54DyO7c0Rg6dGi9b7h69Wp0s0bQH/4fjL+ycVdQXS5XXONeeeUVgsEgPXvWpKhX55Hv2rELwzCoUgpdhdADlTjT2mGL/M+v+j1uuukmFixYwPTp08nJycHhcDBx4kQMw4iOUUrhdDpj5qWUwuVyRfeZzWYAbDYbLpeLV199lX/84x9Mnz6dY489lsTERJ5++mnmz58fc538/HzWrl2Lruvs2LEj7s9+MNhstugXkHgsXLiQvf1OiRpyn+LXWPcqZsU7mmqyAd/mzRAM1nuOXliIXliIddWqmP3mzEys2dlYsruGH7DMzsbatQta5Ev4gSC/U/GTexUfuU/xkft04DVkgL0EyFFKdQZ2AOOBCbUHKKXaALmGYRhKqYGEH8Is3NdFNVMe65YuIGfAqXWOKaVIbuWgeHcloaCBETKwX9uPlDYOtFoNZoxACH9uFUSCWM1uQk9tnHzsQCDAnDlzePDBBxk1alTMsQnnT+Ctl9+ia/eu/LD8Z4IQbZ/+/fffx4xdtGgRkyZNYmykG53H42HTpk306NHjT81v0aJFHH300VxzzTXRfRs2bKgz7rLLLqNr16489dRTnHfeeZx88skMGDCgzjghxMETk2oysma/4fPh3bwZX0yO974Db/+OHfh37IAvv4zZ3xCBtxBCNDcNFmAbhhFQSl0DfES4TN9swzB+UUr9NXL8WWAccKVSKgC4gfHG73ROUZrB2s03kJjWkdad6hYl0U0aSRl2inPdYBgEAyFK890kt3ZEA2hl0tBTrASLwikkIXcAVelHdzZ8fez333+fgoICLr/8ctLSYrtRThg/gaf+/RQPPfsQk0ZN4s6nnufC00bw0eufMH/+/Jix3bp1Y/78+YwZMwaz2czdd9+N1+v90/Pr1q0bL7zwAh9++CHZ2dm88sorfPnll6SkpETHPPvssyxcuJAVK1bQuXNnLrroIiZMmMDy5cujKSdCiMajLBZs3bph69at/sC7vhzvPxh4W3OysVTneUvgLYQ4RDRoHWzDMD4APthj37O1Xj8FPLW/17WlePjhmwsZkbyAhOS0OsfNVhOJaTbKCsINZvzeIOWFHly1qoboDjOGN0io0g/Uqo9dq5xfQ5g1axbDhg2rE1wDnHPOOdxyyy1UVVZxz+P38O9pT/PIY89x/DFHceedd3LddddFxz766KNceumlHHfccaSkpHD99ddTUVHxp+d3xRVXsGLFCiZMmIBhGIwdO5YbbriB2bNnA/Dbb79xww038Mwzz9C5c2cgXKmkf//+/O1vf+M///nPn56DEOLgiAm8awn5fPiigXdN8B1P4F1RO/BWKhx4R+p3W6rreXfpLIG3EKJFUc29tXb37lbj38+0B6BqezYjz3sPUyRveM2aNTEpEZWlXipLalZxE5KtJCTVlO8zQgaB/CqMSM42Jg1zK0dMo5rGFjJCrC1eSzAU/p9aZiBAciiE29W5Tvv0PZWXlzdqLnRj2fP34PdILlp85D7Fr6Xeq5DPh2/TZnwb1sc00dlX4F2vSOBdkZxMmz59MLdvjzkzM/LTDj05WaoQ7aGl/k4daHKf4iP3KX5KqaWGYRz5e+Oafav0UNAZfe1ov57PXpvMyRNm1/sfY0eihaA/hCeySl1Z4kU3adgSwgG50hR6qp1AXiQfOxAiWOxptHzs+mhKI82WRl5VHgAFuk5SKCTt04UQDU6zWLB174atez0r3nsG3uvX49u6tf7A2zDwb9+Odft2ivd4uBJAS0ioFXBHftpnYom81hITm8x/o4UQAlpAgK3p6ZgCPQiYfgZAb/0V3753P4NH31ZnrFIKV5qNYCCE3xv+j3xZoQfdpGGOtErXzE0nH3tvUmwpFLgLCBkhvEpRoTRc0j5dCNFE/F7g7V2/LuYBy70G3tXnVVbiXbsW79q19b+f01lr1btdOPCutQquH4J/cyeEaFzNPsAGGDx8Lgs/HoGy5aE0qDTN4ZfvuqEl964zVikVfuhxdxXBQAgMg9L8KlLaJKCbwpVFmko+9t6YNBMpthQK3eECKwUmDZc/RKBsN1Z710aenRBC1G/fgfcmln/wAd2SkqP52/4dO/Dt2IFRVbXP64YqKvD++iveX3+t/30TE2tWvNtVr4DXCsCdsjAhhDiwWkSAbTI5OPaEeSz66hR0qxvdGmJr3p20T3i53vGarpHUKhxkGyGDUNCgNK+K5DYJaJF8az3JiuELhvOxDQgWeVBNKB87zZZGkacoUhNbo1Ip7IEy/D4vZov19y8ghBBNRDjw7o531y7S9sgDNQyDYEkJ/u3VQff2aODt37ED//YdGJ59NxELlZXhXV2Gd/Waeo/rSUl75H1HVsLbt8fcrp10txRC7LdmH2AHIu2BHQmZ9O//PMtXTkQzBbG4fPh9RQT9PnRz3fQOk1knKcNOSW54ZSTgD1GW7yaplR2lVCQf20YgL1zezwiECJZ40VOsTSLXz6ybSbImUeIpAaBQ1+loBKgq3Y05I6txJyeEEAeIUgpTSgqmlBTs1Z0razEMg2BRUc2K9/btkdc7o/uM3ylRGiwtJVhaiueXX+o9rqek1Fr1boc5M7MmDaVdOzS7/YB8ViFEy9HsA2y32x2tEpHe+ii6Zt3Lxu23ohQoPUR52UYSU7qhaVqdcy02E640G+WF4dUPnydARbEXV2q4K6Jm1tGTrQSLI/nYVX6UVUePPBTZ2NJt6dEAu1zT8CiF3VdCMJCJbmr2/2iFEOJ3KaUwpaVhSkvD3qdPneOGYRAsKKhZ9d6+IyYFxb9jB4bfv8/3CBYXEywuxlPPA5gAelpaOOhun1n3Ycx27dAaoM28EKJpaRFR2Jtvvskll1xC27Zt6dL9XMpL1lFQ+TwAmtlPefEmElO71LvybHeGK4tUlfkAcJf70E0ajsTwqreeEMnHrorkY5d4URYNzdz4+dhWkxWXxUW5rxyAQl0j0whSUZqHM61dI89OCCEan1IKU0YGpowM7EccUee4EQoRyC+oFXBvj8n/9u/cBb8XgBcWEiwsxPPTT/Ue1zPSsdST+129Gq5Zms5D9EKIA6NFBNh+v5+5c+dy+eWXk5iYSJ+BU/nms3XR48pcRUXJDlwp7es9PyHZSjBg4I0E0RXFHnSTwuoIr1TryZF87MhDkcHCppOPnW5PjwbYpZpOBsFo+/T6Vu2FEELUUJqGuXUrzK1bQf9+dY4bwSCB/Py9p6Ds2gWRVMW9CeYX4M4vwL1yZb3HTa1axZQfjKagZGZibtsWJQG4EM1Osw+wq1ely8vLefnll7n44ouxWCwcO3wmK1d8Ex1naMVUlVtxuDLqvUZimo3iQIiAL1K+r8BDchsNs0UP52On1c3HNqU2/l/7OcwOHGYHVf4qDMK52G2DASrLCklIrvtZhRBCxE/pOuY2bTC3aQMDBtQ5bgQCBPLy9p6Csnv37zbdCeTlEcjLw718eT0TUJhat45Z8bZkZmLJzcPTti2mVq2kEY8QTVCzD7Dt9vBDiYZhsGvXLubPn8/ZZ5+Nppmx2jIwQgqlBUGBP7gbr9uK1Z5Y5zpKU+HKIruqCAVDGIZBaZ6blDYOdJNWbz52sInkY6fb09nq3wpAia6REQyiV+VjJKXX+Y/uNddcw6pVq1i4cGEjzFQIIVoWZTJhbtcOc7t2OI46qs5xIxDAvzu3JuDeXisFZecOArtzIRTa+xsYBoHduwns3o176dLo7hRg07/+Fd4wmzFlpGPKyMDcqlU4Jab6z1qv9ZQUlPzNphANotkH2Lquc9ppp/H+++8D4bbYn3/+OSeeeCJKaSQ4O1NZuR6lDJQGHs82dFM2JnPdUna6rpFcXb7PMAgFQ5Tmu0lu7UDTFJrDhOE1H/R87Isuuog5c+Zw7733ctttNQ1zFi5cyLBhw8jPzyc9PT2632l2YjVZ8Qa8hFAU6Tqtgl7cFaW/2z5dCCHEwaNMJiztww9A1sfw+fDn5u41BSWQmxvuLLwvfj+BnbsI7NzFPgsWmkyY0tNrgu9WGbFBeSQY11NTJRAX4k9q9gE2wFFHHUVBQQE//PADAIsWLSI9PR2r1YrJZMNu64DHG17hVXqIivKNJCZ1Q9PrBsYmi05ihp3SvEj5Pl+Q8kI3ienhlfI6+dhFHlTGgc/HttlsTJs2jSuuuIKMjH2neiilSLels6NiBwBFukZ6MCjt04UQoolTFguWDh2wdOhQ7/GQz0dg167YFJSdOylY+xtOfzg9JVRREd+bBQLR1fB90vVwIF57JbxVRt2V8bQ0VD3/HxVCtJAAG+CUU06hqKiIdevCDze+8847nHXWWQBYrEkEA63xB3MB0EwByks2kpiaXW/emtVuwplqoyLSLt1bFaCyxIszxVZTHzs/ko/tDxEs9WJKObD52MOGDWP79u3ce++9PPnkk3WOB4NBJk+ezOeff87u3btp3749Z048k0lXTQJNo1jTSPaX87frr+OFOf8F4LzzzsPYYyVkwYIF3H///axatQqlFEcddRSPP/44PXr0AGDz5s107tyZl19+mWeeeYbFixdz2GGHMWfOHDRNY/LkyaxcuZJ+/frx3//+l86dOx/Q+yCEEIcyzWLBkpWFJSuL2u1u1i1cSN9IU55QVRWB/PzwT15e9LW/+nVeeDtUVhbfmwaDBHJzw6vn+5ycFi6RuGdayp5/pqWipHSsOMS0mN94TdMYN24cs2bNIi8vj1AoRGVlJYFAAJPJhD2hFcEyDyFKAVBmD+UlW0lMqb8pi8MVLt/nLg+X76sq86GbNexOC5pFR0+yECwJNy8IVUbysR0HLh9b0zQeeughzjzzTP7v//6Prl1jW6CHQiEyMzN57bXXyMjIYPHixVw++XJcyS7Gnj+WQl1n5lOzmT37eWbMnEWfPn147LHHePnll+nfv3/0OpWVlVx//fX06dMHt9vNfffdx+jRo1m9ejWWWk+u33nnnTz22GN06dKFK6+8kgkTJpCRkcH9999Pq1atuPDCC7nuuut49913D9g9EEII8fs0hyMahO9LyOOJDcTz8gnk1/ozPx9/Xj6h0tL43jgUil5v3xPU0NNSw+koGa0iq+GRP/dcETc3/nNNQhwILSbABrBarUyYMIEZM2ZQWVmJYRgUFRWRnp6OpmkkuDpw992zG21+d911136NP+200xg8eDBTp07llVdeiTlmNpu55557otudOnXix6U/8uH8Dxl7/lj8SvH4zJe58cpJnHXmGZgt4ZSTL774IuY6Y8eOjdl+/vnnSUxMZPHixQwZMiS6/+9//zunnXYaADfccAOjR4/mjTfeYNiwYUD44clrrrlmvz6fEEKIhqPZbPtMR6kW8noJ5BfUrIbv+WfkdbCkJL43DoUI5hcQzC/AS/3t6gFQCj01NRJ01+SK13lwMz1dAnHR5LWoABsgOTmZ8ePH88ILLwDhVupFRUWkpaU1yzJG06ZNY9CgQUyZMqXOsWeffZaZM2eyZcsW3G43fr+f9h3Dtb7Ly8rZnZvPMQP64C3NxZyRhaZpHH300Wzbti16jQ0bNnD77bfzww8/kJ+fTygUIhQKsXXr1pj36lOrQ1rr1q0B6N27d8y+yspKqqqqcDgcB/QeCCGEaDia1brPBzOrhXw+gnumo9RKSakOyINFRfG9sWFEm/Z49xGHA+FAfC854ubq/bWKAQjR0FpcgA3QoUMHzjzzTCoiD374fD5KS0tJSkpq5Jntv6OOOoqxY8dy8803c/vtt0f3v/rqq1x//fVMnz6dY489lsTERJ5++mnmz58f80Widvv0+owePZrMzEz+85//kJmZiclkomfPnvh8vphx5lqrBdXXr29faF/lpoQQQrQYmsWCFmmIY9/HOMPnI1BYGBN0+2NWxcOr5cGiot+vmBIRLCoiWFSE97ff9jkuIyGBDa1bo6emYEpNq/VnKqa0VPTUNEypKehpaehJSfLQpjhgWmSADeHV1eW1ivZXVVVhMpmiaRp+XwVV7k1Ux6JGUMfpykE31f/XTn5vkJLcquhDgmarTnKkm2OwwhfNxwbQU20HNB/7gQceoGfPnixYsCC6b9GiRRx99NExaRkbNmwAIMWagpFokNE6g4XLV3H64KOoKM3DMDtZvHgxbdu2BaCwsJA1a9bw9NNPR1M9li1bRuB3upIJIYQQ8VIWC+a2bTFH/t+zN4bfT6CoKDYlJSZPPB9/fh7BwqJ91w6vRausxLdxI2yMZ6IKPSUlNghPTQ3nj6fuEYynpIQDcilnKPaixQbYEC51Z7PZ8HjC1UDKysowmUzYbDbMFifWQDt8gZ0AKD1IRdlGEpNz6v0XxmzVSUy3UZrvBsIBd3mRB1eaDS3BjOENEnKHA9NgsRfNoqNMB+ZfvOzsbCZPnswTTzwR3detWzdeeOEFPvzwQ7Kzs3nllVf48ssvSUlJIc2eRpGniPMnn89/npjJEZ070Ld7d55++UN27doVDbBTUlJIT09nxowZdOjQgR07dnDjjTdikqe9hRBCNDBlNmNu3RpzJA1xb4xAgEBhUb154TF/FhTEHYiHL2xEV8Z9bPj98bqOnpISCb6rg/FIEF69Wh4Jxk1paWguV7NMVRV/TIuPpJKTkyksLMTvDzeHKS4uJj09HbPZjM2RRrDcQ9AI54cpk4/y0s24kjvXX77PYSYhOURlZLXaU+lHN2skJFnRU2yE/FUQqY8dKPRgamU/YP8y3XHHHcyZMye6fcUVV7BixQomTJiAYRiMHTuWG264gdmzZ2PRLSRZk7jwqgspyCvgqin3ojA4Z9w4Jk6cyJo14eQ2TdN49dVXue666+jVqxfZ2dk88sgjdR58FEIIIZoKZTJhbt0Kc+tWwOF7HWcEg3z1wQcMOuwwAoVFBIuLwn8WFREoKiRYVBz+M7IvGG/1lGrBIMGCAoIFBfGNN5sxpYRXwKN/7iUY11NT0RISJCBvxlp8gK1pGqmpqRQUFBAMBmMqi+i6ToIrk/JSL4aqDJ+gV1JZthNnUv05y45EC8FACE9FOGCvLPGimzRsCWZMqTYC+VVggOEPhutjJ+9/fezqBzRra9WqFeXl5TH7Zs2axaxZs2L23XHHHUC4fXqpt5Sb77uZm++7mWy/H2Xo+B2tsSfWPPgxfPhwVq1aFXONilpNCzp16lSndvaRRx5ZZ9+pp55aZ58QQgjRWJSuY7hcWHNysOb8/njD7ydYUkIgsoodDsYLw9uFRQSKi6LBeKCoiNAe/0/+XX5/JO0lD+/vj0ZZLHsPxmsH5ZHUFU0KDDQpLT7AhnA79eog2zAMgsFgtLKIpmk4EztRVroOpYUf7AupItyVVuwJdZ9AVkrhSrURDBj4PeGUkLJCD7pJYbaa0BOtBEsj9bEr/ISsOpq94csJ2Uw2nBYnFb5wsFyoa7QLBLBU7cBftZsqSwrWpFaY62kZL4QQQhxqlNkcrckdj5DPR7C4mGBhIYGi4nqD8eqV8mBhIaGqqv2ajxHp4hnYtSu++dvt0WD8dx/qTE1Fsx3YBnki1iERYEO44kVKSgpFkXJBfr+fkpISUlJSUErD5epKeflalBYEwBfYhe6xYbE561xLKUVSuo3i3VUEIykhpXluUtokoDnNhLxBjEjwHSj2YjYfuHzs/ZFuT48G2CWaTgZBzICZIGZfAaG8Air1RHRXK2wJrgafnxBCCNFcaRYLWhw549VCHk9k9TsSjNeXrlJUHbAXYUSeH4uX4Xbjd7vx79wZ3/wdjmgwnmwY7PzoY/Tk5Pp/UpIxJSejajWgE/t2yATYEH7oMTExkbJIu1iPx0N5eTmJiYlouomEhM5UVm1AKQOlwO3Zgm7KQTfV/YXSdI2kVnaKd1dhhAxCIYOS/CpS2iRgSrHizwtBMAQhg0CRB1PGgcvHjpfD5MButuP2uzGAnaYE2gU8mAl/idAUJITKoLQMT6mNoCMde2J4VV8IIYQQB45ms6G1a4e5Xbu4xoeqqmqlq+yRMx6TT15EsLAQI/KsWbxCVVWEqqrwb9uGFSj96eff/wwOxz6C8JQ6QbmenHzI5pLHFWArpXoCQcMwfotsnwRcCPwCTDMMI3jwpnhgJSQkEAgEqIr8VU1FRQUmkwmHw4HJbMdm7YDXuxUUKC1ERfkGXEnd0LS6tTFNZp2kDDsleeG866A/RFm+m6RW9pp8bMDwBQmW+jAlN2w6hlKKdFs62/zhxjIVmp+tjgSchgWXuwIHNd+ObXigajv+ql1UWVIj6SPyTVUIIYRoDJrDgcXhgPbtf3esYRiEKiujq981gXf9wXiguBj+QEneaFAe5yo5AGYzelISenISenJyOI1lb0F69U9SEqqZVzSLd/azgCeA35RS7YG3gYXA1UAicMtBmd1BoJQiKSmJYDCI1xvOlS4pKcFkMmGxWLDakggGWhEI5YXH6wHKSzeSmJxd7zcwi81EYqqdssJw+T6fJ0BFkRdnqhU9qXY+ti+Sj92wvzAuiwubyYYnEA6mPQEPHjwU23RcejpOjxdXoAJNRep7E8Tsyw+nj5hc4fQRh6SPCCGEEE2VUgrd6UR3OrFkZf3ueMMwCJWVRYPxlV99zWHtMwmWlIR/iktqXlf/lJZC8A+sp/r9+1dtJUJLTKwVdCfVCcJN9ayaa/Z9tTxqWPFGez2AZZHXZwM/GIZxmlJqGPA8zSjAhvAvYkpKCgUFBdGmKtWVRUwmEw5na8pLPRgqnEqidA8VZdtwJXWs93o2p5lAIERVJJh2V/jQzRp215752B7MZkeD5mMrpeiY2JHcylzKvGUYhAPpYChISaiMEh2ctmQcfkj2ldVKHzFICJZBSRnuEhshSR8RQgghWgSlVHhVOSkJOnfGW15OytCh+zzHCIUIVVTEBt3FxeHKK3sG4yWl0deG2/2H5hgqKyNUVoZ/69b4P5fVWm/+eL3BeXVQnph4UBoGxRtg60B17+wRwAeR1xuA+LL7m5jq8n35+fnhb3KhUDTIDlcW6Uh5yXrQwyu/hiqlqiIXh7P+j5uQZCHoD+GtCudAVRSHK4tYUqz484IQNBotH9usmWnvak+JUYLf5KfYU4w/VJOrVeGvpAIosdtxGhYSvVUkGDXpI/Y90kdsSa0wSfqIEEIIcchQmoaemIiemAgd619wrE/I46m7Gr6XlfJASTHBklJCZWXwB0r/Gl4vgdxcArm58Z9U/bniSV1JSY77svEG2KuAK5VS7xEOsKtXrDOB/Vvzb0JMJhOpqakUFhYCEAgEKC4uJjU1FaUUzqQulJeuRemRFehgHl63Das9qc61lFIkptkoCYbwe8OrwGUFHpJbOyL52OFvcIYvSLDMhymp4cvj6Uon2ZFMuj2dcl85xd7iaJURAF/QRxE+SiwaTj0Vp9dHUqACLfJdQNJHhBBCCLE/NJsNrU0bzG3axH2OEQwSLCurP1Wl1sr5nj/7+6AnAKFQ9PwDKd4A+2bgLWAKMMcwjOpHTc8AFh/QGTUwq9VKcnIyJZEb6/V6KSsrIykpCU3Tcbq6UFGxHqWFQIHHuw3dZMFkrpvnozRFUoY9Wr7PMAxK892ktHHE5mOXR/KxbY2TwK+UItGaSKI1EW/AS5G3iBJPCSEj3FI2ZIQoC1RQpkOxNZGEgCLFV4GlvvSR0kj6iEvSR4QQQgjx5yldx5SSgiklJe5zDMPAqKqqm7KytyA98hOq1VzvQIorwjMM4yulVAaQaBhGca1D/wH2r3J6E+RwOAgEAtEOhpWVlZhMJhISEtBNVuz2jrg9m1EKlGZQWbEJV2I3NL3u7dN0LRxk50bK9wVDlOa7SW7tQNXOxy7yYG514PKx582bx9lnn73f3RStJittTW1pZW9Fqa+UIk8R3kBNjyl3wIMbKLFZcGIlyevGadQctxseqNyOv1LSR4QQQgjROJRSqIQEtIQEzJn1d+Ouj+H3Eywt3Uc+eWxOOb/9Gtd1415CjZTiK458CDswGFhnGEZe3J+iCXO5XAQCATyRwu6lpaXouo7NZsNidREMtMUfDHdTUnqQ8rINJCbnoFTdANlk0UlKj5TvAwK+IOUFblxpNgL7kY+9fPlyjjzySAYNGsQ333xzkD55mK7ppNpSSbGmUBWooshTRLm3PPpQZCAUpIQqjjhiKBdePolbrr2ClEAlmoJ7H5vBHdOfYd5z/+Ss006MpI+05tLLr2Dbtm189dVXB3XuQgghhBB/hDKbMaWnY0qv2727/hPie4YuruVTpdQLSqmrIq8thNNCPiZctm9kfDNq2pRSJCcnYzbXtDUvLi7GH8nnsSeko5FaM173UVG6ea/Xs9hNuFJr2pB63QGqynyYau2rzsfemxkzZnDVVVexatUq1qxZ80c+1n5TSpFgTqCDqwM5KTlkODIwaTXfwwYOGcg3X3/Lbt3PBruTXZZEPv9uKR0z2/DFt0ui6SO2knV88fmnDD7maIxQqEHmLoQQQgjRFMSbn3AK8H3k9RmAC2gD3BX5aRGqK4tU5xIbhkFRURHBSN1HZ2ImBB3R8YZWSWX53out210WHK6adImqMh9eXwg9sWZfqNxHyFO32Lvb7Wbu3LlcfvnljBs3jlmzZsUcf/HFF8nKysLhcDBq1Chy93hidsOGDYwZM4Y2bdqQkJBA//79+fDDD2PGdOrUiXvuuYeLLroIl8tFhw4dePXVVykpKWH8+PGkJKUwuO9gNi3ZRHtXexxmBwOHDGTFkhX4vD58IR+7vWV8v+wnrvjb1Xz27dLotddu2MKu3XmcOrA7gd2/UFGwnYB/718mhBBCCCFaingD7BSgOhXkVOCNSGrIK0DPgzGxxqLrerSKCEAwGKSoqCia2+xK7owRqFnlDhqFeKoK93q9hBQr1lrNZcqLPATNOspa0xkyUOTBCMau8s6bN4+srCz69OnDBRdcwIsvvhhdTf/hhx+46KKLmDx5MitWrGD06NHccccdMedXVFQwcuRIPvnkE1auXMnYsWM5//zz+fXX2Nyhxx9/nIEDB7Js2TLOOeccLrzwQiZMmMBpp53GihUrOP7445l0wSSshpXOSZ0ZN3IcHreHVctWAbDyx5UkpSRx8tmnsmHzVhaXecnTE/js2yXYbTYG9e+NmQBOXz5a3moqczfiqTo4DxQIIYQQQjQF8eZg7wZ6KaV2EV7NnhzZ7wT+QE2UxvPZ510b7b17d10OQGmBm5QMO4bfA6Fa+djpNfnYM2fO5IILLgDghBNOwOFw8M477zB27FieeOIJRowYwdSpUwHo1q0bS5YsiVnl7tu3L3379o1uT506lbfeeot58+Zx2223RfefcsopXHXVVQDcfffdPProo2RnZzNp0iQAbr/9dmbPns2qVas48sgjOfyww2nfvj3rl67ntBNPY+m3Szlq8FHYHXZ69u3JV18vIuGskbz3wwoGDOyPYbVDTPWRUigpxV1qJ+RIx+FKPSgF3oUQQgghGku8kc1s4FXC9bCDwGeR/UcD8T1OKdD0cPBshAxKCz3oyTW1sA1vkFB5OIVi/fr1fPPNN0yYMAEI50VPnDiRmTNnArBmzRqOOeaYmGvvuV1ZWclNN91Ez549SUlJwel0snz5crbu0RGpT58+0ddOpxOHw0Hv3r2j+1q3DjfWycureZZ12LBhfLnwS9Lsafz0/U+cOuJUXBYXRx17FIu/CVdt/GHRD/QfciQbrSY2W12UKCu165vYDTcJldsi6SM7CPyR2pVCCCGEEE1QvGX67lFK/QJ0BF43DKM6mTYAPHywJtfSJGU4KMmtwjAMgoEQZWU+XC5LNLAOlvlQFp2ZM2cSDAbpWKtTUnWKyrZt2+IqxTdlyhQWLFjA9OnTycnJweFwMHHiRHy+2Dzo2g91QjiYr72vekU9VOtBxeHDh/PXv/6V4uJifvjhB2bPnk3HxI6cefKZXH/99Wxet5nC/EIGDhmIYRhU4qXSDPlaAq6AQUbAjR4Jt80EMPvyCOXlU2lKxJTYCqvduT+3VQghhBCiSdmfMn1v1LNvzoGdzsE3YviG/RpvGAaFhYUxgWl6ejoWS/hBxcry3QSN/JoTQnZcSV33WnovMd1GaaSro98bpFLXcFh1jEj3R09+BXPmzOHBBx9k1KhRMedecMEFPP/88/Ts2ZPvv/8+5tie24sWLWLSpEmMHTs2fF2Ph02bNtGjR4/9+vz1GTZsGF6vl0ceeYSMjAy6dg2n3Qw9YShbNm/h2/e+xel0ctTAo/AbNSvTvpCfQg2KrVachok0nxvHnukjxaW4S+wYjnTskj4ihBBCiGYo7gBbKdWHcCfHnoABrAam1+rq2CIppUhJSaGgoCBaTaSoqIj09PRwMxpXG8qKPaCXh0/Q3FSWb8eZ2KHe61kdZpwpISqKw81avFV+TC4LZi0EIYMPPl5AQUEBl112Gel71GQcP348zzzzDHPnzmXIkCE8+OCDjBs3joULFzJ//vyYsd26dWP+/PmMGTMGs9nM3Xffjdfr5UDIysqic+fOPPnkk4wZMya6v7payb/+9S+OO+44uqV1wx1wU+QpotRbGl15DxkhyvBRZtGxKxtJfj+pIR/VX0nshhsqt+Gv3IXXkootuRUmk7memQghhBBCND3x1sE+A1gGdAA+BBYQThdZppQaffCm1zTsWVkkFApRVFQUTZtwJWdhBGryqUOU4K7ce/8du8uC3VlTqq+y3EfIEf6u88IrL3LCMceRYnHVOe/ss89my5YtVFRUMGvWLJ555hn69OnDm2++yV133RUz9tFHH6VVq1Ycd9xxjBw5kkGDBtXJ0/4zhg0bRnl5OUOHDo3ZP3ToUMrLyxk+fHj4s5rsZDoz6ZbSjdYJrbHosV0e3Yaf3SZYa7Wz02THT83Kf7j6SB5a7i9U5m7E65bqI0IIIYRo+lQ8+bxKqZ+A+YZh3LnH/nuAMYZh9K3/zIOve/fuxm+//VbvsTVr1hyQlIhqXq+XwsKaknxWqzUaeIeCQcpL16JMkZrWBthsWVisifVeyzAMSvPc+KprYCtITjCDu6YmtinDjmaN+y8Zfld5eTkuV93AvSEZhkGFv4IiTxEVvroBs1IKh2Ei3e/BaQTrHHcrO4YjA3ti6l7TcPa0v78HCxcurPPFQdQl9yl+cq/iI/cpfnKv4iP3KT5yn+KnlFpqGMaRvzcu3gTXbsB/69n/X6D7/kysObNarSQlJUW3vV4vZWVlAGi6ToKrC0YwEvQpcHu2Egh46r2WUorEdBu6OfKPwICyqgCY910fu7lTSuGyuMhKzCInJYc0exq6VvOZww9F+tli1llndZCvWah9B+yGG0flVvy7VlFRuINAQKqPCCGEEKJpiTfAzgMG1LN/AJBbz/4WKyEhgYSEhOh2ZWUllZWVAJjMVmy2LKr/UkApg8qKjYRCdTs1Ami6RnKGA02rTj0xqAiEILJN0CBQ7I2rakhzZNEttEloQ7eUbrRztsNmssUc9xkB8kzwm9XGdpMdb630EQsBnN48VO4vVORuwuuubOjpCyGEEELUK978gxnAf5RS2cC3hB9yHEL4ocd/HqS5NVmJiYkEAoHoQ4OlpaWYTCasVitWu4tgoA0BYzcASgtSUbYBV1K3elMadLNGUis7xbluMAwCgRAei44tUsbO8AQIVfjRXZY657YUmtJIsaWQbE2OPhRZ5iuLeSiyVINSixk7JtL8XhKNIArQlYEzWALFJZHqI/uXPiKEEEIIcaDFG2DfB1QANwD3RvbtBO4EnjwI82rSalcWCQTCq9PVlUXMZjMOVwblJR4MrSR8guajomwzrqTO9V7PbDWRmGajrCBcvs/jC2Ky6pgC4eSIYKkXZdHRarVXb4mUUjjMDhxmB4FQgGJPMcWeYvyhmjQQNwG2m3VMWEgOBkkP+qi+K+HqI1vxVe7EZ03DlpQh1UeEEEII0eDiShExwh4zDKM9kAQkGYbR3jCMJ4wmnr9wsKanaRqpqalokTrNhmFQVFQULeXnTGqPEXDUzENVUFWxa6/XsyWYSUiqqURS4Q1i6DWrsC0xH3tfTJqJDEcGOSk5dHB1IMGcEHM8QJACHX6zWNlqsuFWe6aP5KJyf6F890YC/gNTnlAIIYQQIh773cXDMIxywzDKD8ZkDjSz2Yzb7T5o1zeZTKSmpka3g8EgxcXFGIYRfpgvuTMhf80KaiBUgNddtNfrOZIs2BJqxpf7QlAdOAZDLTofe2+UUiRaE+mU1Ins5GxS7aloqubX1sCgXAux0WxmvcVOkaZHH4rUlYHVX4KtZAM/PziUFZ++TDBQfz68EEIIIcSBstcUEaXUz0Bc0ZxhGH0O2IwOoFatWrFjxw4yMzOx2+0HJS/XYrGQkpJCcXExAD6fj9LSUpKSktA0DVdSF8rL1qGZwmGf17cDzWTFvMeKLEQqbKTaCAZC+L1BQkBl0CChutDIIZCPvS9Wk5W2pra0srei1FdKkacIb6BmddpLkF0mnTzMJAZDpAW85BVXkLT5fXK8y2HRX9nxzZ1syz6fHqddRVJK+j7eTQghhBDij9lXDva8BpvFQZKYGK5BvXPnTvz+g1vOzePx4PHUlOSz2+1YreGUj6Dfj89fiNIiDy4aeVitrdG0+nOqjZBBZZkPIxgeb9GI5hmjQHdaUKb9byHu8Xiw2Wy/P7AZCQQDVPor8QQ8GLW+D+4gvLpdULqOTjs/IgNQQKaRS+a6R6h6/Cl+yDidNideS9Zh/Rtr+kIIIYRogfYaYBuGcXdDTuRgSUxMjAbaB5NhGLz11lusXLkyum/8+PEcdthhAKxZ/Brb8qeiW8Ir2aGqNgw79TNMpvoD3uLdlbwxbSneqgAKGJZqwRUKB5B6ipXW1/VHs+9fE5qFCxfSr1+/P/Dpmr78qnzmrZvH67+9Tr47P/Zg21TahdpzXlEeZ1cUk2AYOJSXowvehFfe5CfbAIyBk+l9wtloest+kFQIIYQQB9/+L4OKeimlGD16NB07dozue+ONN9i1K/xgY4+B5+AMXYgRSRDWHLv55rMJe82pTmmTwKlX9EbTFAbwfYmP6h42wWIvRfPWHnL52PuS4cjgyr5X8tG4j5h+wnSObB3bZGmnVsUj6U6GdurCzWkd2Wiu+XLSx7OUvl9dwc77evL93HvxSUt2IYQQQvwJEmAfQCaTiXPPPZeUlBQA/H4/c+fOjXZ7PGbkVEIFx0fHB8wr+XHRjXu9XvvuKZwwMdwosyoESytqHtDz/FJI5Xd7r0pyqDJrZk7pdArPn/o8b57xJud2Pxe7yR497sHPB4kwpn07zm2Xw8d2B9V3tb2xm0FrpzP0+wtZ9eAJfDdnKutWfE0oWLdluxBCCCHE3kiAfYAlJCQwYcKEaP51eXk5L7/8Mj6fD6UUw8f+B/fOrtHxZf75/PbzjL1er+fgdvQ/JbwqvstvsNFbE+yVvL8R3w5Zbd2bnJQcbht0G5+d/Rn/GPgPOu9Rh3y11csNbdIZnpXNk8npFERKLlpUgF7eFRyz6Sly3hpF6b1ZLJ0+hsVvPMauLb81xkcRQgghRDMiAfZBkJGRwTnnnBOtWrJr1y7mz59PKBTCZLYw/IxXcOfWlPfbtvthdm37Yq/XGzSmK136ZQDwiztESeThR4IGhXPXEPJI6bl9cVlcTOwxkbfHvM2Mk2cwouOImFJ/xZqPGSkOTszqyNWtslhis1L7kdgUyhlQsZCBP99F2+cHsu3uHvzw1MUs//glykoKG/4DCSGEEKJJkwD7IOnatSunnXZadHvNmjV88UU4iHYkpjJw8It4S8IPOCrd4OdfrqKsdH2911Ka4sSLe9Iqy0UI+LEygD+Sfx0s9FD85jrJx46DUopBbQfx+LDHWfCXBVze+3JSbbXqmBPiqwSDS9q2ZlDnLozPPIwnklqxwmqJCbg7GDs5uuBN+n17NY7Hsvn1/mP4btYUfv3hY/w+aWojhBBCHOriKkOhlJq0l0MG4AHWG4ax/IDNqoU46qijKCgo4IcffgDg66+/Ji0tjSOOOIJWHXuQU/gIG3Zeh9keRLf4+OGbcxl64ueYLUl1rmW26Jx2VR/mPfQjFcVeVlQFOSoh/I/P/VMBlV124xzUtkE/X3PW1tmW6/pfx1/7/pWPt3zMK7++wsr8mgowPgL8YgnwS6qNmbTBgk53r8ZxlYUc66mip9eHGTCpEIf5V8O21bBtBhUf2FmV0A9fx+Np238kHbL7oDT5HiuEEEIcSuKt8/Y0YAHMEG2Up0F0Yc+slFoOnGoYRn495x+yTjnlFIqKili3bh0A77zzDikpKWRlZZHT71RK8q+lJPAEmslAs5Ww6POzOeHkD9C0uv9oEpKsnH51X97851J2eoNs8gbpbA2XlSt5bwOWji4s7ZwN+vmaO4tuYVSXUYzqMorVhauZt3YeX2z8goJAQcw4H0F+tgb52ZrIv0nEamj09Bic4C7iKI+Xnl4fJsCp3PSr+hZ+/RZ+fYjdpLM1eSBaznC6DhxFSoZ8CRJCCCFauniX1s4BlgODAVvkZzCwFDgL6Ee4j8ejB2GOzZqmaYwdO5ZWrVoBEAqFeOWVVygqCrdMP+rka9GKa1JJQpYN/PDVFXtN+Uhv7+Tkyw5HKVjlDlFanY8dMCia+yshr+Rj/1E903pyxzF3cGfmnXw09iPuH3I/Z2afSaYzs85Yrwqx3G7weGoKE9u1YVCnTlzSOpPZSS5+tliilUnaUMDAkg84cskUkp7qwfp7+/Pdf65l1ddv43FXNuwHFEIIIUSDiHcF+1HgIsMwfqi17zul1N+B5w3D6KGUugH47wGfYQtgs9k477zzmDlzJpWVlbjdbubOncull16K3W5n2LjH+PB/W7G1/xmAqtBCfln2ML0G/KPe63Xqnc6Qc3L4+tV1/FgZ4ASXCZNSBArcFM9fT+q53Q9KW/hDSTtnO85wnsEZXc8AYEfFDn7c/SOLdy9mye4l7KqMLZHoVSGWOHSWOMIlGm0hRX+Ph0GeKga6vXT3+TApg+zgBrJ3bYBdL+L+1MJP9t5UtT+OjL4j6XL4QEknEUIIIVqAeAPsTkBVPfurIscANgEpf35KLVNKSgrjx4/nhRdeIBgMUlBQwOuvv87EiRPRdZ0RY1/i4zdPISFzNwC7i2eQuKE7HbueVe/1+gzrQEmum58XbmdlVZAB1fnYK/Kp6ppMwlFtGuyzHQoynZlkZmcyJnsMEA64F+9azI+54aB7d+XumPEezeBbh5VvHeFyjfYQHOl2c7THw5EeD4f5/NiVjz6epbB+Kax/nMI3ktiUeBShzkPpNHAUrTI77zkNIYQQQjQD8QbYi4FHlVIXGIaxG0Ap1QaYDlSvaucA2w/8FFuODh06cOaZZ/LGG28AsHHjRj788ENOP/10bAlOhoz4H998PQZHRgVKg9823IwrqRMp6fW3Nx9ydjal+W62/lJIujdEljW8+lnyzgYsHVyY2yQ02Gc71GQ6Mzkr5yzOyjkLwzDYXrGdH3f/yJLdS1i8ezG5Vbkx490afJ1g5+uEcNObhJDBkR4PR7k9HOXx0N3nJ41S0so+hZWfwsrb2Kx1YHf6MdgPG0H2UaeS4EpuhE8qhBBCiP0Vb4B9GfAWsFUptZNw9ZBMYC1wZmRMAnDfAZ5fi9O7d28KCwtZuHAhAD/++CPp6ekMGjSI1Had6H3406zZcBkWlx/NFOTHJZMYMvRj7Pa6D8dpusYplx3OG/9cys87K0kxKRJ1heEPUTh3Da2u6Ydm0Rv4Ex56lFJ0cHWgg6tDTcBdvp0luUuiAXdeVV7MOZWa4kuHnS8d4YDbGQyFA26PNxpwdwpto1PeNsh7Dd+XOqutPSltO5jU3qeQfcTx6KZ4//UVQgghREOK6//QhmGsU0r1Ak4GuhN+oHEN8IkReRrPMIy3fu86SqlTgScAHZhpGMZDexl3FPA9cK5hGPPimWNzcsIJJ1BQUMCqVasA+Oijj0hNTaVbt2506jWEkvxbyfPci24NoVmr+PbLsxl60ifour3OtSx2E6df3Yd5Dy9lSYWvJh87z03JW+tJPad7Q3+8Q55Sig6JHeiQ2IG/5PwFwzDYVr4tGmwv2b2EfHdssZ0KXWNhgoOFCQ4AEoMhBkQC7oEeDzk+Pz19P8OWn2HLs5S9l8D6hP74s06g/ZGnkdnl8Mb4qEIIIYSoR9xLYJFA+qPIz35TSumEy/2dRDiVZIlS6h3DMFbXM+7hP/o+zYFSijFjxlBSUsL27dsxDIN58+Zx6aWX0rp1a44YNomFr68lYH4ZpQGWXXz35SQGD3sVpeo+BJeYZuf0K/sw/9Fl/FQVpH8kH7tqWR7WrskkDGjdwJ9Q1KaUomNiRzomdmRst7EYhsHW8q3RYHvJ7iUUuGPLApbpGl8kOPgiEnAnBYMMiATbR7q95Pgr6V/5Naz+Glbfx07Vmm2pgzDnDKfrwNNJSs1ojI8qhBBCCPYjwFZKHQ2MAFqxR3k/wzCui+MSAwk3pNkYud4rwBhg9R7jrgXeAI6Kd27NkdlsZvz48cyYMYPS0lJ8Ph9z587l8ssvx+l0csLYe/jgxU3YOn4PgJdlrPjhH/QbNK3e67XunMiJF/XkoxmrSPeF6GiJ5GO/tR5Leyfm1pKP3VQopchKzCIrMYuzu52NYRhsLtvMkt1LopVKCj2xLdhLdZ3PExx8Hgm4k4NBjvR4I3ncXrL9ubQrfBsK3yb43fWsNedQ2HowiYefTM6A4Vistsb4qEIIIcQhScXTYlspNQWYBqwHqnOwqxmGYQyP4xrjCDeiuSyyfQFwtGEY19QakwnMBYYDs4D36ksRUUpNBiYDZGRkDHjttdd+9zM0VRUVFSxfvpxgMAhAYmIiffv2Rdd1gn4fxRvvJSVnZ3R8wH0u1oST93q9/NUGhT8ZnOAy4dLDpfq8ToPtx4Qod1fgdEojmt9TUdG498kwDHIDuaz3rGetZy3rPespD5Xv85yU6oDb7WGgx0tXv5/qQo2VhpXVpp7kJvaFtv1ISO94QMoBNvZ9ak7kXsVH7lP85F7FR+5TfOQ+xW/YsGFLDcM48vfGxRtgbwMeNgzjqT86IaXU2cApewTYAw3DuLbWmNeBRwzD+F4p9QJ7CbBr6969u/Hbb7/90Wk1CWvXruXll1+ONpfp1asXY8eORSlFaf5uvvxoFAntigEwQorePWfSut3Qeq9lGAaf//dXdny/ixNcJvRIPeyEo9qwMm0HQ4fWf56osXDhwiZ1nwzDYFPppmhKyY+5P1LkKdrnOanVKSWRKiVd/IFowJ1HKluSjkJ1HU6ngaeT3qbDH5pXU7tPTZncq/jIfYqf3Kv4yH2Kj9yn+Cml4gqw400RSQQ++HNTYjtQ+//k7Qmvhtd2JPBKpElKOnCaUioQzwOUzVm3bt045ZRTWLBgAQCrVq0iPT2doUOHkpTRhv4DZ7Dip/Oxp3pQmsFPP1/JINe7uFzZda6llGLohO68k+/mpy2l9HOE/xFXLtlNYk+FETJQmjShaU6UUnRJ7kKX5C6MP2w8hmGwoWRDtErJj7t/pNhbHHNOka7zSYKDTyIpJanBYKQkoJejPGUcWfoRatlHsOxmNmqdyMs4BkePk8g56mTsCa7G+JhCCCFEixFvgP0ycCrw7z/xXkuAHKVUZ2AHMB6YUHuAYRjRzhq1VrDf+hPv2WwcffTRFBQU8OOPPwLhb5NpaWn07t2b9t36UZL//+39d3gk933n+75/VdU5A42MyZEzQ3LIYRBJicHKlhxkeS3Ta3ttX9nrPetd+5yzd9Nzn72795x7dn033LN+du/xsWVpj5MsWpa1CrRkUdIokAoMEjWcyOFE5Bw6d1X97h9VaHSjG0DPEANght/X8+Dp7qrqRqE5BD744lvf3//K0Ow/IxB1MAIVvvf8z/P4j32FYLB5bR/TMnj/b97Np//di1zPV9nh92N3nzEY+90XiZ7oJnZ/D1a2eSqJ2P6UUuzP7Gd/Zj9PH34aV7te4PYvmHxp/CXmynMNz5kxTb4cj/HluNeL32k7PFgbCzjEw+OfRI1/ksrXLV4LH2Ox/+1k730f++5+FMOUUY9CCCHEjWg3YF8H/o1S6jHgR0C1fqfW+j+t9wJaa1sp9Vt400FM4ONa69NKqd/09//+DZ35HUYpxfvf/35mZma4dOkSAJ/97GdJp9Ps2LGDY499iLm/fp2i/QcYlkYFZ/nON5/mHT/2OQwj2PR64ViAD/7Wcf76//MSGUcT9/uxnfkyi1+7zuLXrmP0x0i+rY/ovV0YIZmpfLsylMGBzAEOZA7wC3f9Aq52uTh3sSFwz5fnG54zbZl8KR7jS37gztYCd4kHi69x9PIPUZf/C7OfTXApfgJnz1PsfPAD9O48sBVfohBCCHFbabcH+/Iau7XWeu/GndKNuRN6sOsVi0X+6I/+iKkpb2xbLBbjox/9KJlMBq01f/Pf/gGhXV+pHZ8I/RgPPvoH+G01TUZen+Vv/vMP2R9QDAYMQi3aQxwFpc4IoXuydD3cRywVujVf3G3iTutFc7XL67OvNwTuhcrCms/ptm0e8Be9ebBYZqft9XBfV/2MdL6N4MF3MuVmePf7PrA5X8Rt7k77N3WryPvUPnmv2iPvU3vkfWrfhvZg17duiFsrEonwC7/wC/zhH/4hxWKRfD7PJz/5SX7t136NcDjMu//uf+aL/+3DJPafBWCx/DXOnfr33HXPP235ev0HMrzrH9zDd/76DU4P5egNKHYEDXosheGHclNDbKoIX7vO0FeuMWEaVHcm6DiYoWdPiq4dcSxZEfK2ZSiDQx2HONRxiF888ou42uXC7IWGwL1YaZxSMmFZPBu3eNavcHfbttdOUpznwbnPseOFz+Bogzde3MV06hgMnKDz4CPsOnw/VqD5LypCCCHEW4n0BWxDHR0d/PzP/zx//Md/jOM4TExM8OlPf5qnn36aQDDEu/7OH/OVv/4gyd3jAAxP/p8krh5kcNdPt3y9XUc72XW0k69+5esc2nEv41cWOHdxDuvaIr1akzSXq9oxU7EHDdcWmHxjjhcrLmMOpAfj9OxJeh+7k6S7o3Kx5G3KUAaHOw5zuOMwv3Tkl3BcpyFwvzz+MovV5sD9xbjFF/3A3eMH7ntLkxzLfZmDpz5P8BQUdZDXgweY77iHwM4H6L3rMfp3H9qQsYBCCCHE7WLVgK2U+j3gX2it8/79VbW50Iy4Abt27eInfuIn+OxnPwvAxYsX+du//Vve//73E8908MhTH+f73/k5Yr15lIJzF/4pseRuMpnjq76mGVAMHu5g8HAH4I1/W5guMvmDSSo/miI6VcCq6xjqChh0BQxsrRmeLHBtOMdr3xgGIBS16N69HLh79iSJxKVyeTsyDZO7Ou/irs67+OWjv4zjOpyfPd8QuHPVXMNzxi2LL8QtvuAH7oDWHC5XOFaucHflMsdmzrNr/JMYL8IsCa6FD1PoOk50z0PsOPYYHd0DW/GlCiGEEJtirQr23UCg7v5q1m/iFjfl+PHjTE9P861vfQuA733ve2SzWR588EF69xzm0OR/5I3hf0QoVUWZDi9//5d5+xNfJhzua+v1lVKkslFS794F796Ftl3yr02x8MIozrWF2txkSyl2hRS7QgY5R3O94nK9aHP9zAzXzyzPY052RWphu2dPkq7BBGZAKpe3G9MwOdJ5hCOdR/h7R/8ejutwbvYcL46+yIvjXuDOV/MNz6kqxalwiFPhEJ/EG/MXd12OlivcXS5zrPwad4+8Qvf1P4RvwojqZjR2hGrvfST3v43dxx4hGk9txZcrhBBCbLhVA7bW+qlW98Xmeuqpp5iamuLsWa/n+tlnn6Wjo4N9+/Zx6KF3M/v532a+/J+wQi4qkOc73/o53vHUl7CsG18aXVkG8ePdxI934yyUKfxggvxL49iTxdoxcVNxV8TkcNhg0vbC9mhV4wALk0UWJou8/qLXumJYiq4diYbQncxGVr0gU2xPpmFytPMoRzuP8ivHfgXbtTk/c55PvfApSukSr029xvXF603PyxkG34uE+V5keZn2btv2qtzlEsfK3+HoG98gcVHj/I3isrmLydRRdP8JsoceYefhEwSCb+0LboUQQtyepAd7mzMMgw996EPMzc0xOjqK1ppnnnmGj370o3R1dfHwB3+Tv/3ji+j+z6JMcM0Rvv/Cr/LIOz6JUjd/YaKZDJF4YgfxxwepXF+k8PI4hVcn0SVvSXelFN0BRXfAwAaGqy5XSy6zzvIfNFxbM355gfHLC/B1b1s4HmgI3D27k4SigRZnILYry7A4mj3KjyV/jCcffxKAudIcr02/xqmpU5yeOs2pqVMtV5ucsCy+Zll8zV8AB2BPpepXuac4lv8Kh05/keBpr5/7YnA/85m7sXY+QN+Rx+jffZf0cwshhNj22g7YSqmPAO8EuoGGn3Ba65/c4PMSdYLBIE8//TQf+9jHWFhYoFwu82d/9mf8+q//OrFYjHf93X/H5z92ncTBlwEo2i/zo1f+Jfee+N03/bmVUoR2JgntTJL+4F6KZ6bJvzRO+eJcrTnIAnYFDHYFDJyoxXQ0wMW5CpNTpabXK+WqXH1tmquvTde2pXuiDb3cnYNxTFNC1O0kHU7z9oG38/aBtwNef/9ofpRTU6d4bcoL3memz1C0i03PvRwMcDkY4HP+ApKW1hyu+P3c5ascm73A7olPYbwEc8S5Fr6LfNe9RHY/yI5jb6ezZ3Azv1QhhBBiXW0FbKXUvwd+B68OOYL0XW+6ZDLJ008/zcc//nGq1Spzc3N86lOf4pd/+ZexrADv/bsf42/+/KdIHbgGwNT8p7n0+iH2Hvi1DTsHFTCJ3ttN9N5u7PkyhVfGKbw8gT21HJrMgk13waZbQeD+LKW+OGOuZuLqIuNXFigX7KbXnRsvMDde4Px3x7zXCBhea8me5Up3oiMsrSW3EaUU/fF++uP9vHf3ewFwXIdL85dqgfu1qde4MHsBRzsNz7WV4rVQiNdCIf7C37bUz32sXObu8mscG3mFnusfg2/BKF2Mxo9Q6b2PxN6H2X33o8QS6c39goUQQog67Vawfxl4Wmv96Vt5MmJtfX19fPjDH+Yv/sKLHdeuXePzn/88P/3TP00kkeTxD3yCb3/1wyR2zAFw6er/Rjy1l+7uJzf8XKxUiORTO0k8uYPK1QUKL09Q+NEkuuyHJQ3VS/OYl+YZDFscvDdL9Kf3UgiaTFzx2kbGrywwdT2H6zb+vuZUXcYuzTN2aXn1wUgy2NhasitJMCIdTrcT0zBrK05+6MCHACjZJc7NnGsI3dcWrzU9d7V+7uWLKL/L0UvfJHlR43xZcdncyWTyKHppPvddD0g/txBCiE3TbkIxgB/ewvMQbTp8+DDvfve7+cpXvNUcX331VbLZLO94xzvIDu7mnuP/hdPnP0o0W0IZmh/98B/wtkc+Rzxxa5a4VkoR2p0itDtF6if2Ujw9TeFlv4XEp0s2+e+Nkf/eGFZ3lP4TPez/wB7MZBC74jB5Pcf45XnG/eC9ON3cWlJcqHDlR1Nc+dGU/4kh0xujt67K3dEXw5DWkttK2ApzvPs4x7uP17bNleY4PX26ob1ktX7uCcvi63X93LsrVe4uVzhWnuZY8TkOnXmW0GkofSbAG4H9zHXcjbXDm889sPeI9HMLIYS4JdoN2H8A/CLwr2/dqYh2Pfroo0xNTfGDH/wAgK9+9at0dnZy5MgR9t77CLNj/5KJ/P+LYMxGWRW+/92nefsTf3vLz8sImsTu6yZ2Xzf2bInCKxPkXx7HmVkOzPZEgfm/ucz8ly4TPpgh+kAPvXd10rdveURbYaHih+15xi8vMHFlgUqpsY0ADbOjeWZH85x9YRQAK2jQvStZV+lOEc9I1fJ2kw6neWzgMR4beAzw+rnH8mMNgfv09OmW/dxXggGuBAN8PuFN0bG05lCtn/sax2ZfZ8/EMxgvwzwxroYPk8/eS2T3Qwwee4xs785N/VqFEELcmdoN2GngF5RS7wZ+BFTrd8pCM5tLKcUHPvABZmdnuXLlCgCf+cxnSKVSDAwMcOK9f5ev/ulFnOCfYAY02pzle8//Apr/edPO0cqESb5zJ4mndlC5skD+5XGKpybRFdc7QEPp/Cyl87MYUYvIvV3ETvQQGIgTTQbZc0+WPfdkvUNdzexYgfEr87XWkunhPHpFa4ldcRl5fY6R1+dq22LpUMMFlN27kgRCsuz77UQpRV+8j754H+/Z/R6gsZ97KXS/Pvs6tm7s8beV4nQoxOlQiE/522IN/dxnODb6Q3qGPo76NozRxUjsLio9x0nsexu77n6UeDKzyV+xEEKI2127AfsIyy0ih1fskwset4BlWfzcz/0cH/vYx5iZmcG2bT75yU/y67/+66RSKZ56+v/B5//gCrGD30QpqOjXcSr/lrHxEtnOH7upOdk3QxmK0N4Uob0p3J/cR/HUFPmXx6lcXu6vdgs2+e+Mkv/OKIHeKNETPUTv68b0V4ZUhqKjP0ZHf4y7Hu0HoFp2mLy26I8B9NpLcrPlps+fnytz6QeTXPrBpPdaCjr64w0XUGZ6Yxiy7PttZb1+7temveB9deFq03PzhsH3I2G+X9fP3dXQz/19jl75FqlLv4f7t4or5g4mksfQ/ffRcfARdt31IMFQuOl1hRBCiCVtBWxZaGZ7ikaj/MIv/AIf+9jHKJVK5HI5PvnJT/Krv/qrhEIh3vf3/guf//jPkjlyAQAzeJXTp38HtEUm9XYGdnyIzs6nNi1sGyGT2AM9xB7owZ4ukn9lgsLL4zhzy8G4OlZg/ouXmf+bK4QPZYg90EP4UAfKauyVDYRM+g+k6T+Qrm3Lz5X9Crdf6b66iF1ubC3RGqaHc0wP5zjz7RHvtcKm11riV7rLi5pSvkowYknwvo206ueeL8/X5nIvVbqnS9NNz520LE5aFidX9HMfq1Q4Vp7hWPE5Dp99ltAZKP91gPOBfcxm7sbacYKeux5lYO8xDFP+MiKEEMIjYxhuc9lslo985CP8yZ/8Ca7rMjY2xmc+8xk+8pGPEIrGeOeH/4ivfObv0HnX2PKTlM3swklmT58EHaAj8zj9Az9FNvsUphld9XNtJKszQurdu0i+cyflS/MUXh6n+NoUuuq3kLia0tkZSmdnMGIW0ePdRE/0EOyPr/qasXSIvfd1sfe+Lu8lXM3saJ7xywuM+f3cM6P5pr+5VEsOw+dnGT4/W9t28Yve8vTBiEUoYhGKWYSiFqFoYPk24m+LLW8PRwPec2KWzPLeBlKhFI8OPMqjA48CXj/3eGGcU1OnaqH79NRpCnah6blL/dxfiC/3cx+sVPyLKK9z99xFdk/+JeYrsECMq6FD5Jb6uY8+RrZ/16Z+rUIIIbaPVQO2UupzwC9qrRf8+6uShWa21p49e/jABz7A5z//eQDOnz/Pc889x3ve8x4yff2886c+ybc/83sslp4nvWeeSGddK4WqMjP3VWbmvgoE6Ox4kr7+nyTb+eSmhG1lKML704T3p3F/ym8heWmcytWF2jFu3ib3/Ai550cI9MWIPtBD9Hg3ZmztFSANQ9E5EKdzIM6Rt3utJZWS7c3k9gP3+OUFCguVVV+jUrSpFG0Wm4dYrMsKmYSjK4J5xL+/MrCv2G4FpBp6Kyil6I310hvr5d273g14/dyX5y/XLp48NXWKCzMXWvZznwmFOFPXzx2t9XNXuLt8lrvHXqVn+BOo52GcToZjRyj33MdcNc7VngTdOw8SiSU2+asWQgix2daqYE+zXOtr/puq2FZOnDjB9PQ0L7zwAgAvvPAC2WyW+++/n87BnfzUP/4PPPflL9EbNLnwyucp2N8nvXehMWxTZXrmK0zPfAVFkM7Op+jt+wk/bEdu+ddghC1iD/YSe7CX6lTRW579lXGc+eUAXB3NM//5S8w/e5nI4Q6iJ3oIH8qg2qwWB8MWg4cyDB7yLlzTWpObLTf0ck+NzqNci0qxeVGcG2GXHXJlp2Vv+HrMgNFeII9ahOsq6MGIRSBkyqI8N8A0TPZn9rM/s7/Wz112yk3zuVv1cxcMgxcjYV6s6+futB2vl7tS4e7yixy98m0ecTV86n8DYIo0U1YfuegA1cQOzI7dRHv20jFwkO7BvViB4OZ84UIIIW6ZVQO21vpXW90X29e73vUupqenOX/+PABf+MIXyGQy7NmzBwArFObYk09y7Kl3k5+b5cL3nuf173+BivoB6X2LRDqWg6CmwtT0l5ma/jKKENnsO+nt/QCdnU9sStgOZCOk3rub5Lt3Ub44500hOT0Ntt9C4miKp6cpnp7GiAeI3tftTSHpvbF+cqUUiY4wiY4w+090A3Dy5EmefPJxXFdTKdqUCzblQtW/rb/fvK3k368UbPSbuPzXqboU5isU5levrq/GMNWKdpYVLS0rA3ut1SVAMCzhHCBkhri3617u7bq3tm2+PM/p6dO10H1qsnU/97RlctKKNvRz99g2A7bNYNVm0LYZtK8yWH6DXXmb7LCLOuUdZ2uDESPLbKCPfGwQJ7WTQOce4r37yO44SGf3oMzuFkKI24D0YN9BDMPgZ37mZ/jEJz7B2NgYruvyqU99io9+9KNks9mGY2PpDPe994Pc994PsjA1wfkXvsXF57+IEzrtVbY7loOdpszk1LNMTj2LIkxX9zvp6V4K27d2moIyFOGDGcIHM7hFm8KPJim8PE7l2mLtGDdXJfetYXLfGiYwGCd2oofovV0Y0bVbSNZjGIpwLEA4FgBu7JcK7WqqZYdSq2CetykXWwV2/37eblrd8ka4jqa4WKW4WF3/4BWUguAqgTzs3w/623NjmomrC7XHwcid3XeeCqV4tP9RHu1v7Oeur3K/NvVay37uccti3LJ4pcX/LmHXpd92vOBdtRmwiwzaFxjMnWFwziZ6ZfnfQlEHmTB7mAv1UYoNojO7CWb3kurbR9fOQyTTnbfs6xdCCNG+tgO2Uuop4GlgJ9DwN0yt9Y9t8HmJmxQKhXj66af5wz/8Q3K5HKVSiT//8z/nox/96KrPSWa7efAnP8yDP/lhZkaGOP/Ct3jj619EJV4nvW+BcKY+bJeYmPgiExNfxFARurreSU/PB+joeALTvLWLuhgRi/jDfcQf7qM6UaDw8jj5VyZwF+taSIZyzA3lmPvCJSJHOr0WkgMZlLm5VVllKIIRL3Ryg5lHa41dcRsq5aW8F8ArRbsutNcH9uXHztKFojdBa7zXy7fXHnP15EsNj62QWRfMvVaWYNQiFFluYVlucWkM7Lfb1Jb6fu537XoX4PVzX1m40hC4z8+ex3ZXfz9LhsGloMGlYOtfCDscxw/efvW7OsOgPcGOuZfpmXIwX18+dp4Yk2YvC+EBKokdqI7dRLr2kh7YT/eOA4QjmzMxSAgh3uraCthKqV8Bfh/4a+BJ4L8DB4E9wJ/eonMTNymVSvH000/ziU98Atu2mZmZ4ZlnnmHnzvVXqevoH+SRn32at33455m8epmzL3yDy899iUDmCum9jWHb1UXGJ77A+MQXvLDd/W56un+cjo7Hb3nYDnRHSb1/D8n37KZ0cdabQnJ6Ghy/2udoiqemKJ6awkgEid7vt5B0b86UlDdDKUUgZBIImcRvYo0Tu+osB+9C1Q/fKwJ5oUrJD+z17S0rxxre8OcuO9hlh/zcjfedgzcyMVQXuOt7zoP1wXwpsNdtC4Yt1BYHdNMw2Zfex770Pn56/08DUHWqfPZrn2Xg6ABDi0MM5YYYWhxiODfM0OIQC5WFNV9zxjSZMU1+RPP/U5bW9PnBe2Cp/aQ6wmD1Gvsmvk1yzKX+HZmgg+lAL/nIAHZyJ0bnHmI9++gcPEBX/x5MS/6oKYQQG6Hd76b/BPgtrfXHlFKLwL/QWl9SSv0XIHfrTk/crIGBAT70oQ/xl3/5lwBcuXKF+fl5ent72b9/P8Hg2hdSKaXo3r2X7t17eVz/CqOvn+PsC9/gyne/TLh7mPS+RcLpFWF7/HOMj38Ow4jS3fVuurt/nI6Od9zSsK1MReRQB5FDHbiFKoVXJ8m/PE51aPmfpbtYIfeNIXLfGCK4I+FNIbmnCyNyZ4YJK2BipUxiqRt/3x3bXQ7jxca2lYaQXrQZH54kEoov96kX7Te97FS15FAt3dyFoSjvItamMO4H8oYwXt/+4m8PhMxbEtADZoCuQFettWSlhcoCw4vDteBdC98573at6retFNcDAa4HAi27mBKO64XvWv93hUH7EgOFC/Qv2ASHlo+taJNRo4vZYB9Fv/87mN1Lom8/2cEDZLJ90v8thBBtajdh7AWe8++XgaVhxP8FOAn88409LbERjh49yvT0NF/72tcAmJ2d5ZlnniEQCHDw4EGOHDnCgQMH2grb/Qfvov/gXbjur3P99CnOv/ANLn/7q0T6x0jvXRG23QJj4/+dsfH/7oft99Dd8+N0drwdw7h1YduIBog/0k/8kX6qY3nyL49T+MEEbm65F7lyfZHK9UXmPn+JyNFOYid6CO1Pb3nlc7swLYNoMkg0uf4kC+9i0Idqj5f6zldWzOsDeKWw3H/utbssbbPf9NQW9PJYRW5irKJSNLSr1F8E2lg9twg29Ki/uektyWCSZGeSuzrvatrnuA6TxUmuL16vVb+XKt9Di0MtL7Kst2ganDWDnA01//dUWtPjOMuVb9tmsLrAoD3D3vlX6ZxxUZeXjy/oEONmL/PhfkqxQcjsIpTdQ3rgAN07DxFLpG/4axdCiDtVuwF7Glga3joMHAN+hNddeutHSoib9o53vIPFxUVefPHF2rZqtcrp06c5ffo0gUCAAwcOcOTIEQ4ePLhu2DYMk113H2fX3cdx7P+BK6/+gHPPn+TiN04S3zFFZt8CodRyoPXC9mcZG/8sphHz20g+QEfHY7c0bAd6Y6Q/sJfU+3ZTOu+3kJybWW4hsV2Kr05SfHUSMxUken8P0fu7CXRt/xaS7aq+7zzRcePPd11NtbQyjDdWzZe31Qd3b3+19ObaW7SmdrHpzVCGalk9D0Ysxidcvj3xOoapUKbCMBSG6X0oY+mx4W0z/G3+fsMwyJq76TL2cCKkMCIKo9c7tuyWmS5PMVEaZ6I0zlhxjNHCCKPFEUYKIxScPK5y0MrF9T9Q3v8DWinGLIsxy+LlFl9P2HX9vm+nNv1kwJ5gsDrCwanvEp3UcGH5+FmSTFq9LIb7qSR2YnTsItq9l/TAAXp2HJDl5YUQbyntBuxvAe8BTgHPAL+nlHo38E7gK7fo3MQGUErxgQ98gAceeIBnn32WfD7P1NRUbX+1WuXMmTOcOXMGy7IawnYotHYANq0A+048xL4TD1Et/2MuvfIi557/BteufZvkrhnSexvDtuPmGRv7LGNjn8U0E3VtJI9hGLdm9q8yDSJHOokc6cTJVyn80FuevTqSXz6v+QqLX7/O4tevE9yVJBlTVEbzBHqiUtneRIah/JaNm5v+4joulZJTF76rzWHcD+Stgnr1Tfafa1dTylcp5VtPb5l5/fqbev31dROjm/3cw/41jtIshW3H/3DrAvhSGHeWH+OSVy5nlcNp5aL9fRY2YRzC2ibqf8R1lbi2iY1UMRliUV0lx3MM41BUIUpmjGowjo6kMWMZQqksyWwviUwnpmUyf01z+UdTWJaBGTSwAgamZWAFDUzL9B4HDSzLkP83hRDbWrsB+7eApfLDvwVs4DG8sP2/3oLzEhusp6eHPXv28MQTTzAxMcGZM2c4ffp0Q9i2bZuzZ89y9uxZLMti//79HD16tK2wHQiFOfTIOzj0yDsoF/JcfPG7nHv+JFdHvktqz3xz2HYWGR37DKNjn8Eyk3R1vZvu7vff0rBtxgIkHhsg8dgAlZGct5DNDydw6yZmVK4u0I3BxJlXUCGT4I4EwZ0JgjuThHYm3vToP3HrGKZBOGb4YxVvnOO4VIveaMX6QF5fKa8F8+Ly9JaKH+Ttys1Pb9lMCgNTG5h6Y69BKPofkzf8zCn/wzP0wo/aepZhKi9wBwysgIlZu2+sut0MeOG8FtiD3rblEO8/P2hiWiue57+eYSmZFS+EWNe632GVUhbw88BnAbTWLvC7t/a0xK2ilKKnp4eenh6eeuqphrA9Obn8o9G2bc6dO8e5c+cwTbMhbIfDa/+pNxSNcfSJd3L0iXdSWJjnwnef5/wL3+DK5Euk9y6S3rdAKLkctm1ngdGxv2J07K+wrCRdXe/xwnbm0VsWtoP9cYL9cVLv30Pp/Az5l8YpnZ+Buoykyw7li3OUL87VtlldEYI7kwR3JgjtSmJ1S5X7TmGaBmbcIBy/yYBuu0395kth/dzZC+zbuw/X1biORvu3rqNxXY32b13HXfG47tbRaNdd8bhxf+25/ussP14+7k7hOpqK40DJAW585vtNU3gV9obgbjYEe7NFyG+uypu1QN/y+KbtBsYdPGdeiDvNugFba20rpf498MVNOB+xybq7u+nu7ubJJ59kcnKyFrYnJiZqxziOw/nz5zl//jymabJv3z6OHj3KoUOH1g3b0WSK4+/5cY6/58dZnJ7i/He+xbnnv8HCwinS+xa9ynZ92LYXGB39NKOjn8ayUnR1vYee7h8nk3kEw9j46rGyDCJHs0SOZnEWKxR+NMnw998gWQg1zNeund9kEXvSW8YdaKxy70oS2iFV7rcq0zKIJIJEEs2/FE46r3P8yfXHZG4GXR/cl0J9q9Df9NjFcbzAbtsOs8U5pvJTTBdmmC7MMFucZbY4z3xxnmKliKFNDG2g/FtDmyhtePcxMVwDxfI+QxsYrknADRB1TKKORdi1CLoWphvAcAO4Ooijg9gEgC0Kmxrsqov9JubN3yxlLFftHddl+OvfxQwYBIJ+yA8uV+CXKu5msG5/wPCPMWu35srnBJePk0AvxM1r92+E3wVOAFdv4bmILdbV1cUTTzzBE088wdTUVC1sj4+P145xHIcLFy5w4cKFWtg+cuQIhw4dIhJZ+3rXRGeWBz74IR744IeYHRvh/PPf5Ny3vkGhfIHMvgXSexcJJurD9jyjo3/J6OhfYllpbxpJ94+TybztloRtMxEk8dgAY9XXOfTEQzhzZSrXFqhcXaR8bcHr216xwuKaVe5dCUI7pcotthdlKExDYb7pV+rGWw6hWaFaYDg3vDzxZMXs75JTuqnPmHIcdldtdleq7KpqdlUUgxVFT8XAIIitAyzoJOPGDnKRQZz4TqzUDuIdO4jFszgOOFUHu+ri+CG56dZ2sCsuju16t1UX23ZxKg627eLaW/dXgKVJPUvXC8wVmlcN3UiGodYM4A2hful+cLkCbwWXg3wt3K+xX75PijtJuwH7D4H/oJTaCbwM5Ot3aq1f2egTE1srm83y+OOP8/jjj9fC9pkzZxgbG6sdUx+2DcOohe3Dhw+vG7Yzvf287cM/z8M/8xGmrl/l/Avf5NxzJ6nqq6T3LZDeu0AwsdwbbdtzjIw+w8joM8thu+cDZNJvwzA2fp61UgorE8bKhIne2w2ArjpUhnO1wF25toDbYjnyllXuuj7uoFS5xR0uGohyIHOAA5kDTfu01kyXphuC99L9i1MXmXfmV33dedPkVdPk1XDjNSGG1gzYNrureXZX59hdvcSeapXdC1Wysy7qijdmcDiwk7nYXnTnIWJ9d5Hdcw99uw/f0AI72tVe4K6F8tUD+1KYb97v1D1/Kdi72BV/+1K4t+v2Vxz0Jmd719W4/mz6zWjDMSxFYGUAr7s1byK0F6Y0Y5fnvek8ypvQowxaP/a3Gf42tTTRR9U9lv570Sal1/g/Vin1ceB3gLk1XkNrrd98MeQmHTp0SJ8/f36rPv1txZtb/OSbeo3p6ela2B4dHW15jGEY7N27txa2o9H2Rt9prRl74wLnnv8m57/zTXRghPTe5rBdLxDooKvLG/2XTj+8IWG73fdJa40z61e5r61e5W7F6o4Q3HF7V7k34t/TW4W8V+05efIkDz72IFcWrnBl/krD7dWFqxTt4g2/Zsx12V2tepVv/3ZPtcrOqk1Ea8o6wJA1yGx0L9WOA4T67qJz9z307z1KIHhrV6S9UY7jh/KKy7e/9TwPnngIu+KH8IpTu3UaHvu/BFSWg7q96n6n9vr2FgT624LCD9zLoXs5rK/xuG7bqo9rAZ/VHxsKQzXur32ets+r+XOcv3COu+89SiBoYgW9lYSXfnkJBE2skHftgPyCAUqpl7XWD6x73DoB2wH6WGfWtdZ6y1pHJGC3b6N/yM/MzNTC9sjISMtjDMNgz549HDlyhLvuuqvtsO26DsNnT3Pu+W9y4XvfxohOLle242uFba9n+82E7TfzPrVb5V6pqcq9M7ntV5qU0Ng+ea/as9b75GqXicIEl+cvNwXw0fwo+iaWEe2z/dBdWQ7fu+0qvbaDo02GzX5monsoZw4S6D1Mx6576N93jHAk9ia/0jfvVv+b0trrv6+F8RYB3K7WhfM19jtNvwSsCPWVrelpFzdGKWp/IfACuB/GgwZWyMQKmARCdaHc374U2uufF2h6He95xm1QaGo3YK/3E1zB1gZosX11dHTw9re/nbe//e3Mzs7Werbrw7brurzxxhu88cYbfOELX2DPnj0cPXqUw4cPE4ut/kPKMEx2HL2HHUfv4cd+7Te5euoHnH/+m7z+V98hkJrxppGsCNvV6gwjI3/ByMhfEAh00N39Prq73k8m8zBKbc4fWVTAJLQ7RWh3igTtV7l12aH8+hzl1+dY9LdZ3RE/cHuVbqvr9qtyC7FRDGXQG+ulN9bLI/2PNOwr2SWuLlxtWfnOVXOrvuaoZTFqWXxnRQkp7LrsrNrsrhbYXX2V3TMvsWfcpvulKgEXrht9TEV2U0ofwOo5THrX3Qzsv4doPHUrvvQtoZTCtBSmZRDahF/2tdbLLTOrBHC7qfrut+esUsWvVhzmZudJxBPehbraa/HR/v2li3mXPtz6/S0ev9Ur+lpTuwag2Ebh6GaYftvPWqHcCpkEAl5VvVVYXyvcG+bmtfm083/NW/yflGhHJpPhscce47HHHmNubq4WtoeHh2vHaK25dOkSly5d4gtf+AK7d++uhe14PL7qa5uWxd77HmTvfQ/yrkqZyz94iXPPf4Pzz3yfcMcC6X0LpPYuEow1hu3h4T9nePjPCQQ6vbDd/X4y6Yc2LWyD38vdEcbqCBM97vVyuxWH6nCOyrUFylcXvSp3rkUv90QRe6JI4SW/lzu8NLEkSWhX0uvl3uZVbiE2Q9gKc6jjEIc6DjVsX+r3vjx/2QvgS+F74QpDi0M4uvXiQiXD4EIoyIUWS8xnbcevdp9ld+4Ue2ar9JyyCdo2I6qbyfBuiqkDmN2HSOw8Rv/+4yTTnbfk676TKKVqFVE28A8EXqX/wQ15La0bQ/rK0O4Fdv84V9cFeP8vAnVBfTm0a1x3ndfU/mu4za+x6udo+UsEuLpx/9L90dExOtJZ7xeUskN16a8WFS9QL10TcKstXZtQzt/cirrrUYbyKu5B0w/gxnIl3m+LWW6TMVpW6dvVzk/nsfXS/lb2YIvtJ51O8+ijj/Loo48yNzfH2bNnOX36NENDQ7VjtNZcvnyZy5cv88UvfpFdu3Zx9OhR7rrrrjXDdiAY4uDDj3Hw4ccoFwq88dJ3OffCNzn3yVeIdOX8nu1FAg1he5rh4T9jePjPCAazdHW9j57u95NOP7ipYXuJETQJ7UkR2tNc5S5f9Srd1dFcw0xuAF1aUeVWYHVFazO5gzulyi1EPaUU2UiWbCTLg72NIavqVLmeu95U8b4yf4XZ8uyqrzllmUxZJi9FGkeUWlr7Ve9L7C6fZ/elz7LnfBX3WZsJN814aDf51H5U1yESO7zgnc723pKvW9waSimUAu7A77EnT07w5JP3rHmM63h/KVgK3HbFD+L+Yy+UO1TLdfsqrr9/+XG19nip/Wj5/q0u6WpXUyk5VEpvbuXedrQTsH+DtS9yFGJV6XSaRx55hEceeYT5+flaz/b168vLRmutuXLlCleuXOHZZ59l165dtZ7tRCKx6muHolGOPP5jHHn8xygszHPx+9/h3PPf4PSfnSLWU/B6tvcsEIgt/49UqUwxPPynDA//KcFglu6u99Pd/eOk0ye2JGzDGlXuoZzfx71KlVuDPVHAnijUVbktL3D7fdzBnQmMsFS5hVgpYAbYm9rL3tTepn3z5fmWvd7XFq9RdVv/adxWikvBAJeCzROC0o7D7uowu6tX2D30N+y+bBP+apVSNcZ0cBe55H7IHiQ2eJTe/cfp7B5EGTKDWmwvhmkQNA2Ct+hnylKb0MogXgvgK4J5dUWw9yrvdaG9RdB32xhCsFHaeZc+r7WeWP8wIdaWSqVqYXthYaEWtq9du1Y7ZrWwfeTIkTXDdjSZ4p53vY973vU+cjPTnP/Otzn/wjc5/cI5Yr1Fr7LdImwPDf8JQ8N/QjDY5beRfABvsdKtZQRNQntThPZ6PZ1aa5yZUq2Pe/Uqt035wizlC34FToHVHfX6uP3FcKxsRKrcQqwhFUpxvPs4x7uPN2x3XIeR3AiXFy43tJtcmb/CZHH1ReLnTJMfmiY/bDlecJLd1VF2T3yN3cM2xW9Xma8GKBs7yCX243YeJDpwlO5999IzsFeCt7hjNbQJ3SKO4y5X3MsOdrUuiPuP7XJdaG+ouHv72v562pkisp0DtkwRad92nWSwsLDA2bNnOXPmDFevrn497c6dO2thO5lMtvXac+Nj3oztF77J1PXLxHoL3gqSexYIRFf7E1GcbPZtpFMnSKVPkEwcwzC217guWKpyL1K+tkjFby1x821MLKmvci/1ct9ERWK7/nvajuS9as/t/D7lKjmuLlxtDN/zV7i6cIWSU77h14u7LrtWjBfsqRhY9FGK7mPaiZIe2I+V7Cac6iHe2U+ys49UR88NzfW+093O/6Y2k7xP7dvQKSJC3ErJZJKHH36Yhx9+mMXFxVrP9sqwfe3aNa5du8aXvvQlduzYUQvbqdTqV+6ne3p5+EM/x8Mf+rnlBW2e/ybDz48Q7/XaSFJ7FleE7RxTU88xNfUcAEoFSSaPkUqd8EJ36n6Cwa2/aMmrcqcJ7U0DUuUWYivFg3GOZo9yNHu0YburXcbz403B+8qCN15wNTnD4HQoxOnQyl/uy/TZP6LXtsnOfpPOKYes49Ble7cZ2yXoRjF1klKgg3Kwg2q4Ex3LYsa7CSS7iXT0kejoJ93VRzSWlKq4ELfAmgFbay3/14lNlUgkeOihh3jooYdYXFzk3LlztbBd/9eW69evc/36db785S8zODhYu0AynU6v+trZHbvIfuSXePTnfpHxSxe9SSTf+RZDz08R7yuQ3utNIwlEGivbWleYn3+F+flXuMYfAhCJ7K5VuFOp+4lF96HU1v7vopTC6oxgdUaI3lffy71OlVuDPV7AHi+Qf9FbqVNFLII73nyVW4i3OkMZ9MX76Iv38Wj/ow37inaRawvXmsL35blLFJzVF9VZGi+4FqU1GXeSTmfMC985h855l+w1P5A7DmXHIW6b2DpJzspQDGQohzpxIllUPIuV6CaU6iHa0U+qs49UtnfbLb4jxHYlPzHFtpVIJHjwwQd58MEHyeVytTaSK1euNITtoaEhhoaG+PKXv8zAwABHjx7lyJEjq4ZtpRS9+w7Qu+8AT/zirzF87gznXvgmF777bYa+PU8oXSHWWyDeWyTaUyScrjS9RrF4hWLxCqNjfwWAZaVIpe4nnbqfVOoEyeQ9mObay8VvhtWq3MuBe4HqWL65yl1cpcrtTysJ7kzKAE8h3qSIFVl3vGCt4j1/mTdm32Ck0N6iOlopZkyTGdPk9eZpgw1CrkvWydHpzJN13iBbcchOOmTHHLKOS9Z2iDkOOA5zxJk30uStDKVghmo4ixvNYsS7CCS7Cad7SXT2kcwOkEx1SHVcvGVJwBa3hXg8Xgvb+Xy+FrYvX77cELaHh4cZHh7mb//2b+nv76+F7Uwm0/J1lWEweOQYg0eO8dSv/AbXz5zi+Wc/j5FfZOhbr+M6NlbYJtZbJNpT8G67Shhm4w84255nevrrTE9/3XtdZZFIHCXlB+506gShUPete4PaVF/ljtVVuSvXF2vTSirXFnBXziCtr3J/36ty7wkYTF46RXAgTmAgTnAggZkJyVK6QrxJ640XHMoN8dx3nmPw0CBTxSkmi5NMF6e9+4VJJvMTzFcX2l7dsmwYDBsGw4H1I0HKccg6NllnnKwzQtZxyM45ZKe9ynjScUk4DknXpapN5lSKBTNDIZChHOrACXdCrAtjqTqe6SWR7Sed7dsWK2QKsVEkYIvbTiwW44EHHuCBBx4gn89z7tw5zpw5w6VLlxrC9sjICCMjI3zlK1+hv7+/1rPd0dHR8nVNy2L3PfdxZWaeJ598kmqlzNjr5xk6d5qhs6cZ/eE5RssllOkSyZaI9RaJ9xSI9hZbtJXYLCy8ysLCq1y//gkAwuFBv4fbayuJxw9u2WjAekbQJLwvTXhfGvCr3NOl5RGBV/0q94qf1WZV1eZy114ravlhW0K3ELdCwAywJ7WHA+EDPLnnyVWPq7pVZkuzTBWn1vyYLExSckptf/5502TeNHljneMsrb3w7Thk7XmyzgxZ53WyBYfsokN22KntD/nfWxZ1hHkjXWtXqYQ7caNZVMyrjofSPSQ6+klm+0l1dGOYW//9U4jVSMAWt7VYLMaJEyc4ceIEhUKhIWy77nLfw1LYfu655+jr6+PIkSMcPXp01bAN3qI2S8u1Azi2zcSVNxg+e5qhc6cZPneGyVcXAU0wWSXeW6hVuiMdzW0lpdIQY6Uhxsb/OwCmGSeVus+vcN9PMnkvlrX6IjubRSmFlY1gZSPE7u8BwC07VIb8CvfVRSrXW1S5AbdgS+gWYhsIGAG6o910R9f/y1mhWmCyONkQvKeL07VtS9Xx6dI0bptjTG2lGLMsxiwL1mnbTjjuchh3KnQ6I3Q518lWXLJFh45xr2c87bosNZw4WjGlUiwaafKBNKVgJ3akE6JdGIkugskewpke8rMTlAo5wtGt/94q3lokYIs7RjQa5f777+f++++nUChw/vx5zpw5wxtvvNEQtkdHRxkdHeWrX/0qvb29tbDd2bn2ZBDTsujbf4i+/Yd44Cd+Bu26TA9dY+jcGYbOvsbwudPMXJj2jg05xPyWklhPkWhXESPQWAJ2nBwzM99iZuZb/haDRPwuv63kftLpBwiH+zf0PbpZRqi5yv3833yD+wePesu+D+eoDOXQJQndQtxuooEouwK72JXcteZxjuswW55dbkdZEcDrW1Vy1Vzbn3/RNFg0DS7TvEhPPVNrOh2HTselyw/knc4sWXuKLuc82XmH7IxLp+MQ9f+aeRjg1d9kgShzRoZFq4NSKEs10oWOdWOl+gil+4h1DpDqGiCT7ZMxh2JDyL8icUeKRqPcd9993HfffRSLRc6fP8/p06ebwvbY2BhjY2N87Wtfo6enhyNHjpDL5XBdF2Odi3OUYZDduZvszt0cf8+Po7VmfmKc4XOna4F79Psj/rGaSGfJD9xe8K5fzt3jspg7zWLuNEPDfwJAKNTrXzzptZbE43dhGFv/v61SCjsK0Xu64J4uoG5MoB+4q28qdCcIDsQldAuxjZiGWesNP8ShNY8t2sVa2F7rY7o4ja2bv0e04ijFhGUxYcHZdY6Nua4fwL1AnrUdss4inc4cWft1snMundPe/vpYv1QZnzM7yQc6KIe7cKJdqEQPgVQvkY4BEtkBMt2DxOIpuYhTrGrrf1ILcYtFIhGOHz/O8ePHKRaLXLhwoRa2HWe5d3p8fJzxcW/J8VOnTtHf38/g4CADAwMMDg4Sj6/9J0alFOmeXtI9vRx94p0A5OdmGTq7HLgnX7vC5KkOQBNMVIn1FIn5rSXhjjIrs2S5PMbExLNMTDwLgGFESCXvJZX2LpxMJu8jEGhv0Z1brWFMoIRuId7SIlaEwcQgg4nBNY9ztct8eX7NAL5UKV+oLLT9+fOGQd4wuBpYuyoOkHT8aSm1QO7Q6UySdcbIlh06Cw7ZcYeM4zaEpoIOMWukWbQ6KQSzVCNZ3Fg3ZrKXYLqPWEc/qe4dZLr6ZbzhW5AEbPGWEolEuPfee7n33nsplUq1NpKLFy82hO1yuczly5e5fPlybVsqlWoI3H19fQTW+eYdS2c49MjbOfTI2wEo5XOMnD/L0NnXGDp3mvE3Xmf2ordQjhFw/MDtVbmjPUXMFW0lrltkdu67zM5919+iiMUO1BbASaVOEIns3DYB9NaG7kQtfEvoFuL2ZCiDTDhDJpzhQObAmsdWnEpD4F6tV3yyOEnVXX9V2yULpsmCaXJpnRYVb7a4Wwvh3gjDMp3OdTqdK3TmXK9N5XpjvzjALEnmjAy5QAflUBY72g2JHqxkL+FMH4nOAdLdgyQzXVIVv0NIwBZvWeFwuCFsX7hwgbNnz3Lx4kWq1eZvzvPz88zPz3P69GkADMOgp6enFrgHBgbo7Oxcs7UkHIuz9/4H2Xu/N3qrWi4x+vqFWoV75PVzLA75yyorTaSj7FW4/Up3MLEyhGry+Qvk8xcYHvkkAMFgtjapJJ06QSJxFMNYZxDuJpLQLYS4GUEzWFu0Zy1aaxYqC0wVp/jqd7/KjkM7GgL5VMm7nS5OM1OawdHOmq9Xe9362eLrHGtqTYffntJZ6xef86epnKfTH23Y6bgkXbe2bHZFW8yoDAtWhnwwSyXsVcWNRA/BdD+Rjj6S2UE6ugfkws1tTgK2EHhh+5577uGee+7h61//OsePH2d4eJihoSGGh4cZHR3FthvDnuu6tQsmX3rppdrrrGwticVWn+0aCIXZeewedh6rm1Ry+Y1ahXv43GmmToeZOu0fH6s29HFHOkusXECyUplicvLLTE5+GQDDCJJI3LO88mTyPoLB1aenbAUJ3UKIjaKUIhVKkQqluB6+vuY4Q8d1mCvPMV2argXw+qkpS8F8pjTDbGm27dnijlJMWhaTbaSsQO3izeVWlQ5nnKw9QmfJIZt3yY56+2Na18L48oWbncsXbsZ7sJI9hNJ9xLODtQs3ZaTh5pOALcQKSikymQyZTIZjx44B4DgO4+PjtcA9NDTE9PR003NLpRKXLl3i0qVLtW3pdJrBwcFa6O7t7V21tcS0LPoOHKLvwCEe/MkPo12XqaFrXoXbHw8498YMc294fdeG5RLtLi73cvcUMUONY7Rct8L8/EvMz78E17xt0eje2gI4qdT9RKN7t13wlNAthLjVTMOkM9JJZ6STg5mDax5ru3bDbPGmUF5arpLfSL94tX6k4TrCrruiKl4g6+TIOpfozDl0zjt0XvOCesSfpGJrg2mVYt7sWL5wM9aNivcQSPUR6egjNz1FITdPNJ5q+7zF2iRgC9EG0zTp7++nv395bF6xWKytHLkUvAuFQtNz5+bmmJub47XXXgO81pLe3t6GKndHR0fLkKcMg66du+nauZv73vtBb1LJ+FhDhXtuZJTcyFKVXBPOlL0qt1/pDqWa210KhUsUCpcYHf1LAAKBjNfDnbyfVPoEycTdmGZ4A965jSWhWwixVSzDoivaRVe0a91jK06FmdJMY2tKXTCfLk7XAnq+mm/7HEo3sOpmzK0P4i6dzgxZZ5JO54w3znDSqV3YeQTg1D9kUUeYNTtYtLIUw13Y0R5I9BJI9xPpGCDZtYOO3h0SxNsgAVuImxSJRNi/fz/79+8HvKA3Ozvb1FpSf/EkeK0lSwvf1L/WwMBAQz93NBpt+pxKKdK9faR7+zj21LsByM1M18L20NnTTF2/Smk2zPRZb3l4K2LX9XEXiWSLGCv+WlitzjI19VWmpr7qf54AicTR5ZUn0ycIBbMb9t5tpLZC99AileH8zYfuwThmWkK3EKI9QTNIb6yX3ljvusfWjzSsD961UF7XM34jq24uTVK51sYklYTj0u3YZB2XbrtE1rlKt3OJ7KJD96xD12UvjC9VxReIMmt0sBjIUgp1eRdtJvtqQTzVvYOOnp1EYom2z/dOIwFbiA2ilKKjo4OOjg7uvvtuAGzbbmotmZmZaXpusVjk4sWLXLx4sbato6OjIXD39vZitfgTYryjk8OPPs7hRx/3Xiu3yMj5MwydPc3w2dOMX77I/GWL+cteW4kyXaJdpYaFcKympd6rLCz8kIWFH8L1PwIgEt5JKn1/rbVEt7mi21a41aE7OOgtkCOhWwjxZrU70lBrTb6abw7gfo/4ytYV221vvjgsLfYT5I11jkv4i/x4H0W67Ct0OW/QtejQNevQdckL4tFaEI/5QbyTYrgbO9qNSvQRSA8Q7ewn2bWTzt4dd+QFmxKwhbiFLMuqVaaXFAqFptaSYrHY9NyZmRlmZmY4deoU4LWprGwtyWQyTQEvEk+w78TD7DvxMADVUomR188x7Fe5Ry6cJz9mkB+LwqsAmlCq4reVeJXucKZ5qfdi6RrFsWuMjX126TPx0st3EYvuJxbzPqLR/YTDfaiVV15uA+uG7qEc1WEJ3UKI7UkpRTwYJx6Mr7vq5tIklVYXbL6ZSSpLq26uN9Iw7nqL+3Q7DlmnQLe9SNZ5g+4Fh+ysQ/aSF9Lrg/jMUkU83IUd7UUlewmm+4l2DJDs3klH7w7CkdWHBmw3ErCF2GTRaJQDBw5w4IA381VrzczMTEOVe2xsrGHFSfAutFwK5vWvtbK1JBKJNDwvEA6z6+7j7Lr7uPc6dpXxS2/URgMOnz9DeT5PeT7EzPk0AGbY9lpK/Isno10lDGvl1fNF5udfYX7+lYatphklGt3rhe668B0O79gWq1DWaz9059Cl5h9Aa4buwURtKfg2Bw8IIcSGqJ+ksje9d81jXe3yxa99kYP3HWSiMMFUcYqJwgSTxUkmC96M8YnixA1VxXOGQS5ocGWdIB5zXbpsL2xnnQLdzmW67It0LXgV8Y43vH0xP4jPE2PW6FwO4rEeVKKPYGY5iHf27iAUbm6x3Gzb66edEG9BSik6Ozvp7Ozk3nvvBaBarTI2NtZQ5Z6dnW16bqFQ4PXXX+f115ensnZ2djYE7p6enobWEtMK0H/wMP0HD8NP/aw3qeT6Vf/CyTMMn32N/NwsC1cTLFz1+ueUoYlkSw293IFo62+0jlNgcfE1FhdfW/F1BolGdzcF72h0N4axfVY5WzN0Dy1dSHljoXuvaTD+o1ewshGsjjBWZwSz079NBlGGVLyFEFvDUAYJM8GhjkMc6ji06nGudpkrzzFZmKyF74bbuvvtBvG8YZBvI4hHXb81xXbocvJ0OQt02a/TNe/QNeOQueTtWxpjOEfcC+LBLOWQF8SNZB+BdB/RzkG/R/zWBnEJ2EJsQ4FAgB07drBjx47atnw+3xC4h4eHKZWaL3iZnp5menqaH/3oR4DXWtLX19fQWpJOp2ttDMow6Nq1h65de7jvfT+B1pq5sRHvwsmzZxg69xrz42MUJiIUJiJMAqAJxGxC6TLhTIVwpux/VLDCrf/UqHWltihOI4NIZGctcHvhex/R6D4sa3v8ObAhdN9746HbcBTV0TzV0RbTAixVC91WR9gL4f59MxNCmduv3UYI8dZjKIOOcAcd4Q4OsXoQ11p7QbxVCF9x2+6KmwXD4KphcHWdCzYjDUE8R5czT5dzoRbE0/6+uB/EZ0kwtxTEw8tBPJjuI9I5SLp7Jx09OwiGbnyqlgRsIW4TsViMgwcPcvCgN6vVdd2m1pLx8fGWrSVDQ0MMDQ01vNbK1pJw2PsGopQi0zdApm+Au596DwCLM1P+HG6vwj11/SrVfIBqPkBuuOHTYYZtL3Snl0N3KFMmGFutouFSLF6hWLzC1NRzDXvCoX6vyl0L3/uIxfYTCKRv/o3cIKuG7un6kYGr93TX2Bp7oog90dyHjwFmOozlV7sbbjvCqIAsHiGE2F6UUmTCGTLhzJqzxbXWzJfnV62C199W3ObrglopGgbX2picEnG9BX28ML5IlzNHl3OerjmHrmmHlD/eMOEuBfEks0YHueD6IxqXSMAW4jZlGAbZbJZsNsvx48cBr7VkdHS0odI9NzfX9Nx8Ps+FCxe4cGG5mpzNZhuq3N3d3Zj+6l+JjiyHH3uCw489AUBxcYGvfPYzDGY7mRm+zszIEDMjQ+RnZ3BKFvlRi/xo45/ejKBDOL1c7Q7594OJKqtdE1gqj1AqjzA9882G7cFgllh0ZfA+QDCY3dILDJVSXgU62xi6v/WVb/Dw4fuxp0s400Xs6RK2f+vm16jguODMlHBmSg0tJ0vMVBCzI9IygBth+fYuhNi+lFKkw2nS4TQHMgdWPW7pgs31QvhkcZKyU27rcxcNg+uGwfV1gnjYD+LdjkPWXqTbmWv765PvwELcQQKBADt37mTnzp21bblcrqm1pFxu/iY0NTXF1NQUP/zhDwFvAkp/f39DlTuVSqGUIpJIktyxm/uffLLhNcqFvBe2h4eWb4evMzc+iluh1mZST1ku4ZRX5Q5nyrUQHkpVmpaBX1KpTFGpTDE7992G7ZaVbOjxjsb2EYse2NLJJkop3CCEdiYJ7Uw27XdLdkPgXrp1Zoo482tXbZz5Cs58hcrl+aZ9RizQELjNusq3EQvIpBMhxG2h/oLN/Zn9qx6ntWaxurhuW8pkYbLteeIlw2DIMBhqY5b4ShKwhbjDxeNxDh06xKFDXs+c67pMT083tZZo3TjqwrZtrl27xrVr1xpeaylwz87Osri4SDwer4W1UDRG3/5D9O1v7M9zbJv5ibHG4D1ynZnhIcqFPMXpMMXpxh43ZWiCybr+7qXgna60mGiydM4LLSebGEaEWGxf3cWVXsV7O0w2McIWQX8FyZV01cGeKbUO4HMlWGMUuZuvUslXqVxbbNqnQmbDBZdeEPfuGwm56FIIcftRSpEMJkkGk+xL71v1OK01uWquFrjrJ6fU304WJynaLVr32iQBW4i3GMMw6Orqoquri/vuuw+ASqXS1FoyP99cFc3lcpw/f57z588D8OqrrxIMBmtTUOo/Ojo6aiMDTcuio3+Qjv7GhRS01hTm55bbTJYC+MgQC5MTlOdClOdCzF+ue5LSBBNVv8fbr3z7981g68TpusU2J5t4wXu7TDZRAZNAT4xAT/PFntpxcWbLXuCeKWFP+bf+Y+zVZwPqskPVX1a+iWUsV747wljZMJbfhmKmwyhTwrcQ4vallCIRTJAIJtYcYbi0sM9EcYKpwlTt9lf51bY+z6YGbKXU+4D/DJjAx7TW/27F/p8C/he8uowN/I7W+tubeY5CvBUFg0F27drFrl3LixcsLi42tZZUKs0tC0vhfHR0tGlfLBZrGb4zmQyBgNemEEtniKUz7Dh6T8Nzq6USs2MjTA9frwXv2eHrzIwOU1lQVBaCLFyrf8Yqk03SlaaVKmvPuJ0nm5hGrd97Je1qnIUK9nQRp1b1XqqAl9CVNRaVsF3s8QL2eKF5n6GwMqHldpP620wYFZCJJ0KIO0P9wj57U8tBfNsFbKWUCfxX4N3AEPCiUupzWuszdYd9Ffic1lorpe4BngEOb9Y5CiGWJRIJDh8+zOHD3v+CrusyNTVVC9wXLlygUqm07Odeks/nyefzDW0mS9LpNB0dHU3hO51OYxgGgXCY7t176d7dWGFwXYfFqcla6K4P4MWF+TUmm5TrLrK8MyebLFGGwkqHsNIhWPGXUq01bq7aVPVeCuJuYY2JJ66uhfSm/+oKzGTIC9zZCOaK9hMjJH8wFUK8dWzmd7yHgIta60sASqm/AH4KqAVsrXX93ytjyPpnQmwbhmHQ3d1Nd3c3999/PydPnuSJJ56gUCjUZm+v/HCc1Sulc3NzzM3NcenSpYbtpmmSyWRaVr7j8TiGYZLq7iXV3cue+x5oeG5xcYGZkeFaf7fXdnKd+fFxf7JJY/V5syabbCdKKcxEEDMRJLSrxUWXRbup33up7cRdWOOiSw3OfBlnvkz5UouLLuOBhhGDS/O+zY4wRtSSiy6FEHeUzQzYA8D1usdDwMMrD1JKfQj4t0A38IHNOTUhxM1QShGLxYjFYg2TS8CreC8sLLQM3nNzc00XVS5xHKc20WSl1fq9Ozs7CYfDRBJJBg4lGTh0V8Pz7GqVubGR5gknI0MUJortTzZJVlCrjJ5ea7KJ43Zy6tSnCUcGCIcHiYQHCPsfltV8ceNWMiKWt8z7YKJpn1txcGaaL7i0p4s4c+U1SyJurkolV6VydaFpnwpbWJ1hehzFfPGyV/3uCGNlwpjpEMqS1hMhxO1FrfZDbsM/kVJ/B3iv1vqj/uNfAh7SWv+jVY5/HPhXWut3tdj3G8BvAHR1dZ145plnbt2J30FyuRzx+Pb6Yb4dyfvUnjfzPrmuS7FYpFgsUigUGm5b9Xm3IxAIEI1GiUQiDbfhcLg2z3slrTXVfI7S3Ayl2Wn/dobS3AzVfPMFgDcz2WR9MSALdKLoBNWJIru8Td26pXw3lAuBIgQKECioFbeg9M1VqDUaOwx2BKoRTTXaeN8JAW/B4rd8n2qPvE/tkfepfU899dTLWusH1jtuMwP2I8C/1lq/13/8LwC01v92jedcBh7UWjeXsnyHDh3SSxMNxNpOnjzJkyvmFotm8j6151a9T6VSiZmZmZaV77X6vdeSTqdbVr1TqRSG0bo6Wi4UmB0dbppwMjs6guus6FNeMdnEC91rTzZpl2Ul/Gr3IOHwgF/9HiQc7icSGcSy0tu+vUK7Gme+3HChZX3ft66+iffIVF6lOxPyl5evq37fwe0n8n2qPfI+tUfep/YppdoK2JvZIvIicEAptQcYBn4e+IX6A5RS+4E3/Isc7weCwPQmnqMQYouFw2H6+/vp7+9v2K61Jp/PtwzeMzMzbfV7v/HGGw3bTdNseaFlZ2cnsViM3n0H6N3XuMKY6zjeTO+60O1daHmdhWv5lpNNgomq9xGv1u4H/PuGuXaRw7YXyeXOkcuda7nfNGOEw/2NATyyfD8Q6NzygKkMLwRbmTCsWCeidtHldJHXnv8h+7t348yWsGdKOLMlnIXK2lfjONq7WHOq2HzhJf7Mbz9sW5mQf+uFcLMjjBGU5eaFEBtv0wK21tpWSv0W8GW8MX0f11qfVkr9pr//94EPA7+slKoCReAjerNK7EKIbU0pRTweJx6PN4wTBK/lZH5+ftV+79U4jsPk5CSTk5NN+0KhUMvZ3p2dnWT6Bsj0DbDvxPJlJFprigvzdbO8vQstp4eHWBifID/W6luZxoraTeG7/vF6rSeOkyeff518/vWW+w0j7FfA+4mEBxuq3+HwAMFg15atcgmNF10uXtGknmz8b6ttF3uu7PV+z5Zqt0sB3M2vMfUEf+b3WJ7qWL7lfiMWqIXvpgq49H8LIW7Sps5N0lo/Czy7Ytvv193/XeB3N/OchBC3P8MwyGQyZDIZ9u9vLJFWq1VmZ2dbVr1zuRYLrfjK5TIjIyOMjIw07VttvndHRweDR44xeORYw/Ff++pXOX7XYebGR5gbG/U/RpgbH2N+YoxCIUBhvNVZaKyw41W8W4TvUKKKEVi7vcJ1SxQKb1AovNFyv1JBP3wvX3gZjgz6YbyfUKgHtdqVnZtAWQaBbIRAi3nfAG7Z9hbcmfFD94oArivrvD/5Km6+SvV684qXS6MHzY5QQ9V7KYDLqpdCiNXIYFIhxB0tEAjUxguutFq/99TU1JoXW64231spRSqVagre5UqFVE8vHf0DTa/lOg6L05PMLgXv8eUAPj8+hl2qYJcsmGwVMDVmyGnZghJM2oQSNkZgnQqvrtRmfreilEUo1NfUerLUFx4K9W7pcvNGyMLotQj0tljtUmvcfHU5gNdVwJ2ZEvZcGZw1/kJQN3qwcrl5+gmWwkqHW1bAzcyd2/8thFifBGwhxFvWRvd7a61X7fd+8cUXyWQydHR01G6XPtIdWVLdvXDPfY2v57rk5mYaq95jo8yNjzE3PkKlWMQpWxTLFsWp1hVeM+jU+r2XPkJJm3BaE4iXMay1p7ZobVMqXadUug5zzfuVMgkFe/zw3e+PIRys6wvvwzCCa36OW0UphRkPYsaDBHc0jx1cWvHS8avfKwO4s7hO/7ct/d9CiNYkYAshxAq3ot/bdd3aca0+XyqVagjdSx+ZTIYdHVl2HLm74TlLPd+zde0m3q0Xxks5r+XBqZg4MyalmXDL8zICzor+b5top0E47WBGiiizuOZ7pbVTW3ynNUUo1FNrP6mvfkcig4RC/ZhmaM3PcavUr3gZ2ptq2q9t1wvbq1TA11z1kjb6v+OBugAebmxFSYdQpvR/C3G7koAthBA34Gb6vcfGxtZsOamvfK9c2RIgmUw2he6l+wOH7mpaWAeglMv5YXtkufXED9/5udnacW7VpDRrUpptHcCV5S4H8HiVeLdFtEN5F2CG8mijRe9y41dHuTxGuTzG/PzLLY8IBrsIhwdw3QAXL35vuRc83L+li/EoyyDQFSXQ1XoWuVuysWfLtQr40vSTpQC+3vjBpcV3WK3/OxWqu+gy1ND/LescC7G9ScAWQogNslq/98mTJ3nkkUeYnZ1lZmam6WNhoUV/b52FhQUWFha4cuVK075YLNay8t3R0dFyzCBApVRs7Peu9X2PsjjdOFFF2wbluRDlOa/KPH22fm8GZbr+KMIKie4A8e4A4YwmEC1DYAGXOdZLg5XKJJWK93mvXnuxab9lperaTgaaAnggkNmSXmcjbBHss6Bv9f7v5eBdbgzgs2Vw1+n/nivjzJWpXG5een4fBiPPfxczEcTwp7CYiQBGvO6+v12FTOkFF2KTScAWQohNEAqF6O3tpbe3t2lftVplbm6uZfhea1l5WL7g8vr16037IpHIquG7a9ceunfvbXqOXakwPzFem3gyOzbKvB/A5yfH0W5jVVY7BpWFIJWFILnh+j1RIIoyegjEqsS7LJL9EWJZg1DKwQwX0eYctjMNrD7DHMC251nMzbOYO91yv2lGCYX6iUT84B3yw7f/OBTs3vRRhPX93+xMNu33+r+Xqt9l7JliQyuKu7B2b7xC4eaquLkqjLZuQakdGzC8sB1fDt0N95dCejwgYwmF2CASsIUQYosFAgG6urro6upq2mfbNvPz8y3D9+zsLK67ehtCsVhkeHiY4eHhpn3BYHDV8N0xMEjn4I6m5zi2zcLURNO0k7mxUeYnxnDs5p5k7Soqi0FmFmHmUv2lgCbQCaqDaMYkszMBsTK9u5IEElWMYB5XzVKpjuG6a4dNxylQKFykULjYcr9SAcKhvlrgrq9+R8ID/iSUzb0Q0+v/DmOlw4Saf89BV13sufqxg+WGBXjW6/9e+VqOP8JwPUbU8qvgfgD3K+JG0gvgS2HciFgyolCINUjAFkKIbcyyrNq4v5WWLrhcCtsrA7jdIvAuqVQqjI2NMTY21vJzrha+U929ZHr7m57jug65melaq8nsUvAeH2V2fBR7tWXutaIw41KY8doghp+vD4ExgpGjdOzoJL0jRrwrQDjtEoiW0dY8VXuCUmkEx1l9njmA1lWKpWsUS9dWOWLpQszlFTFXzgY3zdZTWm4VFVi7//vk107y9hOP4C5WvEkouQruYhVnseJtyy3fv5Gl6N2CjVuwsSfWOdBQLargfgD3A3otjMu0FPEWJAFbCCFuU/UXXK7kui65XK5l5XtmZmbNiy5t22ZiYoKJieaUZZpm7XOuDN/pTCfJbDc7j93b8BytNfm52bppJ6MNE0/KhdVbHCrFEmMXhhm70LwvFEuS6T1EeqCTVF+EaKdBMFHFDBWoupOUSsOUSiNUqzNrvIvQeCHmKy2PCAQ66qrezf3glpXc3D5nA6xUCFJrT2DRWqMrDs6CH8BzFT94+wHcf+wsVnFz64wlrLc04nChQnWdQ1XQxEwGMfwKeC2Mx1f0j8eCKFOq4uLOIAFbCCHuQIZhkEwmSSaT7N69u2Hf0pzvVi0nMzMzFIurj+ZzHIepqSmmpqaa9imlSKfTLSvf6XSawbuOMXhX4yqXWmtKuUVmR0f4zsmv0ZtOMTc2wuzoCHNjI2uG73I+z9gbFxl7o7k1JJxIkundT6bvCdK9WeI9ASJpCMTKdeHbC+Dl8jjrJctqdYZqdYbFxdda7jfNeEPoblgZMzxAMJjdkgsNlVKokIXRZUFzB1ID7foL8yxWcP0KeH1F3F2s1Lbp0tp98w2vW3Gwp4owtfbIR5S/dH28rhpea1NprJarsFy4KbY3CdhCCPEWUz/ne+fOnU37C4XCqhNP8vnVA6/WmtnZWWZnZ5sW2gEaZn2vrID3HzxM58gYjz35ZMPrFRfmmR0d8VtORpbvj45QLa/eU1xaXGB0cYHR18837Yum0mT6+kn3Pkamt5+uvh5iWYtgoortTNWFby+Al8qjaL12ndZxcuTzF8jnW5TaAcMIehdiNvSAD9YCeCjUs6UrYoLXF74UYNejqw6OXxF3/Qr4ckW8MYyvuVpmw4uyfOFmc+dSI0st94cnGltS6gO6av/3ACE2lARsIYQQDaLRKNFolIGB5qXdy+Xyqm0ni4trz8Sen59nfn6ey5cvN+2Lx+MYhsHExASJRIJ4PE4ikfDuZzrZu3M3kUikVrWstZ34gXt2dLhW9Z4bG8Wurt4CU5ifozA/x/C5M83n0dFJprefdN8OMr0P09XXT3qwh2jGoup4Pd/1AbzoP3bdtauzrrvekvT+ipj1AbxuafqtXJCnFRUwsTpMrI7W89OXaK3RRbuhJ7wxmC9vcwvV9ltUbF0bY7iWfZgMf+s7dSMMAw1TUxou5IwFpEVFbBgJ2EIIIdoWCoXo6+ujr6+vaV+lUll13OD8/Pya4wZzOe9CxTNnmkPvEtM0G4J3LYhnuujfuZeD/r5IOExudqax4u3fnx8fbTntpHYeM9PkZqa5fuZU4w6lSGa7SPf2k+ntJ9P3AOnen2Tnzn6SXd24OkepNFQL4MX6CnhpGNtunmVdr2FFzPnmWeAAwWC2FsBdt8zlK6cJBrMEA53ebbCTYLAT02x9YeRWUEqhogGMaIBA99rnpR3Xb1Gpv1hzuV+8Pozryg20qJRs7JINk220qEQDDRNUloL4yos4ZYqKWI8EbCGEEBsiGAy2XGgHvAsn15r1vda4wSWO49Sq4GsxDGNFBbyHzM797EwkiMWiGLaNnVugODvNfG3iyQjzE+O4zirBTWsWJidYmJzg2qkfNuxShkGyq9sP3gNeCO87Tk+vF74N08S2F1uE7+UAvrTQzloqlSkqlSkWFl4F4NKlr7Y8zjSjBAKdfuDOEgx01O4Hatu8/d4iPdtj9rUyDcxkCDO5fqXeLTtNF2g6C5Wm/nFnsYzSbQZhDW6+ipuvwlhh7WNXTFGpXcDZYpss9PPWJAFbCCHELWdZFtlslmw227RvKTh/4xvfYN++fSwuLpLL5VhcXGy4v9bkk3qu69ZWv1zLUi96oqOf+M6DZGMxAqaBqlZwC3kqi3MUpybJjY+wODmJ1q1/CdCuy/z4GPPjY1x5tXEKiWFapLp7/J7vper33fT0vZfE3izKMPz3oEy5PLIifC8H8HJ5DK3bq9o6TgHHKVAqNS8+1MwgGOyoVcEDfhU8GMguB/RgZy2wm+baLSGbxQiZGKEIVufa4xNPfv0k73josVoYr1XDc8tTVW6qReVGpqjUL/SzZptKABWQkYZ3CgnYQgghtpRpmrULH++5555VjyuXyy2D98r75dVmbq+gta49Z42zQ2V3Ett5mEg4TNA0MFwHyiXs3AKl2RnKs9Mou4KybdSKhOY6tt8f3rzYjxkIkO7p8yveXvj27h+mv7ejFr4BXNemUpmgWByiVB7h7NnvsXNHmkplmkp12q9uT1OpTKN1e7+I+K9cq4yTb74gtOmczbgXyP0qeCBY356yXBkPBrP+6MItro4rMGMBzFiAQE/zkvb1tLM8RaUWvBump1RrF3Hq0q1Z6EeFzYaLNOvbVBpHGgZQ5vb4y4NoTQK2EEKI20IoFCIUCrVcdKdepVKpBe61Avla4wjraa3J5fPkmiaoWJDu9j58QcvEApTtVcGdQg5lV1F2FaPq3SqnitIap1pleuga00PNC+BYwRDp3r7l4N23VP0+QLrnQc6fS7N//5Mtz9Vxcg2Buz6AVyv+fX+bba9d5V/JcXIUizmKxdUW7VmmlEUg0LEcwGvhu65aXusf78AwtvYiTmUqzGQQM9nOFBV3eaZ4rsUCPze50I8uOdilNkYaAkZsadXNxpaUhr7xuNf/Lv3im08CthBCiDtK/TLwa6lWq+RyuYbg3SqIFwrr9OPWqdgOXv3YhGjS+2hBOQ6qWl4O3/7t0odrV5i8fpWpa1eanhsIRzBCYUa/9izRZJJIMkU0ma7d9x6niCb3kOi4F9MKrHq+rluhUp2hUpnyw3d9AJ/2t8/Utml9A5Vb7VXdK5X1loX0WFbCC94N/eN1bSrBTkL+fstKbGlfswoYWJkwVqaNKSoVZ5VFfpqr5W2PNATcvI2bt7HH1+sXZzmI19pU6qvkAQJ5cCuOrLq5gSRgCyGEeEsKBAKrroRZz7btpiDe6v5aM8JX0qaJbmfah2M3hG+jWqFiV1GOTf76da8abtsox2a1uBmKxogkk0STaT98J+tCeKoulB8llU1hBVoHcq01tr2wXB2vTtcF88ZQXqlMr7uE/Uq2vYhtLwLNYxxXUirot6p0rugfb2xT0XoG285jmtGtXegnZGFl1+4Xr400XNGO0jjS0H+cv5F+cXAXKrhr9IvvwmTkWy9gxCzMdBgzFcJKhzDrPqx0CCMelGp4myRgCyGEEGuwLIt0Ok06nV7zOMdxyOfz6/aI5/P5NUcWNjAtXNOC0NrhDK29kG3bdaHbu604VXK5Isb8Qm07rrtqIA9Gon7wbq6OL4fyDiLJPXR2p7CCrVsqHKdMdUV/eGMon6ZS9VtXqjNtX8TpfbmV2vL26/nGN//vKGViWcnaR6B2P4EVSNU9TmIFko2PreSmXNzZMNKwZ+1jtaNxCy1aU+r7xpf6xYvt/9XBq4rnqA6v8suRqTBToVUDuJkOYYQkWoIEbCGEEGJDmKZZW55+La7r1oL4elXxtoO4UmgrgLYCwDph3DuJpiBu+JXxql2lkMuj5uaWQ/sa5dJAOEI0lSKaqAvlqTTRxHIojyQHiaeOEsmmCASbe621dqlW55oDeENl3O8hr07jOO3/tcB7fYdqdZZqdfaGnrfEMIKtA3qgVWhfGdITGMb6fd03Qpk3sOqm7TbOE28xQSU/MU+gYqzfouLo2gWbq11Kq8LWquHbTIcwE6G3xII+ErCFEEKITWQYRm1G91pc16VQKLQM3leuXCEajZLP58nn821fsFl3EmgjhA60eWFhrVWluUJedaoUF3LMzs6ibBtcZ9XqOEAgFPZDuB++/WAe9YN5JJkkmjhIMpki2p0iEGquHjtOgUpdb3i1rjVl+aLOKfL5CQyjjOuuP8FjLa5bWZ62chMMI+IF7pWBvM2ArtTN90Yry8BKhyG9ehX+5MmTPPH4O3BzVey5Um2VTGeujD1Xxpkv48yVcPPrV8N1yaY6ZlMdW+WXIIU377xV+E6HsVJBVMS67WeHS8AWQgghtqGlBXPi8Ti9vb0N+06ePMmTTz5Ze+w4DoVCoRa46z9yuVzTNnuN1SxbqrWqtHGsdhuDuF8ZV7aN4VSx7SqlxUXmZme87etU6a1QqBbEo8mkH8JTRBL1oXyQTDJFpNcL5EvhbOl9ct1yrce7Wp3Hthew7QWq9oK33d9W9bfX9le9W63Xm3a9NtctUq4UKVfGb+r5phm/gUDu7w+ksKwEphlvK6wqo26Kys5Vvo6K44ftuvBdC+Bl7LkS2OtUwTXe8fNluLrKuQTNlgHc8kO4mQyirO09plACthBCCHGbM02zrao4eBfTVSqVlmG81UehUGi/VQVAGehAEB1osy3CsRsC+HIo9+7bjk15foG5mZk1L+ZcYgWCRPzqeNF2KJ5+xWtZWWpdSaaIpvqJJO+iM7N6D/kSrbUf0OeXA3jVC+ZVezmst9xmL/oBvf3+8pZvkZPzLhotj9zEsw0sK0HASmEFEi1bXVw9wfhEkVCwi1Com2Cwu2XfuRE0MbqiBLpaX6CrtT9LvEUA9+6XcBfX/2VFVxzsiQL2RIGWU+2VNxmldStK2OsFj25tFVwCthBCCPEWopSqzRRfb5QheK0qxWJx3ar40ke7K27WmBbatNBBWHdidO1iztbtKoZTxbFtKvPzLExPo7TLmWtrTyUJRiLehJWUf0Fn3W3tws6lYJ7Yi2HeWLuGN5s8XwvcVXuhVjH3quaLfkCfb6yq14L6WgshtcP1X2se1uiUee21P2t47I1N7CYU7CIYWrrtIhTsJlgXxOtHJiqlvFUp40EYbP3LnrbdusDdHMCd2fL6s8M1uIsVKosVuN76/VEBwwveqdVaUUKowK2rgkvAFkIIIcSqDMMgFosRi629EuKSarXadnU8n8/juu0vxNJ4MWcbXKflnPHlxxXKlQrl8VHmxkfb+vyReGK5V3xFIF8O6t79UCyGUgrLimNZ8fa/zjpaO9j2UkCvr6Iv+oF8RcW8Wr9t8YYvCF2y1FJTKLyx5nGGEfICdy2Idy8H8bpAHgx2oJTp9YR3rr7M/dK4QntlH/hSb/h8GWehsu6YQl11sSeL2JOrX59gxANe+E6trIT7VfDYzS/SIwFbCCGEEBsmEAi0NdYQvDBVKpXWrIjXf5RKN3ixomGigyZOcJ0xe9pdddGflY+LiwsUF9tbAdMwLW/EYUOLSpJIi2AeTaYIhJvPUymTQCBJIJAEBm/s6wdc18Zx6nvPm6voV6+eoTMboFKZpFyeoFKZarvv3HXLlEpDlEpDax7nfR2dhEJda1TGuwmFshjREMFoAPpb/1KiHRdnodIygC8Fc11evy3HzVVxc1WqQ2uMJVwRwNslAVsIIYQQW0IpRSQSIRKJ0NXVte7xtm2vejFnq4s7HafN3mdloAPeVJU16+kNLSpVDLuyehjXGtexyc3OkJudaes0vAs607UJK/W94yvbVSLJFKa1fowzDAvDyBAIrL6g0vXrJ7n3nifrvkx/bGItcE9QrkxRKU9QrkxQKU96t5VJHKe9lU61dupW9jy99vtgpQnVV79XVMRDoW6CiS6C6eSqfdZuyW7sA/dDeO3xQnn9niRH40yXcKZvfAqNBGwhhBBC3BYsy2pr1jh41fHnnnuO48ePN4w4bHVbLre8lK7ZihaVteK7chzUGgF8KZzXL/pjl8ssTI6zMNnetJFwLO5Xx5N1feMrq+P+ap3xBMpor+dYKcNfKbODePzQmsfads4P4pN+EJ9sCuLl8iS2PdfW5/Zecw7bniOff33N4wwjslwRD/m94cHu2rZgvItQRxfhQA9KNX7t2tXeXPBa9bvSOKJwvoxbuMFpO3UkYAshhBDijqOUIhAI0NXVtW51vFKpkMvl1gzhi4uLFArtVWsBtGmizci6q3AqrTEcG6plVLWyamtKqwkqpXyOUj7HbBvDRZRheKMNG6riXjCfHBvjQiRAOJYgHI8TjieIxBNYodC6kziW+suj0T1rHue6ZSqV6eWK+FIVvOyH8soklfIklepU21NXXLdIsXiNYvHa2l+7sggGs34V3G9LWaqMR7sJZbxwHgvuwjCW+/vdstMwgtCZK8PvtnVqErCFEEII8dYWDAbp6OhYd6qK4zhtBfEbuXhTK4VjBcAKrLkIpwJMvDCuKmXcUrFWIW8M461X3tSuS2F+jsL8XMvXv/aNrzRtMy2LcDzhf3jBuz6Ee49jdcd4+0KRaFO13DBChMP9hMP9a78f2qFSnW3ZjlKrkvu3rtveXx60timXxyiXx2DNoSyKQCCzoj+8m1Cki2Dau4CzXRKwhRBCCCHaYJomqVSKVCq15nH1q3CuF8bbXfRHAzYKzABEAhBZfSpJwFB+GHf8MF7ALRaae8fXmW/u2Db5uVnycze2xLxSBqF4nEg83hzIV96P1d+PY5gmoWCWUDBLgiOrvx9aY9uLfuD2A3itPaXutjJxA6MONdXqDNXqDOTP39DXvJIEbCGEEEKIDVS/CudatNaUy+V1e8QXFxfb7xMHqq6mCqBMCEW9jxa/E1imQdA0ccslQpYFjo2ulHErZexSAV2polzH+3AclGuD4z9eI5xr7VJaXKDU5rSVesFItCmIR2rV81ZBvYNkYhdWYPXRjY5TqusPX9Ga4t+WyxNesF5v/l+bJGALIYQQQmwBpRThcJhwOLxun3i1Wq0F7rXCeD7f/txr23GxHReUScnRgAnBqPcRX33qiHfuYCmFAbUAru2qH9Ar/jYb5TrePHJnOajXHrcIs5VigUqx0PaFnkusUMgL4ytCeCi23FPuhfI+wvGDpFLe9kAoXOszd12banV6uSJeVwVf2gaX2jufGzp7IYQQQgix6QKBQNt94vl8ft2qeC6Xu7FFflbQGqq1KrYBpuG1r4RaL6PeikJjaO2FcNtGL13M6TrLlXL/tvZ4ZTXdfy27XCZXLpObnrqhr8Mwraa2lUhD+8pewvF7SMUThDMJ4K/bel0J2EIIIYQQdwjTNNsaZei6LsVikVwux/PPP8/hw4cplUqUSiXK5XLDbattbyacL9EoHKXqwvnaE1dW+UJq1fJVK+VrVNMdx17z4s+bJQFbCCGEEOItxjAMYrEYsViMjo4OjhxZ/YLClbTWVKvVptC9ViBvtU2vc5Flm18I2jBqs8lvSl11nBWBvBbUl+63SQK2EEIIIYRom1KKYDBIMBgkkUjc1GtoralUKm8qpJfL5Y0J6abpzS1/869UIwFbCCGEEEJsKqUUoVCIUCjU1sqcrbiuuyEh/VaQgC2EEEIIIW47hmHUprCsN5t8Na7r1oJ2O4G8XRKwhRBCCCHEW5JhGEQiESKRm7jAcq3X3dBXE0IIIYQQ4i1OArYQQgghhBAbSAK2EEIIIYQQG0gCthBCCCGEEBtIArYQQgghhBAbSAK2EEIIIYQQG0gCthBCCCGEEBtIArYQQgghhBAbSAK2EEIIIYQQG0gCthBCCCGEEBtIArYQQgghhBAbSAK2EEIIIYQQG0gCthBCCCGEEBtIArYQQgghhBAbSAK2EEIIIYQQG0gCthBCCCGEEBtIArYQQgghhBAbSAK2EEIIIYQQG0gCthBCCCGEEBtIArYQQgghhBAbSAK2EEIIIYQQG0gCthBCCCGEEBtIArYQQgghhBAbaFMDtlLqfUqp80qpi0qpf95i/99VSv3I/3hBKXXvZp6fEEIIIYQQb9amBWyllAn8V+D9wBHgaaXUkRWHXQae0FrfA/wvwB9s1vkJIYQQQgixETazgv0QcFFrfUlrXQH+Avip+gO01i9orWf9h98FBjfx/IQQQgghhHjTlNZ6cz6RUj8LvE9r/VH/8S8BD2utf2uV4/8JcHjp+BX7fgP4DYCurq4TzzzzzK078TtILpcjHo9v9Wlse/I+tUfep/bJe9UeeZ/aJ+9Ve+R9ao+8T+176qmnXtZaP7DecdZmnIxPtdjWMt0rpZ4C/m/A21vt11r/AX77yKFDh/STTz65Qad4Zzt58iTyXq1P3qf2yPvUPnmv2iPvU/vkvWqPvE/tkfdp421mwB4CdtQ9HgRGVh6klLoH+Bjwfq319CadmxBCCCGEEBtiM3uwXwQOKKX2KKWCwM8Dn6s/QCm1E/gM8Eta6wubeG5CCCGEEEJsiE2rYGutbaXUbwFfBkzg41rr00qp3/T3/z7wr4BO4P+nlAKw2+lzEUIIIYQQYrvYzBYRtNbPAs+u2Pb7dfc/CjRd1CiEEEIIIcTtQlZyFEIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA0nAFkIIIYQQYgNJwBZCCCGEEGIDScAWQgghhBBiA21qwFZKvU8pdV4pdVEp9c9b7D+slPqOUqqslPonm3luQgghhBBCbARrsz6RUsoE/ivwbmAIeFEp9Tmt9Zm6w2aAfwz89GadlxBCCCGEEBtpMyvYDwEXtdaXtNYV4C+An6o/QGs9obV+Eahu4nkJIYQQQgixYTYzYA8A1+seD/nbhBBCCCGEuGNsWosIoFps0zf1Qkr9BvAb/sOyUuq1mz6rt5YsMLXVJ3EbkPepPfI+tU/eq/bI+9Q+ea/aI+9Te+R9at+hdg7azIA9BOyoezwIjNzMC2mt/wD4AwCl1Eta6wfe/Ond+eS9ao+8T+2R96l98l61R96n9sl71R55n9oj71P7lFIvtXPcZraIvAgcUErtUUoFgZ8HPreJn18IIYQQQohbbtMq2FprWyn1W8CXARP4uNb6tFLqN/39v6+U6gVeApKAq5T6HeCI1nphs85TCCGEEEKIN2MzW0TQWj8LPLti2+/X3R/Dax25EX+wAaf2ViHvVXvkfWqPvE/tk/eqPfI+tU/eq/bI+9QeeZ/a19Z7pbS+qesMhRBCCCGEEC3IUulCCCGEEEJsoNs6YK+39LrwKKU+rpSakHGGa1NK7VBKfV0pdVYpdVop9dtbfU7bkVIqrJT6vlLqVf99+jdbfU7bmVLKVEr9QCn1ha0+l+1MKXVFKXVKKfXDdq/SfytSSqWVUp9WSp3zv1c9stXntB0ppQ75/5aWPhb867rECkqp/9H/Xv6aUuqTSqnwVp/TdqSU+m3/PTrdzr+l27ZFxF96/QJ1S68DT69Yel0ASqnHgRzwx1rrY1t9PtuVUqoP6NNav6KUSgAvAz8t/6YaKaUUENNa55RSAeDbwG9rrb+7xae2LSml/ifgASCptf7gVp/PdqWUugI8oLWWWbxrUEr9X8C3tNYf8ydyRbXWc1t8WtuanxeGgYe11le3+ny2E6XUAN738CNa66JS6hngWa31f9vaM9telFLH8FYgfwioAF8C/oHW+vXVnnM7V7DXXXpdeLTW3wRmtvo8tjut9ajW+hX//iJwFllttIn25PyHAf/j9vxN/RZTSg0CHwA+ttXnIm5/Sqkk8DjwRwBa64qE67a8E3hDwvWqLCCilLKAKDe5Rskd7i7gu1rrgtbaBr4BfGitJ9zOAVuWXhe3jFJqN3Af8L0tPpVtyW97+CEwAXxFay3vU2v/O/BPAXeLz+N2oIG/VUq97K/WK5rtBSaBT/htRx9TSsW2+qRuAz8PfHKrT2I70loPA/8BuAaMAvNa67/d2rPall4DHldKdSqlosCP07h4YpPbOWBv2NLrQtRTSsWBvwJ+R2awt6a1drTWx/HGaj7k//lM1FFKfRCY0Fq/vNXncpt4TGt9P/B+4B/6rW2ikQXcD/wfWuv7gDwg1x+twW+j+UngL7f6XLYjpVQG76//e4B+IKaU+sWtPavtR2t9Fvhd4Ct47SGvAvZaz7mdA/aGLb0uxBK/p/ivgD/TWn9mq89nu/P/PH0SeN/Wnsm29Bjwk35v8V8AP6aU+tOtPaXtS2s94t9OAH+N1wYoGg0BQ3V/Mfo0XuAWq3s/8IrWenyrT2SbehdwWWs9qbWuAp8BHt3ic9qWtNZ/pLW+X2v9OF7b7ar913B7B2xZel1sKP/ivT8Czmqt/9NWn892pZTqUkql/fsRvG/Q57b0pLYhrfW/0FoPaq13431/+prWWipDLSilYv6FxfgtD+/B+5OsqOMvxnZdKXXI3/ROQC7CXtvTSHvIWq4Bb1NKRf2fge/Eu/5IrKCU6vZvdwI/wzr/rjZ1JceNtNrS61t8WtuSUuqTwJNAVik1BPw/tdZ/tLVntS09BvwScMrvLwb4l/4KpGJZH/B/+VfmG8AzWmsZQSfejB7gr72f71jAn2utv7S1p7Rt/SPgz/zC0iXgV7f4fLYtv1f23cDf3+pz2a601t9TSn0aeAWv5eEHyKqOq/krpVQnUAX+odZ6dq2Db9sxfUIIIYQQQmxHt3OLiBBCCCGEENuOBGwhhBBCCCE2kARsIYQQQgghNpAEbCGEEEIIITaQBGwhhBBCCCE2kARsIYQQLSmltFLqZ7f6PIQQ4nYjAVsIIbYhpdR/8wPuyo/vbvW5CSGEWNttu9CMEEK8BTyHt/hRvcpWnIgQQoj2SQVbCCG2r7LWemzFxwzU2jd+Syn1RaVUQSl1VSnVsBS7UupupdRzSqmiUmrGr4qnVhzz95RSp5RSZaXUuFLqv604hw6l1F8qpfJKqUstPse/8j93WSk1ppT641vxRgghxO1EArYQQty+/g3wOeA43vLGf6yUegBqy0R/CcgBDwEfAh4FPr70ZKXU3wf+T+ATwD3AjwOnV3yOfwX8d+Be4FPAx5VSu/znfxj4J8D/ABwAPgh8f+O/TCGEuL3IUulCCLEN+ZXkXwRKK3b9V631P1NKaeBjWutfr3vOc8CY1voXlVK/DvwHYFBrvejvfxL4OnBAa31RKTUE/KnW+p+vcg4a+Hda63/hP7aABeA3tNZ/qpT6n4C/DxzTWlc36msXQojbnfRgCyHE9vVN4DdWbJuru/+dFfu+A3zAv38X8KOlcO17AXCBI0qpBWAA+Oo65/CjpTtaa1spNQl0+5v+Evht4LJS6st4FfPPaa3L67ymEELc0aRFRAghtq+C1vriio+pNp+rgNX+RKn9/e1YWZnW+D87tNbXgUN4VewF4D8CLyulYm2+thBC3JEkYAshxO3rbS0en/XvnwHuVUol6vY/ivd9/6zWehwYBt75Zk5Aa13SWn9Ra/0/Ag8CR4HH3sxrCiHE7U5aRIQQYvsKKaV6V2xztNaT/v2fUUq9CJwEfhYvLD/s7/szvIsg/1gp9a+ADN4FjZ/RWl/0j/l/A/9fpdQ48EUgCrxTa/0f2zk5pdSv4P0c+R7exZQfwat4v36DX6cQQtxRJGALIcT29S5gdMW2YWDQv/+vgQ8DvwdMAr+qtX4RQGtdUEq9F/jf8SZ7lPCmgfz20gtprf8PpVQF+J+B3wVmgGdv4PzmgH+GdzFlAK9q/jNa68s38BpCCHHHkSkiQghxG/InfPwdrfWnt/pchBBCNJIebCGEEEIIITaQBGwhhBBCCCE2kLSICCGEEEIIsYGkgi2EEEIIIcQGkoAthBBCCCHEBpKALYQQQgghxAaSgC2EEEIIIcQGkoAthBBCCCHEBpKALYQQQgghxAb6/wPr1k6vXFAjhgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "\n",
    "for loss in ('loss', 'val_loss'):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    opt_names = 'SGD Momentum Nesterov AdaGrad RMSProp Adam Adamax Nadam AdamW'\n",
    "    for history, opt_name in zip(\n",
    "        [\n",
    "            history_sgd,\n",
    "            history_momentum,\n",
    "            history_nesterov,\n",
    "            history_adagrad,\n",
    "            history_rmsprop,\n",
    "            history_adam,\n",
    "            history_adamax,\n",
    "            history_nadam,\n",
    "            history_adamw,\n",
    "        ],\n",
    "        opt_names.split(),\n",
    "    ):\n",
    "        plt.plot(history.history[loss], label=f'{opt_name}', linewidth=3)\n",
    "\n",
    "    plt.grid()\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel({'loss': 'Training loss', 'val_loss': 'Validation loss'}[loss])\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.axis([0, 9, 0.1, 0.7])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling\n",
    "Finding a good learning rate is very important:\n",
    "- If we set it much too high, training may diverge. \n",
    "- If we set it too low, training will eventually converge to the optimum, but it will take a very long time. \n",
    "- If we set it slightly too high, it will make progress very quickly at first, but it will end up dancing around the optimum and never really settling down. \n",
    "\n",
    "If we have a limited computing budget, we may have to interrupt training before it has converged properly, yielding a suboptimal solution.\n",
    "\n",
    "<center>\n",
    "  <img \n",
    "    src=\"../images/11/learning_curves.png\" \n",
    "    onerror=\"\n",
    "      this.onerror = null;\n",
    "      const repo = 'https://github.com/alirezatheh/handson-ml3-notes/blob/main';\n",
    "      this.src = repo + this.src.split('..')[1];\n",
    "    \"\n",
    "  >\n",
    "</center>\n",
    "\n",
    "As discussed in Chapter 10, we can find a good learning rate by training the model for a few hundred iterations, exponentially increasing the learning rate from a very small value to a very large value, and then looking at the learning curve and picking a learning rate slightly lower than the one at which the learning curve starts shooting back up. We can then reinitialize our model and train it with that learning rate.\n",
    "\n",
    "But we can do better than a constant learning rate. These strategies are called \n",
    "*learning schedules*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Scheduling\n",
    "Set the learning rate to a function of the iteration number $t: \\eta(t)=\\eta_0/(1+t/s)^c$. The initial learning rate $\\eta_0$, the power $c$ (typically set to 1), and the steps $s$ are hyperparameters. The learning rate drops at each step. After $s$ steps, the learning rate is down to $\\eta_0/2$. After $s$ more steps it is down to $\\eta_0/3$, then it goes down to $\\eta_0/4$, then $\\eta_0/5$, and so on. This schedule first drops quickly, then more and more slowly. Power scheduling requires tuning $\\eta_0$ and $s$ (and possibly $c$).\n",
    "\n",
    "Keras sets $c$ to 1. There was a `decay` argument in Keras optimizers defined as inverse of $s$, but now it is deprecated. Those old optimizers are still available in `keras.optimizers.legacy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.legacy.SGD(learning_rate=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we should use the schedulers in `keras.optimizers.schedules` instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.InverseTimeDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=10_000,\n",
    "    decay_rate=1.0,\n",
    "    staircase=False,\n",
    ")\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `InverseTimeDecay` scheduler uses `learning_rate = initial_learning_rate / (1 + decay_rate * step / decay_steps)`. If we set `staircase=True`, then it replaces `step / decay_step` with `floor(step / decay_step)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.7004 - accuracy: 0.7588 - val_loss: 0.4991 - val_accuracy: 0.8206\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4781 - accuracy: 0.8316 - val_loss: 0.4477 - val_accuracy: 0.8372\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4293 - accuracy: 0.8487 - val_loss: 0.4177 - val_accuracy: 0.8498\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4053 - accuracy: 0.8563 - val_loss: 0.3987 - val_accuracy: 0.8602\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3864 - accuracy: 0.8633 - val_loss: 0.3859 - val_accuracy: 0.8612\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3720 - accuracy: 0.8675 - val_loss: 0.3942 - val_accuracy: 0.8584\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3616 - accuracy: 0.8709 - val_loss: 0.3706 - val_accuracy: 0.8670\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3529 - accuracy: 0.8741 - val_loss: 0.3758 - val_accuracy: 0.8638\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3452 - accuracy: 0.8765 - val_loss: 0.3587 - val_accuracy: 0.8680\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3379 - accuracy: 0.8793 - val_loss: 0.3569 - val_accuracy: 0.8714\n"
     ]
    }
   ],
   "source": [
    "history_power_scheduling = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\u2019s plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 460.8x345.6 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_learning_rate = 0.01\n",
    "decay_rate = 1.0\n",
    "decay_steps = 10_000\n",
    "\n",
    "steps = np.arange(100_000)\n",
    "lrs = initial_learning_rate / (1 + decay_rate * steps / decay_steps)\n",
    "lrs2 = initial_learning_rate / (1 + decay_rate * np.floor(steps / decay_steps))\n",
    "\n",
    "plt.plot(steps, lrs, '-', label='staircase=False')\n",
    "plt.plot(steps, lrs2, '-', label='staircase=True')\n",
    "plt.axis([0, steps.max(), 0, 0.0105])\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Power Scheduling', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Scheduling\n",
    "Set the learning rate to $\\eta(t)=\\eta_00.1^{t/s}$. The learning rate will gradually drop by a factor of 10 every $s$ steps. While power scheduling reduces the learning rate more and more slowly, exponential scheduling keeps slashing it by a factor of 10 every $s$ steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.01,\n",
    "    decay_steps=20_000,\n",
    "    decay_rate=0.1,\n",
    "    staircase=False,\n",
    ")\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ExponentialDecay` scheduler uses `learning_rate = initial_learning_rate * decay_rate ** (step / decay_steps)`. If we set `staircase=True`, then it replaces `step / decay_step` with `floor(step / decay_step)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6916 - accuracy: 0.7632 - val_loss: 0.5030 - val_accuracy: 0.8254\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4832 - accuracy: 0.8311 - val_loss: 0.4601 - val_accuracy: 0.8358\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4372 - accuracy: 0.8449 - val_loss: 0.4256 - val_accuracy: 0.8524\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.4131 - accuracy: 0.8546 - val_loss: 0.4037 - val_accuracy: 0.8568\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3952 - accuracy: 0.8596 - val_loss: 0.3950 - val_accuracy: 0.8598\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3825 - accuracy: 0.8640 - val_loss: 0.4010 - val_accuracy: 0.8584\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3739 - accuracy: 0.8667 - val_loss: 0.3851 - val_accuracy: 0.8650\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3664 - accuracy: 0.8696 - val_loss: 0.3811 - val_accuracy: 0.8616\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3606 - accuracy: 0.8720 - val_loss: 0.3749 - val_accuracy: 0.8662\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3555 - accuracy: 0.8743 - val_loss: 0.3706 - val_accuracy: 0.8662\n"
     ]
    }
   ],
   "source": [
    "history_exponential_scheduling = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\u2019s plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 460.8x345.6 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_learning_rate = 0.01\n",
    "decay_rate = 0.1\n",
    "decay_steps = 20_000\n",
    "\n",
    "steps = np.arange(100_000)\n",
    "lrs = initial_learning_rate * decay_rate ** (steps / decay_steps)\n",
    "lrs2 = initial_learning_rate * decay_rate ** np.floor(steps / decay_steps)\n",
    "\n",
    "plt.figure(dpi=72)\n",
    "plt.plot(steps, lrs, '-', label='staircase=False')\n",
    "plt.plot(steps, lrs2, '-', label='staircase=True')\n",
    "plt.axis([0, steps.max(), 0, 0.0105])\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Exponential Scheduling', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras also provides a `LearningRateScheduler` callback class that lets us define our own scheduling function. Let\u2019s see how we could use it to implement exponential decay. Note that in this case the learning rate only changes at each epoch, not at each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "def exponential_decay(lr0: float, s: int) -> Callable[[int], float]:\n",
    "    def exponential_decay_fn(epoch: int) -> float:\n",
    "        return lr0 * 0.1 ** (epoch / s)\n",
    "\n",
    "    return exponential_decay_fn\n",
    "\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\u2019s build and compile a model for Fashion MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "model = build_model()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.001)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6905 - accuracy: 0.7643 - val_loss: 0.4814 - val_accuracy: 0.8330 - lr: 0.0100\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4672 - accuracy: 0.8357 - val_loss: 0.4488 - val_accuracy: 0.8374 - lr: 0.0089\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.4212 - accuracy: 0.8503 - val_loss: 0.4118 - val_accuracy: 0.8532 - lr: 0.0079\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3975 - accuracy: 0.8593 - val_loss: 0.3884 - val_accuracy: 0.8636 - lr: 0.0071\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3781 - accuracy: 0.8657 - val_loss: 0.3772 - val_accuracy: 0.8642 - lr: 0.0063\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3634 - accuracy: 0.8710 - val_loss: 0.3779 - val_accuracy: 0.8662 - lr: 0.0056\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3530 - accuracy: 0.8744 - val_loss: 0.3674 - val_accuracy: 0.8652 - lr: 0.0050\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3437 - accuracy: 0.8771 - val_loss: 0.3616 - val_accuracy: 0.8686 - lr: 0.0045\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3359 - accuracy: 0.8801 - val_loss: 0.3509 - val_accuracy: 0.8728 - lr: 0.0040\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3290 - accuracy: 0.8826 - val_loss: 0.3504 - val_accuracy: 0.8720 - lr: 0.0035\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3236 - accuracy: 0.8844 - val_loss: 0.3458 - val_accuracy: 0.8736 - lr: 0.0032\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3186 - accuracy: 0.8869 - val_loss: 0.3459 - val_accuracy: 0.8752 - lr: 0.0028\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3147 - accuracy: 0.8878 - val_loss: 0.3359 - val_accuracy: 0.8770 - lr: 0.0025\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3109 - accuracy: 0.8890 - val_loss: 0.3404 - val_accuracy: 0.8762 - lr: 0.0022\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3076 - accuracy: 0.8902 - val_loss: 0.3398 - val_accuracy: 0.8790 - lr: 0.0020\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3043 - accuracy: 0.8915 - val_loss: 0.3331 - val_accuracy: 0.8784 - lr: 0.0018\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3020 - accuracy: 0.8924 - val_loss: 0.3363 - val_accuracy: 0.8774 - lr: 0.0016\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2998 - accuracy: 0.8927 - val_loss: 0.3356 - val_accuracy: 0.8778 - lr: 0.0014\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2979 - accuracy: 0.8935 - val_loss: 0.3309 - val_accuracy: 0.8796 - lr: 0.0013\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2961 - accuracy: 0.8940 - val_loss: 0.3308 - val_accuracy: 0.8782 - lr: 0.0011\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2944 - accuracy: 0.8951 - val_loss: 0.3286 - val_accuracy: 0.8802 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2930 - accuracy: 0.8953 - val_loss: 0.3313 - val_accuracy: 0.8804 - lr: 8.9125e-04\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2916 - accuracy: 0.8957 - val_loss: 0.3285 - val_accuracy: 0.8796 - lr: 7.9433e-04\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2904 - accuracy: 0.8961 - val_loss: 0.3313 - val_accuracy: 0.8786 - lr: 7.0795e-04\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2896 - accuracy: 0.8962 - val_loss: 0.3296 - val_accuracy: 0.8812 - lr: 6.3096e-04\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[lr_scheduler],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Tip**: After training, `history.history['lr']` gives us access to the list of learning rates used during training.\n",
    "\n",
    "When we save a model, the epoch does not get saved, and it gets reset to 0 every time we call the `fit()` method. If our schedule function uses the `epoch` argument, and we were to continue training a model where it left off, this could lead to a very large learning rate, which would likely damage our model\u2019s weights. One solution is to manually set the `fit()` method\u2019s `initial_epoch` argument so the epoch starts at the right value.\n",
    "\n",
    "Another option is to take the current learning rate as a second argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch: int, lr: float) -> float:\n",
    "    return lr * 0.1 ** (1 / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra material**: If we want to update the learning rate at each iteration rather than at each epoch, we can write our own callback class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "class ExponentialDecay(keras.callbacks.Callback):\n",
    "    def __init__(self, n_steps: int = 40_000) -> None:\n",
    "        super().__init__()\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "    def on_batch_begin(\n",
    "        self, batch: int, logs: Optional[dict[str, float]] = None\n",
    "    ) -> None:\n",
    "        # Note that the `batch` argument is reset at each epoch\n",
    "        lr = K.get_value(self.model.optimizer.learning_rate)\n",
    "        new_learning_rate = lr * 0.1 ** (1 / self.n_steps)\n",
    "        K.set_value(self.model.optimizer.learning_rate, new_learning_rate)\n",
    "\n",
    "    def on_epoch_end(\n",
    "        self, epoch: int, logs: Optional[dict[str, float]] = None\n",
    "    ) -> None:\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr0 = 0.01\n",
    "model = build_model()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr0)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6947 - accuracy: 0.7635 - val_loss: 0.5014 - val_accuracy: 0.8224 - lr: 0.0091\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4718 - accuracy: 0.8349 - val_loss: 0.4530 - val_accuracy: 0.8382 - lr: 0.0083\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4255 - accuracy: 0.8500 - val_loss: 0.4216 - val_accuracy: 0.8526 - lr: 0.0076\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4025 - accuracy: 0.8587 - val_loss: 0.3954 - val_accuracy: 0.8618 - lr: 0.0069\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3840 - accuracy: 0.8643 - val_loss: 0.3847 - val_accuracy: 0.8612 - lr: 0.0063\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3696 - accuracy: 0.8689 - val_loss: 0.3908 - val_accuracy: 0.8558 - lr: 0.0058\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3590 - accuracy: 0.8722 - val_loss: 0.3744 - val_accuracy: 0.8670 - lr: 0.0052\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3498 - accuracy: 0.8749 - val_loss: 0.3754 - val_accuracy: 0.8640 - lr: 0.0048\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3415 - accuracy: 0.8783 - val_loss: 0.3592 - val_accuracy: 0.8700 - lr: 0.0044\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3340 - accuracy: 0.8803 - val_loss: 0.3575 - val_accuracy: 0.8724 - lr: 0.0040\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3281 - accuracy: 0.8833 - val_loss: 0.3573 - val_accuracy: 0.8718 - lr: 0.0036\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3228 - accuracy: 0.8847 - val_loss: 0.3579 - val_accuracy: 0.8688 - lr: 0.0033\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3182 - accuracy: 0.8865 - val_loss: 0.3421 - val_accuracy: 0.8756 - lr: 0.0030\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3138 - accuracy: 0.8882 - val_loss: 0.3468 - val_accuracy: 0.8766 - lr: 0.0028\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3101 - accuracy: 0.8889 - val_loss: 0.3471 - val_accuracy: 0.8766 - lr: 0.0025\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3064 - accuracy: 0.8898 - val_loss: 0.3386 - val_accuracy: 0.8752 - lr: 0.0023\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3035 - accuracy: 0.8903 - val_loss: 0.3417 - val_accuracy: 0.8758 - lr: 0.0021\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3005 - accuracy: 0.8919 - val_loss: 0.3398 - val_accuracy: 0.8768 - lr: 0.0019\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2983 - accuracy: 0.8929 - val_loss: 0.3357 - val_accuracy: 0.8766 - lr: 0.0017\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2959 - accuracy: 0.8939 - val_loss: 0.3370 - val_accuracy: 0.8752 - lr: 0.0016\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2940 - accuracy: 0.8938 - val_loss: 0.3346 - val_accuracy: 0.8782 - lr: 0.0014\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2917 - accuracy: 0.8949 - val_loss: 0.3361 - val_accuracy: 0.8766 - lr: 0.0013\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2902 - accuracy: 0.8955 - val_loss: 0.3349 - val_accuracy: 0.8796 - lr: 0.0012\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2884 - accuracy: 0.8959 - val_loss: 0.3364 - val_accuracy: 0.8796 - lr: 0.0011\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2871 - accuracy: 0.8969 - val_loss: 0.3352 - val_accuracy: 0.8802 - lr: 1.0000e-03\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "batch_size = 32\n",
    "n_steps = n_epochs * math.ceil(len(X_train) / batch_size)\n",
    "exp_decay = ExponentialDecay(n_steps)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[exp_decay],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Piecewise Constant Scheduling\n",
    "Use a constant learning rate for a number of epochs (e.g., $\\eta_0=0.1$ for 5 epochs), then a smaller learning rate for another number of epochs (e.g., $\\eta_0=0.001$ for 50 epochs), and so on. Although this solution can work very well, it requires fiddling around to figure out the right sequence of learning rates and how long to use each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[50_000, 80_000], values=[0.01, 0.005, 0.001]\n",
    ")\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.6942 - accuracy: 0.7617 - val_loss: 0.4892 - val_accuracy: 0.8318\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4751 - accuracy: 0.8340 - val_loss: 0.4603 - val_accuracy: 0.8346\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4280 - accuracy: 0.8500 - val_loss: 0.4245 - val_accuracy: 0.8542\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4035 - accuracy: 0.8581 - val_loss: 0.3867 - val_accuracy: 0.8626\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3828 - accuracy: 0.8650 - val_loss: 0.3827 - val_accuracy: 0.8634\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3665 - accuracy: 0.8700 - val_loss: 0.3880 - val_accuracy: 0.8608\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.3539 - accuracy: 0.8730 - val_loss: 0.3669 - val_accuracy: 0.8688\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3423 - accuracy: 0.8773 - val_loss: 0.3583 - val_accuracy: 0.8708\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3322 - accuracy: 0.8807 - val_loss: 0.3447 - val_accuracy: 0.8758\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3218 - accuracy: 0.8832 - val_loss: 0.3488 - val_accuracy: 0.8716\n"
     ]
    }
   ],
   "source": [
    "history_piecewise_scheduling = build_and_train_model(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\u2019s plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 460.8x345.6 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boundaries = [50_000, 80_000]\n",
    "values = [0.01, 0.005, 0.001]\n",
    "\n",
    "steps = np.arange(100_000)\n",
    "\n",
    "lrs = np.full(len(steps), values[0])\n",
    "for boundary, value in zip(boundaries, values[1:]):\n",
    "    lrs[boundary:] = value\n",
    "\n",
    "plt.plot(steps, lrs, '-')\n",
    "plt.axis([0, steps.max(), 0, 0.0105])\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Piecewise Constant Scheduling', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we did with exponential scheduling, we could also implement piecewise constant scheduling manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def piecewise_constant(\n",
    "    boundaries: list[int], values: list[float]\n",
    ") -> Callable[[int], list[float]]:\n",
    "    boundaries = np.array([0] + boundaries)\n",
    "    values = np.array(values)\n",
    "\n",
    "    def piecewise_constant_fn(epoch: int) -> list[float]:\n",
    "        return values[(boundaries > epoch).argmax() - 1]\n",
    "\n",
    "    return piecewise_constant_fn\n",
    "\n",
    "\n",
    "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 5s 2ms/step - loss: 0.5433 - accuracy: 0.8087 - val_loss: 0.4586 - val_accuracy: 0.8288 - lr: 0.0100\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4487 - accuracy: 0.8439 - val_loss: 0.4608 - val_accuracy: 0.8350 - lr: 0.0100\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4263 - accuracy: 0.8502 - val_loss: 0.4234 - val_accuracy: 0.8568 - lr: 0.0100\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4241 - accuracy: 0.8537 - val_loss: 0.4359 - val_accuracy: 0.8490 - lr: 0.0100\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4080 - accuracy: 0.8584 - val_loss: 0.4165 - val_accuracy: 0.8560 - lr: 0.0100\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3544 - accuracy: 0.8738 - val_loss: 0.3830 - val_accuracy: 0.8662 - lr: 0.0050\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3464 - accuracy: 0.8761 - val_loss: 0.4026 - val_accuracy: 0.8652 - lr: 0.0050\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3426 - accuracy: 0.8772 - val_loss: 0.4212 - val_accuracy: 0.8544 - lr: 0.0050\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3417 - accuracy: 0.8793 - val_loss: 0.4116 - val_accuracy: 0.8612 - lr: 0.0050\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3339 - accuracy: 0.8804 - val_loss: 0.4090 - val_accuracy: 0.8618 - lr: 0.0050\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3309 - accuracy: 0.8819 - val_loss: 0.4033 - val_accuracy: 0.8746 - lr: 0.0050\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3270 - accuracy: 0.8826 - val_loss: 0.4518 - val_accuracy: 0.8630 - lr: 0.0050\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3270 - accuracy: 0.8837 - val_loss: 0.3714 - val_accuracy: 0.8674 - lr: 0.0050\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3247 - accuracy: 0.8844 - val_loss: 0.4026 - val_accuracy: 0.8652 - lr: 0.0050\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3204 - accuracy: 0.8852 - val_loss: 0.3993 - val_accuracy: 0.8724 - lr: 0.0050\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2859 - accuracy: 0.8963 - val_loss: 0.3930 - val_accuracy: 0.8736 - lr: 0.0010\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2781 - accuracy: 0.8978 - val_loss: 0.4021 - val_accuracy: 0.8714 - lr: 0.0010\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2743 - accuracy: 0.8984 - val_loss: 0.3955 - val_accuracy: 0.8754 - lr: 0.0010\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2704 - accuracy: 0.8999 - val_loss: 0.4015 - val_accuracy: 0.8756 - lr: 0.0010\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2683 - accuracy: 0.9015 - val_loss: 0.4161 - val_accuracy: 0.8756 - lr: 0.0010\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2655 - accuracy: 0.9020 - val_loss: 0.4207 - val_accuracy: 0.8740 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2646 - accuracy: 0.9020 - val_loss: 0.4497 - val_accuracy: 0.8746 - lr: 0.0010\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2626 - accuracy: 0.9032 - val_loss: 0.4429 - val_accuracy: 0.8762 - lr: 0.0010\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2608 - accuracy: 0.9038 - val_loss: 0.4566 - val_accuracy: 0.8748 - lr: 0.0010\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2587 - accuracy: 0.9038 - val_loss: 0.4726 - val_accuracy: 0.8770 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 25\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "\n",
    "model = build_model()\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=lr0)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[lr_scheduler],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We\u2019ve looked at `InverseTimeDecay`, `ExponentialDecay`, and `PiecewiseConstantDecay`. A few more schedulers are available in `keras.optimizers.schedules`, here is the full list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2022 CosineDecay - A LearningRateSchedule that uses a cosine decay with optional warmup.\n",
      "\u2022 CosineDecayRestarts - A LearningRateSchedule that uses a cosine decay schedule with restarts.\n",
      "\u2022 ExponentialDecay - A LearningRateSchedule that uses an exponential decay schedule.\n",
      "\u2022 InverseTimeDecay - A LearningRateSchedule that uses an inverse time decay schedule.\n",
      "\u2022 LearningRateSchedule - The learning rate schedule base class.\n",
      "\u2022 PiecewiseConstantDecay - A LearningRateSchedule that uses a piecewise constant decay schedule.\n",
      "\u2022 PolynomialDecay - A LearningRateSchedule that uses a polynomial decay schedule.\n"
     ]
    }
   ],
   "source": [
    "for name in sorted(dir(keras.optimizers.schedules)):\n",
    "    # Must start with capital letter\n",
    "    if name[0] == name[0].lower():\n",
    "        continue\n",
    "    scheduler_class = getattr(keras.optimizers.schedules, name)\n",
    "    print(f'\u2022 {name} - {scheduler_class.__doc__.splitlines()[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Performance Scheduling\n",
    "Measure the validation error every $N$ steps (just like for early stopping), and reduce the learning rate by a factor of $\\lambda$ when the error stops dropping.\n",
    "\n",
    "Let\u2019s build and compile a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr0)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.6807 - accuracy: 0.7679 - val_loss: 0.4814 - val_accuracy: 0.8310 - lr: 0.0100\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4659 - accuracy: 0.8343 - val_loss: 0.4615 - val_accuracy: 0.8306 - lr: 0.0100\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.4201 - accuracy: 0.8505 - val_loss: 0.4199 - val_accuracy: 0.8490 - lr: 0.0100\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3957 - accuracy: 0.8590 - val_loss: 0.3845 - val_accuracy: 0.8614 - lr: 0.0100\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3754 - accuracy: 0.8658 - val_loss: 0.3742 - val_accuracy: 0.8614 - lr: 0.0100\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3588 - accuracy: 0.8709 - val_loss: 0.3853 - val_accuracy: 0.8628 - lr: 0.0100\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3469 - accuracy: 0.8740 - val_loss: 0.3627 - val_accuracy: 0.8690 - lr: 0.0100\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3346 - accuracy: 0.8785 - val_loss: 0.3574 - val_accuracy: 0.8680 - lr: 0.0100\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3244 - accuracy: 0.8828 - val_loss: 0.3410 - val_accuracy: 0.8748 - lr: 0.0100\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3149 - accuracy: 0.8850 - val_loss: 0.3410 - val_accuracy: 0.8720 - lr: 0.0100\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3074 - accuracy: 0.8879 - val_loss: 0.3629 - val_accuracy: 0.8678 - lr: 0.0100\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2990 - accuracy: 0.8920 - val_loss: 0.3379 - val_accuracy: 0.8746 - lr: 0.0100\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2929 - accuracy: 0.8938 - val_loss: 0.3223 - val_accuracy: 0.8808 - lr: 0.0100\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2867 - accuracy: 0.8947 - val_loss: 0.3405 - val_accuracy: 0.8754 - lr: 0.0100\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2807 - accuracy: 0.8972 - val_loss: 0.3480 - val_accuracy: 0.8730 - lr: 0.0100\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2743 - accuracy: 0.8998 - val_loss: 0.3350 - val_accuracy: 0.8766 - lr: 0.0100\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2694 - accuracy: 0.9019 - val_loss: 0.3421 - val_accuracy: 0.8764 - lr: 0.0100\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2631 - accuracy: 0.9032 - val_loss: 0.3360 - val_accuracy: 0.8772 - lr: 0.0100\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2445 - accuracy: 0.9110 - val_loss: 0.3162 - val_accuracy: 0.8874 - lr: 0.0050\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2410 - accuracy: 0.9131 - val_loss: 0.3221 - val_accuracy: 0.8812 - lr: 0.0050\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2380 - accuracy: 0.9137 - val_loss: 0.3166 - val_accuracy: 0.8828 - lr: 0.0050\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2351 - accuracy: 0.9148 - val_loss: 0.3146 - val_accuracy: 0.8854 - lr: 0.0050\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2330 - accuracy: 0.9160 - val_loss: 0.3191 - val_accuracy: 0.8836 - lr: 0.0050\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2300 - accuracy: 0.9161 - val_loss: 0.3175 - val_accuracy: 0.8878 - lr: 0.0050\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2276 - accuracy: 0.9174 - val_loss: 0.3205 - val_accuracy: 0.8868 - lr: 0.0050\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[lr_scheduler],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\u2019s plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history['lr'], 'bo-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning Rate', color='b')\n",
    "plt.tick_params('y', colors='b')\n",
    "plt.gca().set_xlim(0, n_epochs - 1)\n",
    "plt.grid(True)\n",
    "\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(history.epoch, history.history['val_loss'], 'r^-')\n",
    "ax2.set_ylabel('Validation Loss', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "plt.title('Reduce LR on Plateau', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1Cycle Scheduling\n",
    "1cycle was introduced in a 2018 paper [\u201cA Disciplined Approach to Neural Network Hyper-Parameters: Part 1\u2014Learning Rate, Batch Size, Momentum, and Weight Decay\u201d](https://homl.info/1cycle) by Leslie Smith. It starts by increasing the initial learning rate $\\eta_0$, growing linearly up to $\\eta_1$ halfway through training. Then it decreases the learning rate linearly down to $\\eta_0$ again during the second half of training, finishing the last few epochs by dropping the rate down by several orders of magnitude (still linearly). $\\eta_1$ is chosen using the same approach we used to find the optimal learning rate, and $eta_0$ is usually 10 times lower.\n",
    "\n",
    "When using a momentum, we start with a high momentum first (e.g., 0.95), then drop it down to a lower momentum during the first half of training (e.g., down to 0.85, linearly), and then bring it back up to the maximum value (e.g., 0.95) during the second half of training, finishing the last few epochs with that maximum value. This feat was dubbed *super-convergence*.\n",
    "\n",
    "The `ExponentialLearningRate` custom callback updates the learning rate during training, at the end of each batch. It multiplies it by a constant `factor`. It also saves the learning rate and loss at each batch. Since `logs['loss']` is actually the mean loss since the start of the epoch, and we want to save the batch loss instead, we must compute the mean times the number of batches since the beginning of the epoch to get the total loss so far, then we subtract the total loss at the previous batch to get the current batch\u2019s loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor: float) -> None:\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_begin(\n",
    "        self, epoch: int, logs: Optional[dict[str, float]] = None\n",
    "    ) -> None:\n",
    "        self.sum_of_epoch_losses = 0\n",
    "\n",
    "    def on_batch_end(\n",
    "        self, batch: int, logs: Optional[dict[str, float]] = None\n",
    "    ) -> None:\n",
    "        # The epoch\u2019s mean loss so far\n",
    "        mean_epoch_loss = logs['loss']\n",
    "        new_sum_of_epoch_losses = mean_epoch_loss * (batch + 1)\n",
    "        batch_loss = new_sum_of_epoch_losses - self.sum_of_epoch_losses\n",
    "        self.sum_of_epoch_losses = new_sum_of_epoch_losses\n",
    "        self.rates.append(K.get_value(self.model.optimizer.learning_rate))\n",
    "        self.losses.append(batch_loss)\n",
    "        K.set_value(\n",
    "            self.model.optimizer.learning_rate,\n",
    "            self.model.optimizer.learning_rate * self.factor,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_learning_rate()` function trains the model using the `ExponentialLearningRate` callback, and it returns the learning rates and  corresponding batch losses. At the end, it restores the model and its optimizer to their initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_learning_rate(\n",
    "    model: keras.Model,\n",
    "    X: TensorLike,\n",
    "    y: TensorLike,\n",
    "    epochs: int = 1,\n",
    "    batch_size: int = 32,\n",
    "    min_rate: float = 1e-4,\n",
    "    max_rate: float = 1,\n",
    ") -> tuple[list[float], ...]:\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = math.ceil(len(X) / batch_size) * epochs\n",
    "    factor = (max_rate / min_rate) ** (1 / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.learning_rate)\n",
    "    K.set_value(model.optimizer.learning_rate, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.learning_rate, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `plot_lr_vs_loss()` function plots the learning rates vs the losses. The optimal learning rate to use as the maximum learning rate in 1cycle is near the bottom of the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lr_vs_loss(rates: list[float], losses: list[float]) -> None:\n",
    "    plt.plot(rates, losses, 'b')\n",
    "    plt.gca().set_xscale('log')\n",
    "    max_loss = losses[0] + min(losses)\n",
    "    plt.hlines(min(losses), min(rates), max(rates), color='k')\n",
    "    plt.axis([min(rates), max(rates), 0, max_loss])\n",
    "    plt.xlabel('Learning rate')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\u2019s build a simple Fashion MNIST model and compile it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let\u2019s find the optimal max learning rate for 1cycle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/430 [==============================] - 1s 1ms/step - loss: 1.7725 - accuracy: 0.4122\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(\n",
    "    model, X_train, y_train, epochs=1, batch_size=batch_size\n",
    ")\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the max learning rate to use for 1cycle is around $10^{-1}$.\n",
    "\n",
    "The `OneCycleScheduler` custom callback updates the learning rate at the beginning of each batch. It applies the logic described earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        iterations: int,\n",
    "        max_lr: float = 1e-3,\n",
    "        start_lr: Optional[float] = None,\n",
    "        last_iterations: Optional[int] = None,\n",
    "        last_lr: Optional[float] = None,\n",
    "    ) -> None:\n",
    "        self.iterations = iterations\n",
    "        self.max_lr = max_lr\n",
    "        self.start_lr = start_lr or max_lr / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_lr = last_lr or self.start_lr / 1000\n",
    "        self.iteration = 0\n",
    "\n",
    "    def _interpolate(\n",
    "        self, iter1: int, iter2: int, lr1: float, lr2: float\n",
    "    ) -> float:\n",
    "        return (self.iteration - iter1) * (lr2 - lr1) / (iter2 - iter1) + lr1\n",
    "\n",
    "    def on_batch_begin(self, batch: int, logs: dict[str, float]) -> None:\n",
    "        if self.iteration < self.half_iteration:\n",
    "            lr = self._interpolate(\n",
    "                0, self.half_iteration, self.start_lr, self.max_lr\n",
    "            )\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            lr = self._interpolate(\n",
    "                self.half_iteration,\n",
    "                2 * self.half_iteration,\n",
    "                self.max_lr,\n",
    "                self.start_lr,\n",
    "            )\n",
    "        else:\n",
    "            lr = self._interpolate(\n",
    "                2 * self.half_iteration,\n",
    "                self.iterations,\n",
    "                self.start_lr,\n",
    "                self.last_lr,\n",
    "            )\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.learning_rate, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\u2019s build and compile a simple Fashion MNIST model, then train it using the `OneCycleScheduler` callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "430/430 [==============================] - 1s 2ms/step - loss: 0.9502 - accuracy: 0.6913 - val_loss: 0.6003 - val_accuracy: 0.7874\n",
      "Epoch 2/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.5695 - accuracy: 0.8025 - val_loss: 0.4918 - val_accuracy: 0.8248\n",
      "Epoch 3/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.4954 - accuracy: 0.8252 - val_loss: 0.4762 - val_accuracy: 0.8264\n",
      "Epoch 4/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.4515 - accuracy: 0.8402 - val_loss: 0.4261 - val_accuracy: 0.8478\n",
      "Epoch 5/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.4225 - accuracy: 0.8492 - val_loss: 0.4066 - val_accuracy: 0.8486\n",
      "Epoch 6/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.3958 - accuracy: 0.8571 - val_loss: 0.4787 - val_accuracy: 0.8224\n",
      "Epoch 7/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.3787 - accuracy: 0.8626 - val_loss: 0.3917 - val_accuracy: 0.8566\n",
      "Epoch 8/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.3630 - accuracy: 0.8683 - val_loss: 0.4719 - val_accuracy: 0.8296\n",
      "Epoch 9/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.3512 - accuracy: 0.8724 - val_loss: 0.3673 - val_accuracy: 0.8652\n",
      "Epoch 10/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.3360 - accuracy: 0.8766 - val_loss: 0.4957 - val_accuracy: 0.8466\n",
      "Epoch 11/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.3287 - accuracy: 0.8786 - val_loss: 0.4187 - val_accuracy: 0.8370\n",
      "Epoch 12/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.3173 - accuracy: 0.8815 - val_loss: 0.3425 - val_accuracy: 0.8728\n",
      "Epoch 13/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.2961 - accuracy: 0.8910 - val_loss: 0.3217 - val_accuracy: 0.8792\n",
      "Epoch 14/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.2818 - accuracy: 0.8958 - val_loss: 0.3734 - val_accuracy: 0.8692\n",
      "Epoch 15/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.2675 - accuracy: 0.9003 - val_loss: 0.3261 - val_accuracy: 0.8844\n",
      "Epoch 16/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.2558 - accuracy: 0.9055 - val_loss: 0.3205 - val_accuracy: 0.8820\n",
      "Epoch 17/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.2464 - accuracy: 0.9091 - val_loss: 0.3089 - val_accuracy: 0.8894\n",
      "Epoch 18/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.2368 - accuracy: 0.9115 - val_loss: 0.3130 - val_accuracy: 0.8870\n",
      "Epoch 19/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.2292 - accuracy: 0.9145 - val_loss: 0.3078 - val_accuracy: 0.8854\n",
      "Epoch 20/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.2205 - accuracy: 0.9186 - val_loss: 0.3092 - val_accuracy: 0.8886\n",
      "Epoch 21/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.2138 - accuracy: 0.9209 - val_loss: 0.3022 - val_accuracy: 0.8914\n",
      "Epoch 22/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.2073 - accuracy: 0.9232 - val_loss: 0.3054 - val_accuracy: 0.8914\n",
      "Epoch 23/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.2020 - accuracy: 0.9261 - val_loss: 0.3026 - val_accuracy: 0.8896\n",
      "Epoch 24/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.1989 - accuracy: 0.9273 - val_loss: 0.3020 - val_accuracy: 0.8922\n",
      "Epoch 25/25\n",
      "430/430 [==============================] - 1s 1ms/step - loss: 0.1967 - accuracy: 0.9276 - val_loss: 0.3016 - val_accuracy: 0.8920\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.SGD(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "n_epochs = 25\n",
    "onecycle = OneCycleScheduler(\n",
    "    math.ceil(len(X_train) / batch_size) * n_epochs, max_lr=0.1\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[onecycle],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "A 2013 paper [\u201cAn Empirical Study of Learning Rates in Deep Neural Networks for Speech Recognition\u201d](https://homl.info/63) by Andrew Senior et al. compared the performance of some of the most popular learning schedules when using momentum optimization to train deep neural networks for speech recognition. In that setting, both performance scheduling and exponential scheduling performed well. 1cycle approach seems to perform even better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoiding Overfitting Through Regularization\n",
    "    With four parameters I can fit an elephant and with five I can make him wiggle his trunk.\n",
    "    \u2014John von Neumann\n",
    "    \n",
    "With thousands of parameters, we can fit the whole zoo. We already know about early stopping and batch normalization. Let\u2019s examine other popular regularization techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\ell_1$ and $\\ell_2$ Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(\n",
    "    100,\n",
    "    activation='relu',\n",
    "    kernel_initializer='he_normal',\n",
    "    kernel_regularizer=keras.regularizers.l2(0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `l2()` function returns a regularizer that will be called at each step during training to compute the regularization loss. This is then added to the final loss. \n",
    "\n",
    "Or use `l1(0.1)` for $\\ell_1$ regularization with a factor of 0.1, or `l1_l2(0.1, 0.01)` for both $\\ell_1$ and $\\ell_2$ regularization, with factors 0.1 and 0.01 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(\n",
    "    keras.layers.Dense,\n",
    "    activation='relu',\n",
    "    kernel_initializer='he_normal',\n",
    "    kernel_regularizer=keras.regularizers.l2(0.01),\n",
    ")\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        RegularizedDense(100),\n",
    "        RegularizedDense(100),\n",
    "        RegularizedDense(10, activation='softmax'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\u2019s Compile and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1719/1719 [==============================] - 2s 878us/step - loss: 3.1224 - accuracy: 0.7748 - val_loss: 1.8602 - val_accuracy: 0.8264\n",
      "Epoch 2/2\n",
      "1719/1719 [==============================] - 1s 814us/step - loss: 1.4263 - accuracy: 0.8159 - val_loss: 1.1269 - val_accuracy: 0.8182\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.02)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train, epochs=2, validation_data=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "It was proposed in a paper [\u201cImproving Neural Networks by Preventing Co-Adaptation of Feature Detectors\u201d](https://homl.info/64) by Geoffrey Hinton et al. in 2012 and further detailed in a 2014 paper [\u201cDropout: A Simple Way to Prevent Neural Networks from Overfitting\u201d,](https://homl.info/65) by Nitish Srivastava et al. \n",
    "\n",
    "At every training step, every neuron (including the input neurons, but always excluding the output neurons) has a probability $p$ of being temporarily \u201cdropped out\u201d, meaning it will be entirely ignored during this training step, but it may be active during the next step. The hyperparameter $p$ is called the *dropout rate*, and it is typically set between 10% and 50%: closer to 20%\u201330% in recurrent neural nets, and closer to 40%\u201350% in convolutional neural networks. After training, neurons don\u2019t get dropped anymore.\n",
    "\n",
    "Suppose $p$ is 75%: on average only 25% of all neurons are active at each step during training. This means that after training, a neuron would be connected to four times as many input neurons as it would be during training. To compensate for this fact, we need to multiply each neuron\u2019s input connection weights by four during training. If we don\u2019t, the neural network will not perform well as it will see different data during and after training. More generally, we need to divide the connection weights by the *keep probability* ($1-p$) during training.\n",
    "\n",
    "Neurons trained with dropout cannot co-adapt with their neighboring neurons; they have to be as useful as possible on their own. They also cannot rely excessively on just a few input neurons; they must pay attention to each of their input neurons. They end up being less sensitive to slight changes in the inputs. In the end, we get a more robust network that generalizes better.\n",
    "\n",
    "**Tip**: In practice, we can usually apply dropout only to the neurons in the top one to three layers (excluding the output layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.Dropout(rate=0.2),\n",
    "        keras.layers.Dense(\n",
    "            100, activation='relu', kernel_initializer='he_normal'\n",
    "        ),\n",
    "        keras.layers.Dropout(rate=0.2),\n",
    "        keras.layers.Dense(\n",
    "            100, activation='relu', kernel_initializer='he_normal'\n",
    "        ),\n",
    "        keras.layers.Dropout(rate=0.2),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\u2019s compile and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.6703 - accuracy: 0.7536 - val_loss: 0.4498 - val_accuracy: 0.8342\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 996us/step - loss: 0.5103 - accuracy: 0.8136 - val_loss: 0.4401 - val_accuracy: 0.8296\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 998us/step - loss: 0.4712 - accuracy: 0.8263 - val_loss: 0.3806 - val_accuracy: 0.8554\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 977us/step - loss: 0.4488 - accuracy: 0.8337 - val_loss: 0.3711 - val_accuracy: 0.8608\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4342 - accuracy: 0.8409 - val_loss: 0.3672 - val_accuracy: 0.8606\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 983us/step - loss: 0.4245 - accuracy: 0.8427 - val_loss: 0.3706 - val_accuracy: 0.8600\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 995us/step - loss: 0.4131 - accuracy: 0.8467 - val_loss: 0.3582 - val_accuracy: 0.8650\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 959us/step - loss: 0.4074 - accuracy: 0.8484 - val_loss: 0.3478 - val_accuracy: 0.8708\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 997us/step - loss: 0.4024 - accuracy: 0.8533 - val_loss: 0.3556 - val_accuracy: 0.8690\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 998us/step - loss: 0.3903 - accuracy: 0.8552 - val_loss: 0.3453 - val_accuracy: 0.8732\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train, epochs=10, validation_data=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: The training accuracy looks like it\u2019s lower than the validation accuracy, but that\u2019s just because dropout is only active during training. If we evaluate the model on the training set after training (i.e., with dropout turned off), we get the \u201creal\u201d training accuracy, which is very slightly higher than the validation accuracy and the test accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 1s 578us/step - loss: 0.3082 - accuracy: 0.8849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30816400051116943, 0.8849090933799744]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 588us/step - loss: 0.3629 - accuracy: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3628920316696167, 0.8700000047683716]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: If we want to regularize a self-normalizing network based on the SELU activation function, we should use *alpha dropout*: this is a variant of dropout that preserves the mean and standard deviation of its inputs. It was introduced in the same paper as SELU, as regular dropout would break self-normalization. Keras includes `AlphaDropout`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo (MC) Dropout\n",
    "In 2016, a paper [\u201cDropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning\u201d](https://homl.info/mcdropout) by Yarin Gal and \n",
    "Zoubin Ghahramani added a few more good reasons to use dropout:\n",
    "- First, they established a profound connection between dropout networks and approximate Bayesian inference (Specifically, they show that training a dropout network is mathematically equivalent to approximate Bayesian inference in a specific type of probabilistic model called a *deep Gaussian process*), giving dropout a solid mathematical justification.\n",
    "- Second, the authors introduced a powerful technique called *MC dropout*, which can boost the performance of any trained dropout model without having to retrain it or even modify it at all. It also provides a much better measure of the model\u2019s uncertainty, and it can be implemented in just a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Note**: `model(X)` is similar to `model.predict(X)` except it returns a tensor rather than a NumPy array, and it supports the `training` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test, training=True) for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`training=True` ensures that the `Dropout` layer remains active, so all predictions will be a bit different. We just make 100 predictions over the test set, and we compute their average. Averaging over multiple predictions with dropout turned on gives us a Monte Carlo estimate that is generally more reliable than the result of a single prediction with dropout turned off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.   , 0.   , 0.024, 0.   , 0.132, 0.   ,\n",
       "        0.844]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[:1]).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The model is fairly confident (84.4%) that this image belongs to class 9 (ankle boot). Compare this with the MC dropout prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.   , 0.   , 0.   , 0.   , 0.067, 0.   , 0.209, 0.001,\n",
       "       0.723], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba[0].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The model still seems to prefer class 9, but its confidence dropped down to 72.3%, and the estimated probabilities for classes 5 (sandal) and 7 (sneaker) have increased, which makes sense given they\u2019re also footwear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.   , 0.   , 0.   , 0.001, 0.   , 0.096, 0.   , 0.162, 0.001,\n",
       "       0.183], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "y_std[0].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If we were building a risk-sensitive system (e.g., a medical or financial \n",
    "system), we would probably treat such an uncertain prediction with extreme \n",
    "caution. We would definitely not treat it like an 84.4% confident prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8717"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_proba.argmax(axis=1)\n",
    "accuracy = (y_pred == y_test).sum() / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Note**: The number of Monte Carlo samples we use (100 in this example) is a hyperparameter we can tweak.\n",
    "\n",
    "If our model contains other layers that behave in a special way during training (such as `BatchNormalization` layers), then we should not force training mode like we just did. Instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(\n",
    "        self, inputs: TensorLike, training: Optional[float] = None\n",
    "    ) -> TensorLike:\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to convert `Dropout` to `MCDropout` in a `Sequential` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropout = keras.layers.Dropout\n",
    "mc_model = keras.Sequential(\n",
    "    [\n",
    "        MCDropout(layer.rate) if isinstance(layer, Dropout) else layer\n",
    "        for layer in model.layers\n",
    "    ]\n",
    ")\n",
    "mc_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_22 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "mc_dropout (MCDropout)       (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "mc_dropout_1 (MCDropout)     (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "mc_dropout_2 (MCDropout)     (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the model with MC Dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.17, 0.  , 0.76]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "np.mean([mc_model.predict(X_test[:1]) for sample in range(100)], axis=0).round(\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max-Norm Regularization\n",
    "For each neuron, it constrains the weights $\\mathbf{w}$ of the incoming connections such that $\\|\\mathbf{w}\\|_2\\leq r$, where $R$ is the max-norm hyperparameter. Max-norm does not add a regularization loss term to the overall loss function. Instead, it is typically implemented by computing $\\|\\mathbf{w}\\|_2$ after each training step and rescaling $\\mathbf{w}$ if needed ($\\mathbf{w}\\gets\\mathbf{w}r/\\|\\mathbf{w}\\|_2$).\n",
    "\n",
    "Max-norm regularization can also help alleviate the unstable gradients problems (if we are not using batch normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = keras.layers.Dense(\n",
    "    100,\n",
    "    activation='relu',\n",
    "    kernel_initializer='he_normal',\n",
    "    kernel_constraint=keras.constraints.max_norm(1.0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to apply max norm to every hidden layer in a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5500 - accuracy: 0.8015 - val_loss: 0.4510 - val_accuracy: 0.8242\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 2s 960us/step - loss: 0.4089 - accuracy: 0.8499 - val_loss: 0.3956 - val_accuracy: 0.8504\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 2s 974us/step - loss: 0.3777 - accuracy: 0.8604 - val_loss: 0.3693 - val_accuracy: 0.8680\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 2s 943us/step - loss: 0.3581 - accuracy: 0.8690 - val_loss: 0.3517 - val_accuracy: 0.8716\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 2s 949us/step - loss: 0.3416 - accuracy: 0.8729 - val_loss: 0.3433 - val_accuracy: 0.8682\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 2s 951us/step - loss: 0.3368 - accuracy: 0.8756 - val_loss: 0.4045 - val_accuracy: 0.8582\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 2s 935us/step - loss: 0.3293 - accuracy: 0.8767 - val_loss: 0.4168 - val_accuracy: 0.8476\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 2s 951us/step - loss: 0.3258 - accuracy: 0.8779 - val_loss: 0.3570 - val_accuracy: 0.8674\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 2s 970us/step - loss: 0.3269 - accuracy: 0.8787 - val_loss: 0.3702 - val_accuracy: 0.8578\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 2s 948us/step - loss: 0.3169 - accuracy: 0.8809 - val_loss: 0.3907 - val_accuracy: 0.8578\n"
     ]
    }
   ],
   "source": [
    "MaxNormDense = partial(\n",
    "    keras.layers.Dense,\n",
    "    activation='relu',\n",
    "    kernel_initializer='he_normal',\n",
    "    kernel_constraint=keras.constraints.max_norm(1.0),\n",
    ")\n",
    "\n",
    "keras.utils.set_random_seed(42)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        MaxNormDense(100),\n",
    "        MaxNormDense(100),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ]\n",
    ")\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train, epochs=10, validation_data=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After each training iteration, the model\u2019s `fit()` method will call the object returned by `max_norm()`, passing it the layer\u2019s weights and getting rescaled weights in return, which then replace the layer\u2019s weights.\n",
    "\n",
    "The `max_norm()` function has an axis argument that defaults to 0. A Dense layer usually has weights of shape [*number of inputs*, *number of neurons*], so using `axis=0` means that the max-norm constraint will apply independently to each neuron\u2019s weight vector. If we want to use max-norm with convolutional layers, make sure to set the `max_norm()` constraint\u2019s axis argument appropriately (usually `axis=[0, 1, 2]`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Summary and Practical Guidelines\n",
    "In this chapter we have covered a wide range of techniques, and we may be wondering which ones we should use. This depends on the task, and there is no clear consensus yet, but I have found the configuration in table below to work fine in most cases, without requiring much hyperparameter tuning. That said, please do not consider these defaults as hard rules!\n",
    "\n",
    "| Hyperparameter         | Default value                           |\n",
    "|------------------------|-----------------------------------------|\n",
    "| Kernel initializer     | He initialization                       |\n",
    "| Activation function    | ReLU if shallow; Swish if deep          |\n",
    "| Normalization          | None if shallow; batch norm if deep     |\n",
    "| Regularization         | Early stopping; weight decay if needed  |\n",
    "| Optimizer              | Nesterov accelerated gradients or AdamW |\n",
    "| Learning rate schedule | Performance scheduling or 1cycle        |\n",
    "\n",
    "If the network is a simple stack of dense layers, then it can self-normalize, and we should use the configuration in following table instead:\n",
    "\n",
    "| Hyperparameter         | Default value                    |\n",
    "|------------------------|----------------------------------|\n",
    "| Kernel initializer     | LeCun initialization             |\n",
    "| Activation function    | SELU                             |\n",
    "| Normalization          | None (self-normalization)        |\n",
    "| Regularization         | Alpha dropout if needed          |\n",
    "| Optimizer              | Nesterov accelerated gradients   |\n",
    "| Learning rate schedule | Performance scheduling or 1cycle |\n",
    "\n",
    "Don\u2019t forget to normalize the input features! We should also try to reuse parts of a pretrained neural network if we can find one that solves a similar problem, or use unsupervised pretraining if we have a lot of unlabeled data, or use pretraining on an auxiliary task if we have a lot of labeled data for a similar task.\n",
    "\n",
    "While the previous guidelines should cover most cases, here are some exceptions:\n",
    "- If we need a sparse model, we can use $\\ell_1$ regularization (and optionally zero out the tiny weights after training). If we need an even sparser model, we can use the TensorFlow Model Optimization Toolkit. This will break self-normalization, so we should use the default configuration in this case.\n",
    "- If we need a low-latency model (one that performs lightning-fast \n",
    "predictions), we may need to use fewer layers, use a fast activation function such as ReLU or leaky ReLU, and fold the batch normalization layers into the previous layers after training. Having a sparse model will also help. Finally, we may want to reduce the float precision from 32 bits to 16 or even 8 bits. Again, check out TF-MOT.\n",
    "- If we are building a risk-sensitive application, or inference latency is not very important in our application, we can use MC dropout to boost performance and get more reliable probability estimates, along with uncertainty estimates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Exercises\n",
    "1. What is the problem that Glorot initialization and He initialization aim to fix?\n",
    "> Glorot initialization and He initialization were designed to make the output standard deviation as close as possible to the input standard deviation, at least at the beginning of training. This reduces the vanishing/exploding gradients problem.\n",
    "2. Is it OK to initialize all the weights to the same value as long as that value is selected randomly using He initialization?\n",
    "> No, all weights should be sampled independently; they should not all have the same initial value. One important goal of sampling weights randomly is to break symmetry: if all the weights have the same initial value, even if that value is not zero, then symmetry is not broken (i.e., all neurons in a given layer are equivalent), and backpropagation will be unable to break it. Concretely, this means that all the neurons in any given layer will always have the same weights. It\u2019s like having just one neuron per layer, and much slower. It is virtually impossible for such a configuration to converge to a good solution.\n",
    "3. Is it OK to initialize the bias terms to 0?\n",
    "> It is perfectly fine to initialize the bias terms to zero. Some people like to initialize them just like weights, and that\u2019s OK too; it does not make much difference.\n",
    "4. In which cases would we want to use each of the activation functions we discussed in this chapter?\n",
    "> ReLU is usually a good default for the hidden layers, as it is fast and yields good results. Its ability to output precisely zero can also be useful in some cases. Moreover, it can sometimes benefit from optimized implementations as well as from hardware acceleration. The leaky ReLU variants of ReLU can improve the model\u2019s quality without hindering its speed too much compared to ReLU. For large neural nets and more complex problems, GLU, Swish and Mish can give us a slightly higher quality model, but they have a computational cost. The hyperbolic tangent (tanh) can be useful in the output layer if we need to output a number in a fixed range (by default between \u20131 and 1), but nowadays it is not used much in hidden layers, except in recurrent nets. The sigmoid activation function is also useful in the output layer when we need to estimate a probability (e.g., for binary classification), but it is rarely used in hidden layers (there are exceptions e.g., for the coding layer of variational autoencoders). The softplus activation function is useful in the output layer when we need to ensure that the output will always be positive. The softmax activation function is useful in the output layer to estimate probabilities for mutually exclusive classes, but it is rarely (if ever) used in hidden layers.\n",
    "5. What may happen if we set the `momentum` hyperparameter too close to 1 (e.g., 0.99999) when using an SGD optimizer?\n",
    "> The algorithm will likely pick up a lot of speed, hopefully moving roughly toward the global minimum, but its momentum will carry it right past the minimum. Then it will slow down and come back, accelerate again, overshoot again, and so on. It may oscillate this way many times before converging, so overall it will take much longer to converge than with a smaller `momentum` value.\n",
    "6. Name three ways we can produce a sparse model.\n",
    "> One way to produce a sparse model (i.e., with most weights equal to zero) is to train the model normally, then zero out tiny weights. For more sparsity, we can apply $\\ell_1$ regularization during training, which pushes the optimizer toward sparsity. A third option is to use the TensorFlow Model Optimization Toolkit.\n",
    "7. Does dropout slow down training? Does it slow down inference (i.e., making predictions on new instances)? What about MC dropout?\n",
    "> Yes, dropout does slow down training, in general roughly by a factor of two. However, it has no impact on inference speed since it is only turned on during training. MC Dropout is exactly like dropout during training, but it is still active during inference, so each inference is slowed down slightly. More importantly, when using MC Dropout we generally want to run inference 10 times or more to get better predictions. This means that making predictions is slowed down by a factor of 10 or more.\n",
    "8. Practice training a deep neural network on the CIFAR10 image dataset:\n",
    "   - **a.** Build a DNN with 20 hidden layers of 100 neurons each (that\u2019s too many, but it\u2019s the point of this exercise). Use He initialization and the Swish activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            100, activation='swish', kernel_initializer='he_normal'\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **b.** Using Nadam optimization and early stopping, train the network on the CIFAR10 dataset. We can load it with `keras.datasets.cifar10.load_data()`. The dataset is composed of 60,000 32 $\\times$ 32\u2013pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so we'll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time we change the model\u2019s architecture or hyperparameters.\n",
    "> Let\u2019s add the output layer to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let\u2019s use a Nadam optimizer with a learning rate of 5e-5. I tried learning rates 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3 and 1e-2, and I compared their learning curves for 10 epochs each (using the TensorBoard callback, below). The learning rates 3e-5 and 1e-4 were pretty good, so I tried 5e-5, which turned out to be slightly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let\u2019s load the CIFAR10 dataset. We also want to use early stopping, so we need a validation set. Let\u2019s use the first 5,000 images of the original training set as the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = keras.datasets.cifar10.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now we can create the callbacks we need and train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    'my_cifar10_model', save_best_only=True\n",
    ")\n",
    "# Increment every time we train the model\n",
    "run_index = 1\n",
    "run_logdir = Path() / 'my_cifar10_logs' / f'run_{run_index:03d}'\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d05c16b556c70d97\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d05c16b556c70d97\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_cifar10_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 4.0493 - accuracy: 0.1598INFO:tensorflow:Assets written to: my_cifar10_model/assets\n",
      "1407/1407 [==============================] - 17s 10ms/step - loss: 4.0462 - accuracy: 0.1597 - val_loss: 2.1441 - val_accuracy: 0.2036\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 2.0667 - accuracy: 0.2320INFO:tensorflow:Assets written to: my_cifar10_model/assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 2.0667 - accuracy: 0.2320 - val_loss: 2.0134 - val_accuracy: 0.2472\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.9472 - accuracy: 0.2819INFO:tensorflow:Assets written to: my_cifar10_model/assets\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.9472 - accuracy: 0.2819 - val_loss: 1.9427 - val_accuracy: 0.2796\n",
      "Epoch 4/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.8636 - accuracy: 0.3182INFO:tensorflow:Assets written to: my_cifar10_model/assets\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.8637 - accuracy: 0.3182 - val_loss: 1.8934 - val_accuracy: 0.3222\n",
      "Epoch 5/100\n",
      "1402/1407 [============================>.] - ETA: 0s - loss: 1.7975 - accuracy: 0.3464INFO:tensorflow:Assets written to: my_cifar10_model/assets\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.7974 - accuracy: 0.3465 - val_loss: 1.8389 - val_accuracy: 0.3284\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 1.7446 - accuracy: 0.3664 - val_loss: 2.0006 - val_accuracy: 0.3030\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.6974 - accuracy: 0.3852INFO:tensorflow:Assets written to: my_cifar10_model/assets\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.6974 - accuracy: 0.3852 - val_loss: 1.7075 - val_accuracy: 0.3738\n",
      "Epoch 8/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.6605 - accuracy: 0.3984INFO:tensorflow:Assets written to: my_cifar10_model/assets\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.6604 - accuracy: 0.3984 - val_loss: 1.6788 - val_accuracy: 0.3836\n",
      "Epoch 9/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.6322 - accuracy: 0.4114INFO:tensorflow:Assets written to: my_cifar10_model/assets\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.6321 - accuracy: 0.4114 - val_loss: 1.6477 - val_accuracy: 0.4014\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.6065 - accuracy: 0.4205 - val_loss: 1.6623 - val_accuracy: 0.3980\n",
      "Epoch 11/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.5843 - accuracy: 0.4287INFO:tensorflow:Assets written to: my_cifar10_model/assets\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.5845 - accuracy: 0.4285 - val_loss: 1.6032 - val_accuracy: 0.4198\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 9s 6ms/step - loss: 1.5634 - accuracy: 0.4367 - val_loss: 1.6063 - val_accuracy: 0.4258\n",
      "Epoch 13/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.5443 - accuracy: 0.4420INFO:tensorflow:Assets written to: my_cifar10_model/assets\n",
      "<<47 more lines>>\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.3247 - accuracy: 0.5256 - val_loss: 1.5130 - val_accuracy: 0.4616\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3164 - accuracy: 0.5286 - val_loss: 1.5284 - val_accuracy: 0.4686\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.3091 - accuracy: 0.5303 - val_loss: 1.5208 - val_accuracy: 0.4682\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.3026 - accuracy: 0.5319 - val_loss: 1.5479 - val_accuracy: 0.4604\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2930 - accuracy: 0.5378 - val_loss: 1.5443 - val_accuracy: 0.4580\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2833 - accuracy: 0.5406 - val_loss: 1.5165 - val_accuracy: 0.4710\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2763 - accuracy: 0.5433 - val_loss: 1.5345 - val_accuracy: 0.4672\n",
      "Epoch 39/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2687 - accuracy: 0.5437 - val_loss: 1.5162 - val_accuracy: 0.4712\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.2623 - accuracy: 0.5490 - val_loss: 1.5717 - val_accuracy: 0.4566\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2580 - accuracy: 0.5467 - val_loss: 1.5296 - val_accuracy: 0.4738\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2469 - accuracy: 0.5532 - val_loss: 1.5179 - val_accuracy: 0.4690\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2404 - accuracy: 0.5542 - val_loss: 1.5542 - val_accuracy: 0.4566\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.2292 - accuracy: 0.5605 - val_loss: 1.5536 - val_accuracy: 0.4608\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2276 - accuracy: 0.5606 - val_loss: 1.5522 - val_accuracy: 0.4624\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2200 - accuracy: 0.5637 - val_loss: 1.5339 - val_accuracy: 0.4794\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.2080 - accuracy: 0.5677 - val_loss: 1.5451 - val_accuracy: 0.4688\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2050 - accuracy: 0.5675 - val_loss: 1.5209 - val_accuracy: 0.4770\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1947 - accuracy: 0.5718 - val_loss: 1.5435 - val_accuracy: 0.4736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb9f02fc070>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5062 - accuracy: 0.4676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5061508417129517, 0.4675999879837036]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The model with the lowest validation loss gets about 46.8% accuracy on the validation set. It took 29 epochs to reach the lowest validation loss, with roughly 10 seconds per epoch on my laptop (without a GPU). Let\u2019s see if we can improve the model using Batch Normalization.\n",
    "- **c.** Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?\n",
    "> The code below is very similar to the code above, with a few changes:\n",
    "> - I added a BN layer after every Dense layer (before the activation function), except for the output layer.\n",
    "> - I changed the learning rate to 5e-4. I experimented with 1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3 and 3e-3, and I chose the one with the best validation performance after 20 epochs.\n",
    "> - I renamed the run directories to run_bn_* and the model file name to `my_cifar10_bn_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 2.0377 - accuracy: 0.2523INFO:tensorflow:Assets written to: my_cifar10_bn_model/assets\n",
      "1407/1407 [==============================] - 32s 18ms/step - loss: 2.0374 - accuracy: 0.2525 - val_loss: 1.8766 - val_accuracy: 0.3154\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.7874 - accuracy: 0.3542 - val_loss: 1.8784 - val_accuracy: 0.3268\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - 20s 15ms/step - loss: 1.6806 - accuracy: 0.3969 - val_loss: 1.9764 - val_accuracy: 0.3252\n",
      "Epoch 4/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.6111 - accuracy: 0.4229INFO:tensorflow:Assets written to: my_cifar10_bn_model/assets\n",
      "1407/1407 [==============================] - 24s 17ms/step - loss: 1.6112 - accuracy: 0.4228 - val_loss: 1.7087 - val_accuracy: 0.3750\n",
      "Epoch 5/100\n",
      "1402/1407 [============================>.] - ETA: 0s - loss: 1.5520 - accuracy: 0.4478INFO:tensorflow:Assets written to: my_cifar10_bn_model/assets\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.5521 - accuracy: 0.4476 - val_loss: 1.6272 - val_accuracy: 0.4176\n",
      "Epoch 6/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.5030 - accuracy: 0.4659INFO:tensorflow:Assets written to: my_cifar10_bn_model/assets\n",
      "1407/1407 [==============================] - 23s 16ms/step - loss: 1.5030 - accuracy: 0.4660 - val_loss: 1.5401 - val_accuracy: 0.4452\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.4559 - accuracy: 0.4812 - val_loss: 1.6990 - val_accuracy: 0.3952\n",
      "Epoch 8/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.4169 - accuracy: 0.4987INFO:tensorflow:Assets written to: my_cifar10_bn_model/assets\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4168 - accuracy: 0.4987 - val_loss: 1.5078 - val_accuracy: 0.4652\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3863 - accuracy: 0.5123 - val_loss: 1.5513 - val_accuracy: 0.4470\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3514 - accuracy: 0.5216 - val_loss: 1.5208 - val_accuracy: 0.4562\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.3220 - accuracy: 0.5314 - val_loss: 1.7301 - val_accuracy: 0.4206\n",
      "Epoch 12/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.2933 - accuracy: 0.5410INFO:tensorflow:Assets written to: my_cifar10_bn_model/assets\n",
      "1407/1407 [==============================] - 25s 18ms/step - loss: 1.2931 - accuracy: 0.5410 - val_loss: 1.4909 - val_accuracy: 0.4734\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2702 - accuracy: 0.5490 - val_loss: 1.5256 - val_accuracy: 0.4636\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2424 - accuracy: 0.5591 - val_loss: 1.5569 - val_accuracy: 0.4624\n",
      "Epoch 15/100\n",
      "<<12 more lines>>\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1174 - accuracy: 0.6066 - val_loss: 1.5241 - val_accuracy: 0.4828\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0978 - accuracy: 0.6128 - val_loss: 1.5313 - val_accuracy: 0.4772\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0844 - accuracy: 0.6198 - val_loss: 1.4993 - val_accuracy: 0.4924\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.0677 - accuracy: 0.6244 - val_loss: 1.4622 - val_accuracy: 0.5078\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0571 - accuracy: 0.6297 - val_loss: 1.4917 - val_accuracy: 0.4990\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 1.0395 - accuracy: 0.6327 - val_loss: 1.4888 - val_accuracy: 0.4896\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0298 - accuracy: 0.6370 - val_loss: 1.5358 - val_accuracy: 0.5024\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.0150 - accuracy: 0.6444 - val_loss: 1.5219 - val_accuracy: 0.5030\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.0100 - accuracy: 0.6456 - val_loss: 1.4933 - val_accuracy: 0.5098\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9956 - accuracy: 0.6492 - val_loss: 1.4756 - val_accuracy: 0.5012\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9787 - accuracy: 0.6576 - val_loss: 1.5181 - val_accuracy: 0.4936\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9710 - accuracy: 0.6565 - val_loss: 1.7510 - val_accuracy: 0.4568\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 20s 14ms/step - loss: 0.9613 - accuracy: 0.6628 - val_loss: 1.5576 - val_accuracy: 0.4910\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 0.9530 - accuracy: 0.6651 - val_loss: 1.5087 - val_accuracy: 0.5046\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 19s 13ms/step - loss: 0.9388 - accuracy: 0.6701 - val_loss: 1.5534 - val_accuracy: 0.4950\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9331 - accuracy: 0.6743 - val_loss: 1.5033 - val_accuracy: 0.5046\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 19s 14ms/step - loss: 0.9144 - accuracy: 0.6808 - val_loss: 1.5679 - val_accuracy: 0.5028\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4236 - accuracy: 0.5074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4236289262771606, 0.5073999762535095]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer='he_normal'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation('swish'))\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    'my_cifar10_bn_model', save_best_only=True\n",
    ")\n",
    "# Increment every time we train the model\n",
    "run_index = 1\n",
    "run_logdir = Path() / 'my_cifar10_logs' / f'run_bn_{run_index:03d}'\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - *Is the model converging faster than before?* Much faster! The previous model took 29 epochs to reach the lowest validation loss, while the new model achieved that same loss in just 12 epochs and continued to make progress until the 17th epoch. The BN layers stabilized training and allowed us to use a much larger learning rate, so convergence was faster.\n",
    "> - *Does BN produce a better model?* Yes! The final model is also much better, with 50.7% validation accuracy instead of 46.7%. It\u2019s still not a very good model, but at least it\u2019s much better than before (a convolutional neural network would do much better, but that\u2019s a different topic).\n",
    "> - *How does BN affect training speed?* Although the model converged much faster, each epoch took about 15s instead of 10s, because of the extra computations required by the BN layers. But overall the training time (wall time) to reach the best model was shortened by about 10%.\n",
    "- **d.** Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.9386 - accuracy: 0.3045INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 20s 13ms/step - loss: 1.9385 - accuracy: 0.3046 - val_loss: 1.8175 - val_accuracy: 0.3510\n",
      "Epoch 2/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.7241 - accuracy: 0.3869INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.7241 - accuracy: 0.3869 - val_loss: 1.7677 - val_accuracy: 0.3614\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.6272 - accuracy: 0.4263INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.6272 - accuracy: 0.4263 - val_loss: 1.6878 - val_accuracy: 0.4054\n",
      "Epoch 4/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.5644 - accuracy: 0.4492INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 18s 13ms/step - loss: 1.5643 - accuracy: 0.4492 - val_loss: 1.6589 - val_accuracy: 0.4304\n",
      "Epoch 5/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.5080 - accuracy: 0.4712INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5080 - accuracy: 0.4712 - val_loss: 1.5651 - val_accuracy: 0.4538\n",
      "Epoch 6/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.4611 - accuracy: 0.4873INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4613 - accuracy: 0.4872 - val_loss: 1.5305 - val_accuracy: 0.4678\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4174 - accuracy: 0.5077 - val_loss: 1.5346 - val_accuracy: 0.4558\n",
      "Epoch 8/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.3781 - accuracy: 0.5175INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.3781 - accuracy: 0.5175 - val_loss: 1.4773 - val_accuracy: 0.4882\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3413 - accuracy: 0.5345 - val_loss: 1.5021 - val_accuracy: 0.4764\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.3182 - accuracy: 0.5422 - val_loss: 1.5709 - val_accuracy: 0.4762\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2832 - accuracy: 0.5571 - val_loss: 1.5345 - val_accuracy: 0.4868\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2557 - accuracy: 0.5667 - val_loss: 1.5024 - val_accuracy: 0.4900\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2373 - accuracy: 0.5710 - val_loss: 1.5114 - val_accuracy: 0.5028\n",
      "Epoch 14/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.2071 - accuracy: 0.5846INFO:tensorflow:Assets written to: my_cifar10_selu_model/assets\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.2073 - accuracy: 0.5847 - val_loss: 1.4608 - val_accuracy: 0.5026\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1843 - accuracy: 0.5940 - val_loss: 1.4962 - val_accuracy: 0.5038\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1617 - accuracy: 0.6026 - val_loss: 1.5255 - val_accuracy: 0.5062\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1452 - accuracy: 0.6084 - val_loss: 1.5057 - val_accuracy: 0.5036\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.1297 - accuracy: 0.6145 - val_loss: 1.5097 - val_accuracy: 0.5010\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1004 - accuracy: 0.6245 - val_loss: 1.5218 - val_accuracy: 0.5014\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0971 - accuracy: 0.6304 - val_loss: 1.5253 - val_accuracy: 0.5090\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0670 - accuracy: 0.6345 - val_loss: 1.5006 - val_accuracy: 0.5034\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.0544 - accuracy: 0.6407 - val_loss: 1.5244 - val_accuracy: 0.5010\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0338 - accuracy: 0.6502 - val_loss: 1.5355 - val_accuracy: 0.5096\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0281 - accuracy: 0.6514 - val_loss: 1.5257 - val_accuracy: 0.5164\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4097 - accuracy: 0.6478 - val_loss: 1.8203 - val_accuracy: 0.3514\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3733 - accuracy: 0.5157 - val_loss: 1.5600 - val_accuracy: 0.4664\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2032 - accuracy: 0.5814 - val_loss: 1.5367 - val_accuracy: 0.4944\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.1291 - accuracy: 0.6121 - val_loss: 1.5333 - val_accuracy: 0.4852\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0734 - accuracy: 0.6317 - val_loss: 1.5475 - val_accuracy: 0.5032\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0294 - accuracy: 0.6469 - val_loss: 1.5400 - val_accuracy: 0.5052\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0081 - accuracy: 0.6605 - val_loss: 1.5617 - val_accuracy: 0.4856\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0109 - accuracy: 0.6603 - val_loss: 1.5727 - val_accuracy: 0.5124\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 0.9646 - accuracy: 0.6762 - val_loss: 1.5333 - val_accuracy: 0.5174\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 0.9597 - accuracy: 0.6789 - val_loss: 1.5601 - val_accuracy: 0.5016\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.4608 - accuracy: 0.5026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4607702493667603, 0.5026000142097473]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            100, kernel_initializer='lecun_normal', activation='selu'\n",
    "        )\n",
    "    )\n",
    "\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    'my_cifar10_selu_model', save_best_only=True\n",
    ")\n",
    "# Increment every time we train the model\n",
    "run_index = 1\n",
    "run_logdir = Path() / 'my_cifar10_logs' / f'run_selu_{run_index:03d}'\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This model reached the first model\u2019s validation loss in just 8 epochs. After 14 epochs, it reached its lowest validation loss, with about 50.3% accuracy, which is better than the original model (46.7%), but not quite as good as the model using batch normalization (50.7%). Each epoch took only 9 seconds. So it\u2019s the fastest model to train so far.\n",
    "- **e.** Try regularizing the model with alpha dropout. Then, without retraining our model, see if we can achieve better accuracy using MC Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.8953 - accuracy: 0.3240INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 18s 11ms/step - loss: 1.8950 - accuracy: 0.3239 - val_loss: 1.7556 - val_accuracy: 0.3812\n",
      "Epoch 2/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.6618 - accuracy: 0.4129INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.6618 - accuracy: 0.4130 - val_loss: 1.6563 - val_accuracy: 0.4114\n",
      "Epoch 3/100\n",
      "1402/1407 [============================>.] - ETA: 0s - loss: 1.5772 - accuracy: 0.4431INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.5770 - accuracy: 0.4432 - val_loss: 1.6507 - val_accuracy: 0.4232\n",
      "Epoch 4/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.5081 - accuracy: 0.4673INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.5081 - accuracy: 0.4672 - val_loss: 1.5892 - val_accuracy: 0.4566\n",
      "Epoch 5/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.4560 - accuracy: 0.4902INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4561 - accuracy: 0.4902 - val_loss: 1.5382 - val_accuracy: 0.4696\n",
      "Epoch 6/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.4095 - accuracy: 0.5050INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.4094 - accuracy: 0.5050 - val_loss: 1.5236 - val_accuracy: 0.4818\n",
      "Epoch 7/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.3634 - accuracy: 0.5234INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.3636 - accuracy: 0.5232 - val_loss: 1.5139 - val_accuracy: 0.4840\n",
      "Epoch 8/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.3297 - accuracy: 0.5377INFO:tensorflow:Assets written to: my_cifar10_alpha_dropout_model/assets\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.3296 - accuracy: 0.5378 - val_loss: 1.4780 - val_accuracy: 0.4982\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.2907 - accuracy: 0.5485 - val_loss: 1.5151 - val_accuracy: 0.4854\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.2559 - accuracy: 0.5646 - val_loss: 1.4980 - val_accuracy: 0.4976\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2221 - accuracy: 0.5767 - val_loss: 1.5199 - val_accuracy: 0.4990\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1960 - accuracy: 0.5870 - val_loss: 1.5167 - val_accuracy: 0.5030\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1684 - accuracy: 0.5955 - val_loss: 1.5815 - val_accuracy: 0.5014\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1463 - accuracy: 0.6025 - val_loss: 1.5427 - val_accuracy: 0.5112\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.1125 - accuracy: 0.6169 - val_loss: 1.5868 - val_accuracy: 0.5212\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.0854 - accuracy: 0.6243 - val_loss: 1.6234 - val_accuracy: 0.5090\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.0668 - accuracy: 0.6328 - val_loss: 1.6162 - val_accuracy: 0.5072\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.0440 - accuracy: 0.6442 - val_loss: 1.5748 - val_accuracy: 0.5162\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.0272 - accuracy: 0.6477 - val_loss: 1.6518 - val_accuracy: 0.5200\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 1.0007 - accuracy: 0.6594 - val_loss: 1.6224 - val_accuracy: 0.5186\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 0.9824 - accuracy: 0.6639 - val_loss: 1.6972 - val_accuracy: 0.5136\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 0.9660 - accuracy: 0.6714 - val_loss: 1.7210 - val_accuracy: 0.5278\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 13s 10ms/step - loss: 0.9472 - accuracy: 0.6780 - val_loss: 1.6436 - val_accuracy: 0.5006\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9314 - accuracy: 0.6819 - val_loss: 1.7059 - val_accuracy: 0.5160\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.9172 - accuracy: 0.6888 - val_loss: 1.6926 - val_accuracy: 0.5200\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.8990 - accuracy: 0.6947 - val_loss: 1.7705 - val_accuracy: 0.5148\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 0.8758 - accuracy: 0.7028 - val_loss: 1.7023 - val_accuracy: 0.5198\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 0.8622 - accuracy: 0.7090 - val_loss: 1.7567 - val_accuracy: 0.5184\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.4780 - accuracy: 0.4982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4779616594314575, 0.498199999332428]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            100, kernel_initializer='lecun_normal', activation='selu'\n",
    "        )\n",
    "    )\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True\n",
    ")\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
    "    'my_cifar10_alpha_dropout_model', save_best_only=True\n",
    ")\n",
    "# Increment every time we train the model\n",
    "run_index = 1\n",
    "run_logdir = Path() / 'my_cifar10_logs' / f'run_alpha_dropout_{run_index:03d}'\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The model reaches 48.1% accuracy on the validation set. That\u2019s worse than without dropout (50.3%). With an extensive hyperparameter search, it might be possible to do better (I tried dropout rates of 5%, 10%, 20% and 40%, and learning rates 1e-4, 3e-4, 5e-4, and 1e-3), but probably not much better in this case.\n",
    ">\n",
    "> Let\u2019s use MC Dropout now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs: TensorLike) -> TensorLike:\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now let\u2019s create a new model, identical to the one we just trained (with the same weights), but with `MCAlphaDropout` dropout layers instead of `AlphaDropout` layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.Sequential(\n",
    "    [\n",
    "        (\n",
    "            MCAlphaDropout(layer.rate)\n",
    "            if isinstance(layer, keras.layers.AlphaDropout)\n",
    "            else layer\n",
    "        )\n",
    "        for layer in model.layers\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Then let\u2019s add a couple utility functions. The first will run the model many times (10 by default) and it will return the mean predicted class probabilities. The second will use these mean probabilities to predict the most likely class for each instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.typing import ArrayLike\n",
    "\n",
    "\n",
    "def mc_dropout_predict_probas(\n",
    "    mc_model: keras.Model, X: ArrayLike, n_samples: int = 10\n",
    ") -> ArrayLike:\n",
    "    Y_probas = [mc_model.predict(X) for _ in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "\n",
    "def mc_dropout_predict_classes(\n",
    "    mc_model: keras.Model, X: ArrayLike, n_samples: int = 10\n",
    ") -> ArrayLike:\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return Y_probas.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now let\u2019s make predictions for all the instances in the validation set, and compute the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4984"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = (y_pred == y_valid[:, 0]).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  We get back to roughly the accuracy of the model without dropout in this \n",
    "> case (about 50.3% accuracy).\n",
    ">\n",
    "> So the best model we got in this exercise is the Batch Normalization model.\n",
    "- **f.** Retrain our model using 1cycle scheduling and see if it improves training speed and model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            100, kernel_initializer='lecun_normal', activation='selu'\n",
    "        )\n",
    "    )\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.SGD()\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 3s 8ms/step - loss: nan - accuracy: 0.1706\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(\n",
    "    model, X_train_scaled, y_train, epochs=1, batch_size=batch_size\n",
    ")\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "            100, kernel_initializer='lecun_normal', activation='selu'\n",
    "        )\n",
    "    )\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=2e-2)\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 2.0559 - accuracy: 0.2839 - val_loss: 1.7917 - val_accuracy: 0.3768\n",
      "Epoch 2/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.7596 - accuracy: 0.3797 - val_loss: 1.6566 - val_accuracy: 0.4258\n",
      "Epoch 3/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.6199 - accuracy: 0.4247 - val_loss: 1.6395 - val_accuracy: 0.4260\n",
      "Epoch 4/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.5451 - accuracy: 0.4524 - val_loss: 1.6202 - val_accuracy: 0.4408\n",
      "Epoch 5/15\n",
      "352/352 [==============================] - 3s 8ms/step - loss: 1.4952 - accuracy: 0.4691 - val_loss: 1.5981 - val_accuracy: 0.4488\n",
      "Epoch 6/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.4541 - accuracy: 0.4842 - val_loss: 1.5720 - val_accuracy: 0.4490\n",
      "Epoch 7/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.4171 - accuracy: 0.4967 - val_loss: 1.6035 - val_accuracy: 0.4470\n",
      "Epoch 8/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.3497 - accuracy: 0.5194 - val_loss: 1.4918 - val_accuracy: 0.4864\n",
      "Epoch 9/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.2788 - accuracy: 0.5459 - val_loss: 1.5597 - val_accuracy: 0.4672\n",
      "Epoch 10/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.2070 - accuracy: 0.5707 - val_loss: 1.5845 - val_accuracy: 0.4864\n",
      "Epoch 11/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.1433 - accuracy: 0.5926 - val_loss: 1.5293 - val_accuracy: 0.4998\n",
      "Epoch 12/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 1.0745 - accuracy: 0.6182 - val_loss: 1.5118 - val_accuracy: 0.5072\n",
      "Epoch 13/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 1.0030 - accuracy: 0.6413 - val_loss: 1.5388 - val_accuracy: 0.5204\n",
      "Epoch 14/15\n",
      "352/352 [==============================] - 3s 10ms/step - loss: 0.9388 - accuracy: 0.6654 - val_loss: 1.5547 - val_accuracy: 0.5210\n",
      "Epoch 15/15\n",
      "352/352 [==============================] - 3s 9ms/step - loss: 0.8989 - accuracy: 0.6805 - val_loss: 1.5835 - val_accuracy: 0.5242\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "n_iterations = math.ceil(len(X_train_scaled) / batch_size) * n_epochs\n",
    "onecycle = OneCycleScheduler(n_iterations, max_lr=0.05)\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    "    callbacks=[onecycle],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> One cycle allowed us to train the model in just 15 epochs, each taking only 2 seconds (thanks to the larger batch size). This is several times faster than the fastest model we trained so far. Moreover, we improved the model\u2019s performance (from 50.7% to 52.0%)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
