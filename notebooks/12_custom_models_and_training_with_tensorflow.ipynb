{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12 – Custom Models and Training with TensorFlow\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/alirezatheh/handson-ml3-notes/blob/main/notebooks/12_custom_models_and_training_with_tensorflow.ipynb)\n",
    "[![Open in Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/alirezatheh/handson-ml3-notes/blob/main/notebooks/12_custom_models_and_training_with_tensorflow.ipynb)\n",
    "\n",
    "95% of the use cases we will encounter will not require anything other than Keras (and tf.data). But now it’s time to dive deeper into TensorFlow and take a look at its lower-level [Python API](https://homl.info/tf2api)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Tour of TensorFlow\n",
    "- TensorFlow is a powerful library for numerical computation, particularly well suited and fine-tuned for large-scale machine learning (but we can use it for anything else that requires heavy computations).\n",
    "- It was developed by the Google Brain team.\n",
    "- It was open sourced in November 2015.\n",
    "- It is now the most widely used deep learning library in the industry (However, Facebook’s PyTorch library is currently more popular in academia. Moreover, Google’s JAX library is gaining momentum, especially in academia).\n",
    "\n",
    "So what does TensorFlow offer? Here’s a summary:\n",
    "- Its core is very similar to NumPy, but with GPU support.\n",
    "- It supports distributed computing (across multiple devices and servers).\n",
    "- It includes a kind of just-in-time (JIT) compiler that allows it to optimize computations for speed and memory usage. It works by extracting the computation graph from a Python function, optimizing it (e.g., by pruning unused nodes), and running it efficiently (e.g., by automatically running independent operations in parallel).\n",
    "- Computation graphs can be exported to a portable format, so we can train a TensorFlow model in one environment (e.g., using Python on Linux) and run it in another (e.g., using Java on an Android device).\n",
    "- It implements reverse-mode autodiff and provides some excellent optimizers, such as RMSProp and Nadam, so we can easily minimize all sorts of loss functions.\n",
    "- It offers many more features built on top of these core features: \n",
    "  - The most important is of course Keras (It includes another deep learning API called the estimators API, but it is now deprecated).\n",
    "  - It also has data loading and preprocessing ops (tf.data, tf.io, etc.), image processing ops (tf.image), signal processing ops (tf.signal), and more.\n",
    "- If we do not want to use the Python API: there are C++, Java, and Swift APIs. There is even a JavaScript implementation called TensorFlow.js that makes it possible to run our models directly in our browser.\n",
    "\n",
    "<center>\n",
    "  <img \n",
    "    src=\"../images/12/tf_python_api.png\" \n",
    "    onerror=\"\n",
    "      this.onerror = null;\n",
    "      const repo = 'https://github.com/alirezatheh/handson-ml3-notes/blob/main';\n",
    "      this.src = repo + this.src.split('..')[1];\n",
    "    \"\n",
    "  >\n",
    "</center>\n",
    "\n",
    "At the lowest level, each TensorFlow operation (*op* for short) is implemented using highly efficient C++ code. Many operations have multiple implementations called *kernels*: each kernel is dedicated to a specific device type, such as CPUs, GPUs, or even TPUs (*tensor processing units*).\n",
    "\n",
    "<center>\n",
    "  <img \n",
    "    src=\"../images/12/tf_architecture.png\" \n",
    "    onerror=\"\n",
    "      this.onerror = null;\n",
    "      const repo = 'https://github.com/alirezatheh/handson-ml3-notes/blob/main';\n",
    "      this.src = repo + this.src.split('..')[1];\n",
    "    \"\n",
    "  >\n",
    "</center>\n",
    "\n",
    "GPUs can dramatically speed up computations by splitting them into many smaller chunks and running them in parallel across many GPU threads. TPUs are even faster: they are custom ASIC chips built specifically for deep learning operations (See https://homl.info/tpus).\n",
    "\n",
    "There’s more to TensorFlow than the library. TensorFlow is at the center of an extensive ecosystem of libraries.\n",
    "- First, there’s TensorBoard for visualization\n",
    "- Next, there’s [TensorFlow Extended (TFX)](https://tensorflow.org/tfx), which is a set of libraries built by Google to productionize TensorFlow projects: it includes tools for data validation, preprocessing, model analysis, and serving (with TF Serving).\n",
    "- Google’s TensorFlow Hub provides a way to easily download and reuse pretrained neural networks.\n",
    "- We can also get many neural network architectures, some of them pretrained, in TensorFlow’s [model garden](https://github.com/tensorflow/models).\n",
    "- Check out the [TensorFlow Resources](https://tensorflow.org/resources) and https://github.com/jtoy/awesome-tensorflow for more TensorFlow-based projects. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Using TensorFlow like NumPy\n",
    "TensorFlow’s API revolves around *tensors*, which flow from operation to operation, hence the name Tensor*Flow*. A tensor is very similar to a NumPy `ndarray`: it is usually a multidimensional array, but it can also hold a scalar (a simple value, such as 42)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Matrix\n",
    "t = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[11., 12., 13.],\n",
       "       [14., 15., 16.]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.add()\n",
    "t + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.matmul()\n",
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Many functions and classes have aliases. e.g. `tf.add()` and `tf.math.add()` are the same function. This allows TensorFlow to have concise names for the most common operations while preserving well-organized packages. A notable exception is `tf.math.log()`, which is commonly used but doesn’t have a `tf.log()` alias, as it might be confused with logging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras’s low-level API\n",
    "We can also use Keras’s low-level API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = keras.backend\n",
    "K.square(K.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s equivalent to TF’s low-level API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[11., 26.],\n",
       "       [14., 35.],\n",
       "       [19., 46.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(tf.transpose(t)) + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions have a different name than in NumPy; e.g., `tf.reduce_mean()`, `tf.reduce_sum()`, `tf.reduce_max()`, and `tf.math.log()` are the equivalent of `np.mean()`, `np.sum()`, `np.max()`, and `np.log()`. When the name differs, there is usually a good reason for it. e.g. in TensorFlow we must write `tf.transpose(t)`; because it does not do exactly the same thing as NumPy’s `T` attribute: in TensorFlow, a new tensor is created with its own copy of the transposed data, while in NumPy, `t.T` is just a transposed view on the same data. Similarly, the `tf.reduce_sum()` operation is named this way because its GPU kernel (i.e., GPU implementation) uses a reduce algorithm that does not guarantee the order in which the elements are added: because 32-bit floats have limited precision, the result may change ever so slightly every time we call this operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors and NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([2., 4., 5.])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([2.0, 4.0, 5.0])\n",
    "tf.constant(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 4., 16., 25.])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  4.,  9.],\n",
       "       [16., 25., 36.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: Notice that NumPy uses 64-bit precision by default, while TensorFlow uses 32-bit. This is because 32-bit precision is generally more than enough for neural networks, plus it runs faster and uses less RAM. So when we create a tensor from a NumPy array, make sure to set `dtype=tf.float32`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Conversions\n",
    "Type conversions can significantly hurt performance, and they can easily go unnoticed when they are done automatically. To avoid this, TensorFlow does not perform any type conversions automatically: it just raises an exception if we try to execute an operation on tensors with incompatible types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40.0, dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=42.0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(40.0, dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "The `tf.Tensor` values we’ve seen so far are immutable: we cannot modify them. This means that we cannot use regular tensors to implement weights in a neural network, since they need to be tweaked by backpropagation. What we need is a `tf.Variable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(2 * v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 1].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2., 42.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100.0, 200.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[4., 5., 6.],\n",
       "       [1., 2., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows how to use scatter_update()\n",
    "sparse_delta = tf.IndexedSlices(\n",
    "    values=[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], indices=[1, 0]\n",
    ")\n",
    "v.scatter_update(sparse_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v[1] = [7.0, 8.0, 9.0]\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: In practice we will rarely have to create variables manually; Keras provides an `add_weight()` method that will take care of it for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello world'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(b'hello world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If we try to build a tensor with a Unicode string, TensorFlow automatically \n",
    "encodes it to UTF-8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'caf\\xc3\\xa9'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant('café')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It is also possible to create tensors representing Unicode strings. Just create \n",
    "an array of 32-bit integers, each representing a single Unicode code point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.constant([ord(c) for c in 'café'])\n",
    "u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Note**: In tensors of type `tf.string`, the string length is not part of the \n",
    "tensor’s shape. In other words, strings are considered as atomic values. \n",
    "However, in a Unicode string tensor (i.e., an int32 tensor), the length of the \n",
    "string is part of the tensor’s shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.strings.unicode_encode(u, 'UTF-8')\n",
    "tf.strings.length(b, unit='UTF8_CHAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 99,  97, 102, 233], dtype=int32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(b, 'UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tf.constant(['Café', 'Coffee', 'caffè', '咖啡'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([4, 6, 5, 2], dtype=int32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.length(p, unit='UTF8_CHAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857]]>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = tf.strings.unicode_decode(p, 'UTF8')\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ragged tensors\n",
    "A *ragged tensor* is a special kind of tensor that represents a list of arrays of different sizes. More generally, it is a tensor with one or more *ragged dimensions*, meaning dimensions whose slices may have different lengths. In the ragged tensor `r`, the second dimension is a ragged dimension. In all ragged tensors, the first dimension is always a regular dimension (also called a *uniform dimension*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([ 67, 111, 102, 102, 101, 101], dtype=int32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232]]>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A slice of a ragged tensor is a ragged tensor\n",
    "r[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "tf.concat([r, r2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[67, 97, 102, 233, 68, 69, 70], [67, 111, 102, 102, 101, 101, 71], [99, 97, 102, 102, 232], [21654, 21857, 72, 73]]>\n"
     ]
    }
   ],
   "source": [
    "r3 = tf.ragged.constant([[68, 69, 70], [71], [], [72, 73]])\n",
    "print(tf.concat([r, r3], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 6), dtype=int32, numpy=\n",
       "array([[   67,    97,   102,   233,     0,     0],\n",
       "       [   67,   111,   102,   102,   101,   101],\n",
       "       [   99,    97,   102,   102,   232,     0],\n",
       "       [21654, 21857,     0,     0,     0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse tensors\n",
    "TensorFlow can also efficiently represent *sparse tensors* (i.e., tensors containing mostly zeros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.SparseTensor(\n",
    "    indices=[[0, 1], [1, 0], [2, 3]],\n",
    "    values=[1.0, 2.0, 3.0],\n",
    "    dense_shape=[3, 4],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0.],\n",
       "       [2., 0., 0., 0.],\n",
       "       [0., 0., 0., 3.]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f84a6749f10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s * 42.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s + 42.0\n",
    "except TypeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 30.,  40.],\n",
       "       [ 20.,  40.],\n",
       "       [210., 240.]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows how to multiply a sparse tensor and a dense tensor\n",
    "s4 = tf.constant([[10.0, 20.0], [30.0, 40.0], [50.0, 60.0], [70.0, 80.0]])\n",
    "tf.sparse.sparse_dense_matmul(s, s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The indices must be listed in “reading order” (from left to right, and top to bottom). If we are unsure, just use `tf.sparse.reorder()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices[1] = [0,1] is out of order. Many sparse ops require sorted indices.\n",
      "    Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      " [Op:SparseToDense]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-17 10:32:40.424119: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at sparse_to_dense_op.cc:162 : Invalid argument: indices[1] = [0,1] is out of order. Many sparse ops require sorted indices.\n",
      "    Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s5 = tf.SparseTensor(\n",
    "    # Wrong order!\n",
    "    indices=[[0, 2], [0, 1]],\n",
    "    values=[1.0, 2.0],\n",
    "    dense_shape=[3, 4],\n",
    ")\n",
    "try:\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 2., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s6 = tf.sparse.reorder(s5)\n",
    "tf.sparse.to_dense(s6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Arrays\n",
    "A `tf.TensorArray` represents a list of tensors. We can read or write tensors at any location in the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1.0, 2.0]))\n",
    "array = array.write(1, tf.constant([3.0, 10.0]))\n",
    "array = array.write(2, tf.constant([5.0, 7.0]))\n",
    "# Returns (and zeros out!) tf.constant([3., 10.])\n",
    "tensor1 = array.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "By default, reading an item also replaces it with a tensor of the same shape but full of zeros. We can set `clear_after_read` to `False` if we don’t want this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[ 1.,  2.],\n",
       "       [ 3., 10.],\n",
       "       [ 5.,  7.]], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array2 = tf.TensorArray(dtype=tf.float32, size=3, clear_after_read=False)\n",
    "array2 = array2.write(0, tf.constant([1.0, 2.0]))\n",
    "array2 = array2.write(1, tf.constant([3.0, 10.0]))\n",
    "array2 = array2.write(2, tf.constant([5.0, 7.0]))\n",
    "tensor2 = array2.read(1)  # returns tf.constant([3., 10.])\n",
    "array2.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Warning**: When we write to the array, we must assign the output back to the array. If we don’t, although our code will work fine in eager mode, it will break in graph mode. these modes are discussed later in this chapter.\n",
    "\n",
    "Alternatively, we can set `size=0` and `dynamic_size=True` to let the array grow automatically when needed. However, this will hinder performance, so if we know the size, it’s better to use a fixed-size array. All elements must have the same shape as the first one written to the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array3 = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "array3 = array3.write(0, tf.constant([1.0, 2.0]))\n",
    "array3 = array3.write(1, tf.constant([3.0, 10.0]))\n",
    "array3 = array3.write(2, tf.constant([5.0, 7.0]))\n",
    "tensor3 = array3.read(1)\n",
    "array3.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sets\n",
    "TensorFlow supports sets of integers or strings (but not floats). It represents sets using regular tensors. e.g., the set `{1, 5, 9}` is just represented as the tensor `[[1, 5, 9]]`. Note that the tensor must have at least two dimensions, and the sets must be in the last dimension. e.g., `[[1, 5, 9], [2, 5, 11]]` is a tensor holding two independent sets: `{1, 5, 9}` and `{2, 5, 11}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f84a1c77400>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1, 5, 9]])\n",
    "b = tf.constant([[5, 6, 9, 11]])\n",
    "u = tf.sets.union(a, b)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[ 1,  5,  6,  9, 11]], dtype=int32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can also compute the union of multiple pairs of sets simultaneously. If some sets are shorter than others, we must pad them with a padding value, such as 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=int32, numpy=\n",
       "array([[ 1,  5,  6,  9, 11],\n",
       "       [ 0, 10, 13,  0,  0]], dtype=int32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1, 5, 9], [10, 0, 0]])\n",
    "b = tf.constant([[5, 6, 9, 11], [13, 0, 0, 0]])\n",
    "u = tf.sets.union(a, b)\n",
    "tf.sparse.to_dense(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=int32, numpy=\n",
       "array([[ 1,  5,  6,  9, 11],\n",
       "       [-1, 10, 13, -1, -1]], dtype=int32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows how to use a different default value: -1 in this case\n",
    "a = tf.constant([[1, 5, 9], [10, -1, -1]])\n",
    "b = tf.constant([[5, 6, 9, 11], [13, -1, -1, -1]])\n",
    "u = tf.sets.union(a, b)\n",
    "tf.sparse.to_dense(u, default_value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[2, 3, 7],\n",
       "       [7, 0, 0]], dtype=int32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows how to use `tf.sets.difference()`\n",
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "tf.sparse.to_dense(tf.sets.difference(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[5, 0],\n",
       "       [0, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows how to use `tf.sets.intersection()`\n",
    "tf.sparse.to_dense(tf.sets.intersection(set1, set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=bool, numpy=array([ True])>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check whether set1[0] contains 5\n",
    "tf.sets.size(tf.sets.intersection(set1[:1], tf.constant([[5, 0, 0, 0]]))) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to add some values to a set, we can compute the union of the set and the values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queues\n",
    "A queue is a data structure to which we can push data records, and later pull them out. They used to be very important when implementing efficient data loading and preprocessing pipelines, but the tf.data API has essentially rendered them useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = tf.queue.FIFOQueue(3, [tf.int32, tf.string], shapes=[(), ()])\n",
    "q.enqueue([10, b'windy'])\n",
    "q.enqueue([15, b'sunny'])\n",
    "q.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=int32, numpy=10>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'windy'>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.dequeue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.enqueue_many([[13, 16], [b'cloudy', b'rainy']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To use `dequeue_many()`, we must specify the shapes argument when we create the \n",
    "queue, as we did previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(3,), dtype=int32, numpy=array([15, 13, 16], dtype=int32)>,\n",
       " <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'sunny', b'cloudy', b'rainy'], dtype=object)>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.dequeue_many(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Other queue types include:\n",
    "- `PaddingFIFOQueue`: Same as `FIFOQueue`, but its `dequeue_many()` method supports dequeueing multiple records of different shapes. It automatically pads the shortest records to ensure all the records in the batch have the same shape.\n",
    "- `PriorityQueue`: A queue that dequeues records in a prioritized order. The priority must be a 64-bit integer included as the first element of each record. Surprisingly, records with a lower priority will be dequeued first. Records with the same priority will be dequeued in FIFO order.\n",
    "- `RandomShuffleQueue`: A queue whose records are dequeued in random order. This was useful to implement a shuffle buffer before tf.data existed.\n",
    "\n",
    "If a queue is already full and we try to enqueue another record, the `enqueue*()` method will freeze until a record is dequeued by another thread. Similarly, if a queue is empty and we try to dequeue a record, the `dequeue*()` method will freeze until records are pushed to the queue by another thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customizing Models and Training Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x252 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)\n",
    "\n",
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "z_center = np.linspace(-1, 1, 200)\n",
    "plt.plot(z, huber_fn(0, z), 'b-', linewidth=2, label='huber($z$)')\n",
    "plt.plot(z, z**2 / 2, 'r:', linewidth=1)\n",
    "plt.plot(z_center, z_center**2 / 2, 'r', linewidth=2)\n",
    "plt.plot([-1, -1], [0, huber_fn(0.0, -1.0)], 'k--')\n",
    "plt.plot([1, 1], [0, huber_fn(0.0, 1.0)], 'k--')\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.text(2.1, 3.5, r'$\\frac{1}{2}z^2$', color='r', fontsize=15)\n",
    "plt.text(3.0, 2.2, r'$|z| - \\frac{1}{2}$', color='b', fontsize=15)\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel('$z$')\n",
    "plt.legend(fontsize=14)\n",
    "plt.title('Huber loss', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "It is also possible to return the mean loss instead of the individual sample losses, but this is not recommended as it makes it impossible to use class weights or sample weights when we need them.\n",
    "\n",
    "To test our custom loss function, let’s create a basic Keras model and train it on the California housing dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "keras.utils.set_random_seed(42)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            30,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        keras.layers.Dense(1),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=huber_fn, optimizer='nadam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 969us/step - loss: 0.3970 - mae: 0.7423 - val_loss: 0.3721 - val_mae: 0.6864\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 702us/step - loss: 0.2330 - mae: 0.5302 - val_loss: 0.2730 - val_mae: 0.5552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8470e12a90>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading Models That Contain Custom Components\n",
    "When we load a model containing custom objects, we need to map the names to the objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_with_a_custom_loss/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('my_model_with_a_custom_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    'my_model_with_a_custom_loss', custom_objects={'huber_fn': huber_fn}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 981us/step - loss: 0.1904 - mae: 0.4699 - val_loss: 0.2363 - val_mae: 0.5045\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 743us/step - loss: 0.1773 - mae: 0.4514 - val_loss: 0.2182 - val_mae: 0.4884\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f84a7329c70>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Tip**: If we decorate the `huber_fn()` function with `@keras.utils.register_keras_serializable()`, it will automatically be available to the `load_model()` function: there’s no need to include it in the `custom_objects` dictionary.\n",
    "\n",
    "Different threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "def create_huber(\n",
    "    threshold: float = 1.0,\n",
    ") -> Callable[[tf.Tensor, tf.Tensor], tf.Tensor]:\n",
    "    def huber_fn(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer='nadam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 996us/step - loss: 0.1950 - mae: 0.4469 - val_loss: 0.2734 - val_mae: 0.4741\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 744us/step - loss: 0.1909 - mae: 0.4434 - val_loss: 0.2507 - val_mae: 0.4685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8430545700>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Unfortunately, when we save the model, the `threshold` will not be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_with_a_custom_loss_threshold_2/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('my_model_with_a_custom_loss_threshold_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    'my_model_with_a_custom_loss_threshold_2',\n",
    "    custom_objects={'huber_fn': create_huber(2.0)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 996us/step - loss: 0.1880 - mae: 0.4395 - val_loss: 0.2452 - val_mae: 0.4571\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 755us/step - loss: 0.1858 - mae: 0.4374 - val_loss: 0.2243 - val_mae: 0.4526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8480b07250>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can solve this by creating a subclass of the `keras.losses.Loss` class, and then implementing its `get_config()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold: float = 1.0, **kwargs) -> None:\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "    def get_config(self) -> dict[str, Any]:\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'threshold': self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let’s walk through this code:\n",
    "- The constructor accepts `**kwargs` and passes them to the parent constructor, which handles standard hyperparameters: the `name` of the loss and the `reduction` algorithm to use to aggregate the individual instance losses. By default this is `'AUTO'`, which is equivalent to `'SUM_OVER_BATCH_SIZE'`: the loss will be the sum of the instance losses, weighted by the sample weights, if any, and divided by the batch size (not by the sum of weights, so this is not the weighted mean. It would not be a good idea to use a weighted mean: if we did, then two instances with the same weight but in different batches would have a different impact on training, depending on the total weight of each batch). Other possible values are `'SUM'` and `'NONE'`.\n",
    "- The `call()` method takes the labels and predictions, computes all the instance losses, and returns them.\n",
    "- The `get_config()` method returns a dictionary mapping each hyperparameter name to its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates another basic Keras model\n",
    "keras.utils.set_random_seed(42)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            30,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        keras.layers.Dense(1),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.0), optimizer='nadam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 985us/step - loss: 0.4997 - mae: 0.7514 - val_loss: 0.5202 - val_mae: 0.6936\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 753us/step - loss: 0.2781 - mae: 0.5435 - val_loss: 0.3794 - val_mae: 0.5651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f84408d09d0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_with_a_custom_loss_class/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('my_model_with_a_custom_loss_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    'my_model_with_a_custom_loss_class',\n",
    "    custom_objects={'HuberLoss': HuberLoss},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 981us/step - loss: 0.2206 - mae: 0.4783 - val_loss: 0.3241 - val_mae: 0.5093\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 760us/step - loss: 0.2018 - mae: 0.4574 - val_loss: 0.2909 - val_mae: 0.4934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8470937610>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows that loading worked fine, the model can be used normally\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The treshold was loaded correctly\n",
    "model.loss.threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Activation Functions, Initializers, Regularizers, and Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T15:33:05.237525Z",
     "start_time": "2023-11-26T15:33:05.143331Z"
    }
   },
   "outputs": [],
   "source": [
    "def my_softplus(z: tf.Tensor) -> tf.Tensor:\n",
    "    return tf.math.log(1.0 + tf.exp(z))\n",
    "\n",
    "\n",
    "def my_glorot_initializer(\n",
    "    shape: tf.TensorShape, dtype: tf.DType = tf.float32\n",
    ") -> tf.Tensor:\n",
    "    stddev = tf.sqrt(2.0 / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "\n",
    "def my_l1_regularizer(weights: tf.Variable) -> tf.Tensor:\n",
    "    return tf.reduce_sum(tf.abs(0.01 * weights))\n",
    "\n",
    "\n",
    "def my_positive_weights(weights: tf.Variable) -> tf.Tensor:\n",
    "    # Return value is just tf.nn.relu(weights)\n",
    "    return tf.where(weights < 0.0, tf.zeros_like(weights), weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(\n",
    "    1,\n",
    "    activation=my_softplus,\n",
    "    kernel_initializer=my_glorot_initializer,\n",
    "    kernel_regularizer=my_l1_regularizer,\n",
    "    kernel_constraint=my_positive_weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.1668 - mae: 0.7430 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 750us/step - loss: 0.7359 - mae: 0.5977 - val_loss: 2.6252 - val_mae: 0.5870\n",
      "INFO:tensorflow:Assets written to: my_model_with_many_custom_parts/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_with_many_custom_parts/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5646 - mae: 0.5293 - val_loss: 0.9063 - val_mae: 0.5070\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 759us/step - loss: 0.4981 - mae: 0.4975 - val_loss: 0.7695 - val_mae: 0.4918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f83d1b07550>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show that building, training, saving, loading, and training again\n",
    "# works fine with a model containing many custom parts\n",
    "\n",
    "keras.utils.set_random_seed(42)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            30,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        keras.layers.Dense(\n",
    "            1,\n",
    "            activation=my_softplus,\n",
    "            kernel_initializer=my_glorot_initializer,\n",
    "            kernel_regularizer=my_l1_regularizer,\n",
    "            kernel_constraint=my_positive_weights,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "model.compile(loss='mse', optimizer='nadam', metrics=['mae'])\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")\n",
    "model.save('my_model_with_many_custom_parts')\n",
    "model = keras.models.load_model(\n",
    "    'my_model_with_many_custom_parts',\n",
    "    custom_objects={\n",
    "        'my_l1_regularizer': my_l1_regularizer,\n",
    "        'my_positive_weights': my_positive_weights,\n",
    "        'my_glorot_initializer': my_glorot_initializer,\n",
    "        'my_softplus': my_softplus,\n",
    "    },\n",
    ")\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If a function has hyperparameters that need to be saved along with the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor: float) -> None:\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, weights: tf.Variable) -> tf.Tensor:\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "\n",
    "    def get_config(self) -> dict[str, Any]:\n",
    "        return {'factor': self.factor}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note that we must implement the `call()` method for losses, layers (including activation functions), and models, or the `__call__()` method for regularizers, initializers, and constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 992us/step - loss: 1.1668 - mae: 0.7430 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 752us/step - loss: 0.7359 - mae: 0.5977 - val_loss: 2.6252 - val_mae: 0.5870\n",
      "INFO:tensorflow:Assets written to: my_model_with_many_custom_parts/assets\n",
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 980us/step - loss: 0.5646 - mae: 0.5293 - val_loss: 0.9063 - val_mae: 0.5070\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 783us/step - loss: 0.4981 - mae: 0.4975 - val_loss: 0.7695 - val_mae: 0.4918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f84a6b929d0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, show that everything works fine, this time using our custom\n",
    "# regularizer class\n",
    "\n",
    "\n",
    "keras.utils.set_random_seed(42)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            30,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        keras.layers.Dense(\n",
    "            1,\n",
    "            activation=my_softplus,\n",
    "            kernel_regularizer=MyL1Regularizer(0.01),\n",
    "            kernel_constraint=my_positive_weights,\n",
    "            kernel_initializer=my_glorot_initializer,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "model.compile(loss='mse', optimizer='nadam', metrics=['mae'])\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")\n",
    "model.save('my_model_with_many_custom_parts')\n",
    "model = keras.models.load_model(\n",
    "    'my_model_with_many_custom_parts',\n",
    "    custom_objects={\n",
    "        'MyL1Regularizer': MyL1Regularizer,\n",
    "        'my_positive_weights': my_positive_weights,\n",
    "        'my_glorot_initializer': my_glorot_initializer,\n",
    "        'my_softplus': my_softplus,\n",
    "    },\n",
    ")\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Metrics\n",
    "Losses and metrics are conceptually not the same thing: losses (e.g., cross entropy) are used by gradient descent to *train* a model, so they must be differentiable (at least at the points where they are evaluated), and their gradients should not be zero everywhere. Plus, it’s OK if they are not easily interpretable by humans. In contrast, metrics (e.g., accuracy) are used to *evaluate* a model: they must be more easily interpretable, and they can be nondifferentiable or have zero gradients everywhere.\n",
    "\n",
    "That said, in most cases, defining a custom metric function is exactly the same as defining a custom loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once again, let’s create a basic Keras model\n",
    "keras.utils.set_random_seed(42)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            30,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        keras.layers.Dense(1),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='nadam', metrics=[create_huber(2.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 596us/step - loss: 1.3734 - huber_fn: 0.5275\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 556us/step - loss: 0.7705 - huber_fn: 0.3166\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8470edd910>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with our custom metric\n",
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: If we use the same function as the loss and a metric, we may be surprised to see slightly different results. This is in part because the operations are not computed exactly in the same order, so there might be tiny floating point errors. More importantly, if we use sample weights or class weights, then the equations are a bit different:\n",
    "- The `fit()` method keeps track of the mean of all batch losses seen so far since the start of the epoch. Each batch loss is the sum of the weighted instance losses divided by the *batch size* (not the sum of weights, so the batch loss is *not* the weighted mean of the losses).\n",
    "- The metric since the start of the epoch is equal to the sum of weighted instance losses divided by sum of all weights seen so far. In other words, it is the weighted mean of all the instance losses. Not the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming metrics\n",
    "For each batch during training, Keras will compute this metric and keep track of its mean since the beginning of the epoch. Most of the time, this is exactly what we want. But not always! Consider a binary classifier’s precision. Suppose the model made five positive predictions in the first batch, four of which were correct: that’s 80% precision. Then suppose the model made three positive predictions in the second batch, but they were all incorrect: that’s 0% precision for the second batch. If we just compute the mean of these two precisions, we get 40%. But that’s not the model’s precision over these two batches! Indeed, there were a total of four true positives (4 + 0) out of eight positive predictions (5 + 3), so the overall precision is 50%. What we need is an object that can keep track of the number of true positives and the number of false positives and that can compute the precision based on these numbers when requested. This is precisely what the `keras.metrics.Precision` class does.This is called a *streaming metric* (or *stateful metric*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.8>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = keras.metrics.Precision()\n",
    "precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.5>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'true_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>,\n",
       " <tf.Variable 'false_positives:0' shape=(1,) dtype=float32, numpy=array([4.], dtype=float32)>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a custom streaming metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold: float = 1.0, **kwargs) -> None:\n",
    "        # Handles base args (e.g., dtype)\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        self.total = self.add_weight('total', initializer='zeros')\n",
    "        self.count = self.add_weight('count', initializer='zeros')\n",
    "\n",
    "    def update_state(\n",
    "        self,\n",
    "        y_true: tf.Tensor,\n",
    "        y_pred: tf.Tensor,\n",
    "        sample_weight: Optional[tf.Tensor] = None,\n",
    "    ) -> None:\n",
    "        sample_metrics = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(sample_metrics))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "\n",
    "    def result(self) -> tf.Tensor:\n",
    "        return self.total / self.count\n",
    "\n",
    "    def get_config(self) -> dict[str, Any]:\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'threshold': self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s walk through this code:\n",
    "- The constructor uses the `add_weight()` method to create the variables needed to keep track of the metric’s state over multiple batches. We could just create variables manually if we preferred. Keras tracks any `tf.Variable` that is set as an attribute (and more generally, any “trackable” object, such as layers or models).\n",
    "- The `update_state()` method is called when we use an instance of this class as a function.\n",
    "- When we use the metric as a function, the `update_state()` method gets called first, then the `result()` method is called, and its output is returned.\n",
    "- The default implementation of the `reset_states()` method resets all variables to 0.0.\n",
    "\n",
    "When we define a metric using a simple function, Keras automatically calls it for each batch, and it keeps track of the mean during each epoch, just like we did manually. So the only benefit of our `HuberMetric` class is that the `threshold` will be saved. \n",
    "\n",
    "**Extra material**: The rest of this section tests the `HuberMetric` class and shows another implementation subclassing `keras.metrics.Mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=14.0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = HuberMetric(2.0)\n",
    "\n",
    "# total = 2 * |10 - 2| - 2²/2 = 14\n",
    "# count = 1\n",
    "# result = 14 / 1 = 14\n",
    "m(tf.constant([[2.0]]), tf.constant([[10.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total += (|1 - 0|² / 2) + (2 * |9.25 - 5| - 2² / 2) = 14 + 7 = 21\n",
    "# count += 2 = 3\n",
    "# result = total / count = 21 / 3 = 7\n",
    "m(tf.constant([[0.0], [5.0]]), tf.constant([[1.0], [9.25]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=7.0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=21.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=3.0>]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'total:0' shape=() dtype=float32, numpy=0.0>,\n",
       " <tf.Variable 'count:0' shape=() dtype=float32, numpy=0.0>]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.reset_states()\n",
    "m.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check that the `HuberMetric` class works well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            30,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        keras.layers.Dense(1),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=create_huber(2.0), optimizer='nadam', metrics=[HuberMetric(2.0)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 587us/step - loss: 0.4997 - huber_metric_10: 0.4997\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 574us/step - loss: 0.2781 - huber_metric_10: 0.2781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f83d0f59280>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_with_a_custom_metric/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('my_model_with_a_custom_metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    'my_model_with_a_custom_metric',\n",
    "    custom_objects={'huber_fn': create_huber(2.0), 'HuberMetric': HuberMetric},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 625us/step - loss: 0.2206 - huber_metric_10: 0.2206\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 609us/step - loss: 0.2018 - huber_metric_10: 0.2018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f845023daf0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.metrics` contains the model’s loss followed by the model’s metric(s), so the `HuberMetric` is `model.metrics[-1]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it works fine! More simply, we could have created the class like \n",
    "this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberMetric(keras.metrics.Mean):\n",
    "    def __init__(\n",
    "        self,\n",
    "        threshold: float = 1.0,\n",
    "        name: str = 'HuberMetric',\n",
    "        dtype: Optional[tf.DType] = None,\n",
    "    ) -> None:\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "\n",
    "    def update_state(\n",
    "        self,\n",
    "        y_true: tf.Tensor,\n",
    "        y_pred: tf.Tensor,\n",
    "        sample_weight: Optional[tf.Tensor] = None,\n",
    "    ) -> None:\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super().update_state(metric, sample_weight)\n",
    "\n",
    "    def get_config(self) -> dict[str, Any]:\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'threshold': self.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class handles shapes better, and it also supports sample weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            30,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            input_shape=input_shape,\n",
    "        ),\n",
    "        keras.layers.Dense(1),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=keras.losses.Huber(2.0),\n",
    "    optimizer='nadam',\n",
    "    weighted_metrics=[HuberMetric(2.0)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 645us/step - loss: 0.2505 - HuberMetric: 0.5049\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 635us/step - loss: 0.1416 - HuberMetric: 0.2854\n"
     ]
    }
   ],
   "source": [
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train, epochs=2, sample_weight=sample_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2505398094654083, 0.2505398573110885)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    history.history['loss'][0],\n",
    "    history.history['HuberMetric'][0] * sample_weight.mean(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model_with_a_custom_metric_v2/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('my_model_with_a_custom_metric_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    'my_model_with_a_custom_metric_v2',\n",
    "    custom_objects={'HuberMetric': HuberMetric},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 665us/step - loss: 0.2257 - HuberMetric: 0.2257\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 628us/step - loss: 0.2034 - HuberMetric: 0.2034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8460c2fa00>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics[-1].threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Layers\n",
    "We may want to build:\n",
    "- An architecture that contains an exotic layer for which TensorFlow does not provide a default implementation.\n",
    "- A very repetitive architecture, in which a particular block of layers is repeated many times.\n",
    "\n",
    "Create a layer that have no weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Like all layers, it can be used as a function:\n",
    "exponential_layer([-1.0, 0.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding an exponential layer at the output of a regression model can be useful if the values to predict are positive and with very different scales (e.g., 0.001, 10., 10000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 845us/step - loss: 1.0631 - val_loss: 0.4457\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 591us/step - loss: 0.4562 - val_loss: 0.3798\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 585us/step - loss: 0.4029 - val_loss: 0.3548\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 597us/step - loss: 0.3851 - val_loss: 0.3464\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 582us/step - loss: 0.3708 - val_loss: 0.3449\n",
      "162/162 [==============================] - 0s 427us/step - loss: 0.3586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3586341440677643"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(30, activation='relu', input_shape=input_shape),\n",
    "        keras.layers.Dense(1),\n",
    "        exponential_layer,\n",
    "    ]\n",
    ")\n",
    "model.compile(loss='mse', optimizer='sgd')\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=5,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, it’s often preferable to replace the targets with the logarithm of the targets (and use no activation function in the output layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self, units: int, activation: Optional[Callable | str] = None, **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(\n",
    "        self,\n",
    "        # The Keras API calls this argument input_shape, but since it\n",
    "        # also includes the batch dimension, I prefer to call it\n",
    "        # batch_input_shape.\n",
    "        batch_input_shape: tf.TensorShape,\n",
    "    ) -> None:\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel',\n",
    "            shape=[batch_input_shape[-1], self.units],\n",
    "            initializer='he_normal',\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            name='bias', shape=[self.units], initializer='zeros'\n",
    "        )\n",
    "\n",
    "    def call(self, X: tf.Tensor) -> tf.Tensor:\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def get_config(self) -> dict[str, Any]:\n",
    "        base_config = super().get_config()\n",
    "        return {\n",
    "            **base_config,\n",
    "            'units': self.units,\n",
    "            'activation': keras.activations.serialize(self.activation),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let’s walk through this code:\n",
    "- The constructor takes all the hyperparameters as arguments (in this example, `units` and `activation`), and importantly it also takes a `**kwargs` argument. It calls the parent constructor, passing it the `kwargs`: this takes care of standard arguments such as `input_shape`, `trainable`, and `name`. Then it saves the hyperparameters as attributes, converting the `activation` argument to the appropriate activation function using the `keras.activations.get()` function (it accepts functions, standard strings like `'relu'` or `'swish'`, or simply `None`).\n",
    "- The `build()` method’s role is to create the layer’s variables by calling the `add_weight()` method for each weight. The `build()` method is called the first time the layer is *used*. At that point, Keras will know the shape of this layer’s inputs, and it will pass it to the `build()` method, which is often necessary to create some of the weights. e.g. we need to know the number of neurons in the previous layer in order to create the connection weights matrix (i.e., the `'kernel'`): this corresponds to the size of the last dimension of the inputs.\n",
    "- The `call()` method performs the desired operations.\n",
    "- The `get_config()` method is just like in the previous custom classes.\n",
    "\n",
    "**Note**: Keras automatically infers the output shape, except when the layer is dynamic. In this (rare) case, we need to implement the `compute_output_shape()` method, which must return a `TensorShape` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 836us/step - loss: 2.8036 - val_loss: 2.9430\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 671us/step - loss: 0.7903 - val_loss: 1.3091\n",
      "162/162 [==============================] - 0s 426us/step - loss: 0.6557\n",
      "INFO:tensorflow:Assets written to: my_model_with_a_custom_layer/assets\n"
     ]
    }
   ],
   "source": [
    "# Shows that a custom layer can be used normally\n",
    "keras.utils.set_random_seed(42)\n",
    "model = keras.Sequential(\n",
    "    [MyDense(30, activation='relu', input_shape=input_shape), MyDense(1)],\n",
    ")\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")\n",
    "model.evaluate(X_test_scaled, y_test)\n",
    "model.save('my_model_with_a_custom_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 892us/step - loss: 0.5665 - val_loss: 0.4506\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 692us/step - loss: 0.4502 - val_loss: 0.5153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f848168da30>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows how to load a model with a custom layer\n",
    "model = keras.models.load_model(\n",
    "    'my_model_with_a_custom_layer', custom_objects={'MyDense': MyDense}\n",
    ")\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create a layer with multiple inputs and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X: tuple[tf.Tensor, ...]) -> tuple[tf.Tensor, ...]:\n",
    "        X1, X2 = X\n",
    "        print('X1.shape: ', X1.shape, ' X2.shape: ', X2.shape)\n",
    "        return X1 + X2, X1 * X2, X1 / X2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our custom layer can be called using the functional API like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (None, 2)  X2.shape:  (None, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'my_multi_layer_4')>,\n",
       " <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'my_multi_layer_4')>,\n",
       " <KerasTensor: shape=(None, 2) dtype=float32 (created by layer 'my_multi_layer_4')>)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests MyMultiLayer with symbolic inputs\n",
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `call()` method receives symbolic inputs, and it returns symbolic outputs. The shapes are only partially specified at this stage: we don’t know the batch size, which is why the first dimension is `None`.\n",
    "We can also pass actual data to the custom layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (2, 2)  X2.shape:  (2, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 9., 18.],\n",
       "        [ 6., 10.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[18., 72.],\n",
       "        [ 8., 21.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[0.5      , 0.5      ],\n",
       "        [0.5      , 2.3333333]], dtype=float32)>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests MyMultiLayer with actual data\n",
    "X1, X2 = np.array([[3.0, 6.0], [2.0, 7.0]]), np.array(\n",
    "    [[6.0, 12.0], [4.0, 3.0]]\n",
    ")\n",
    "MyMultiLayer()((X1, X2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s create a layer with a different behavior during training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev: float, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X: tf.Tensor, training: Optional[bool] = None) -> tf.Tensor:\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a simple model that uses this custom layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 867us/step - loss: 2.1976 - val_loss: 26.5902\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 671us/step - loss: 1.4224 - val_loss: 19.3606\n",
      "162/162 [==============================] - 0s 423us/step - loss: 1.0180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0180009603500366"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests MyGaussianNoise\n",
    "keras.utils.set_random_seed(42)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        MyGaussianNoise(stddev=1.0, input_shape=input_shape),\n",
    "        keras.layers.Dense(\n",
    "            30, activation='relu', kernel_initializer='he_normal'\n",
    "        ),\n",
    "        keras.layers.Dense(1),\n",
    "    ],\n",
    ")\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Models\n",
    "Suppose we want to build the model represented below:\n",
    "\n",
    "<center>\n",
    "  <img \n",
    "    src=\"../images/12/custom_model.png\" \n",
    "    onerror=\"\n",
    "      this.onerror = null;\n",
    "      const repo = 'https://github.com/alirezatheh/handson-ml3-notes/blob/main';\n",
    "      this.src = repo + this.src.split('..')[1];\n",
    "    \"\n",
    "  >\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers: int, n_neurons: int, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [\n",
    "            keras.layers.Dense(\n",
    "                n_neurons, activation='relu', kernel_initializer='he_normal'\n",
    "            )\n",
    "            for _ in range(n_layers)\n",
    "        ]\n",
    "\n",
    "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Keras automatically detects that the `hidden` attribute contains trackable objects (layers in this case), so their variables are automatically added to this layer’s list of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.Model):\n",
    "    def __init__(self, output_dim: int, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(\n",
    "            30, activation='relu', kernel_initializer='he_normal'\n",
    "        )\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs: tf.Tensor) -> tf.Tensor:\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 810us/step - loss: 5.2455\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 807us/step - loss: 0.8515\n",
      "162/162 [==============================] - 0s 512us/step - loss: 0.6072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as dense_19_layer_call_and_return_conditional_losses, dense_19_layer_call_fn, dense_20_layer_call_and_return_conditional_losses, dense_20_layer_call_fn, dense_21_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_custom_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_custom_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Shows that the model can be used normally\n",
    "keras.utils.set_random_seed(42)\n",
    "model = ResidualRegressor(1)\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "model.save('my_custom_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 879us/step - loss: 0.7176\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 816us/step - loss: 0.5186\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.62953055],\n",
       "       [1.2767944 ],\n",
       "       [4.634055  ]], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The model can be loaded and we can continue training or use it to\n",
    "# make predictions\n",
    "model = keras.models.load_model('my_custom_model')\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "model.predict(X_test_scaled[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have defined the model using the sequential API instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "block1 = ResidualBlock(2, 30)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            30, activation='relu', kernel_initializer='he_normal'\n",
    "        ),\n",
    "        block1,\n",
    "        block1,\n",
    "        block1,\n",
    "        block1,\n",
    "        ResidualBlock(2, 30),\n",
    "        keras.layers.Dense(1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses and Metrics Based on Model Internals\n",
    "The custom losses and metrics we defined earlier were all based on the labels and the predictions (and optionally sample weights). There will be times when we want to define losses based on other parts of our model, such as the weights or activations of its hidden layers. This may be useful for regularization purposes or to monitor some internal aspect of our model.\n",
    "\n",
    "This custom model will have an auxiliary output on top of the upper hidden layer. The loss associated with this auxiliary output will be called the *reconstruction loss*: it is the mean squared difference between the reconstruction and the inputs. By adding this reconstruction loss to the main loss, we will encourage the model to preserve as much information as possible through the hidden layers, even information that is not directly useful for the regression task itself. In practice, this loss sometimes improves generalization (it is a regularization loss). It is also possible to add a custom metric using the model’s `add_metric()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconstructingRegressor(keras.Model):\n",
    "    def __init__(self, output_dim: int, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [\n",
    "            keras.layers.Dense(\n",
    "                30, activation='relu', kernel_initializer='he_normal'\n",
    "            )\n",
    "            for _ in range(5)\n",
    "        ]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        self.reconstruction_mean = keras.metrics.Mean(\n",
    "            name='reconstruction_error'\n",
    "        )\n",
    "\n",
    "    def build(self, batch_input_shape: tf.TensorShape) -> None:\n",
    "        n_inputs = batch_input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "\n",
    "    def call(\n",
    "        self, inputs: tf.Tensor, training: Optional[bool] = None\n",
    "    ) -> tf.Tensor:\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        reconstruction = self.reconstruct(Z)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - inputs))\n",
    "        self.add_loss(0.05 * recon_loss)\n",
    "        if training:\n",
    "            result = self.reconstruction_mean(recon_loss)\n",
    "            self.add_metric(result)\n",
    "        return self.out(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Note**: We can also call `add_loss()` on any layer inside the model, as the \n",
    "model recursively gathers losses from all of its layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 820us/step - loss: 0.7640 - reconstruction_error: 1.2728\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 809us/step - loss: 0.4584 - reconstruction_error: 0.6340\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 786us/step - loss: 0.4211 - reconstruction_error: 0.4342\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 745us/step - loss: 0.3753 - reconstruction_error: 0.3597\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 772us/step - loss: 0.3618 - reconstruction_error: 0.2908\n"
     ]
    }
   ],
   "source": [
    "keras.utils.set_random_seed(42)\n",
    "model = ReconstructingRegressor(1)\n",
    "model.compile(loss='mse', optimizer='nadam')\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Gradients Using Autodiff\n",
    "Let’s consider a simple toy function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "TensorLike = tf.types.experimental.TensorLike\n",
    "AnyTensorLike = TensorLike | tf.Variable\n",
    "\n",
    "\n",
    "def f(w1: AnyTensorLike, w2: AnyTensorLike) -> TensorLike:\n",
    "    return 3 * w1**2 + 2 * w1 * w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "One solution could be to compute an approximation of each partial derivative by measuring how much the function’s output changes when we tweak the corresponding parameter by a tiny amount:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.000003007075065"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2 = 5, 3\n",
    "eps = 1e-6\n",
    "(f(w1 + eps, w2) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000003174137"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f(w1, w2 + eps) - f(w1, w2)) / eps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Looks about right! but it is just an approximation and having to call `f()` at least once per parameter makes this approach intractable for large neural networks. So instead, we should use reverse-mode autodiff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = tf.Variable(5.0), tf.Variable(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "`tf.GradientTape` context will automatically record every operation that involves a variable, and finally we ask this tape to compute the gradients of the result `z` with regard to both variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The `gradient()` method only goes through the recorded computations once (in reverse order), no matter how many variables there are, so it is incredibly efficient.\n",
    "\n",
    "**Tip**: In order to save memory, only put the strict minimum inside the `tf.GradientTape()` block. Alternatively, pause recording by creating a `with tape.stop_recording()` block inside the `tf.GradientTape()` block.\n",
    "\n",
    "The tape is automatically erased immediately after we call its `gradient()`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-persistent GradientTape can only be used to compute one set of gradients (or jacobians)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "# Returns tensor 36.0\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "try:\n",
    "    # Raises a RuntimeError!\n",
    "    dz_dw2 = tape.gradient(z, w2)\n",
    "except RuntimeError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "\n",
    "# Returns tensor 36.0\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "# Returns tensor 10.0, works fine now!\n",
    "dz_dw2 = tape.gradient(z, w2)\n",
    "del tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dw1, dz_dw2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Tracking non-variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2 = tf.constant(5.0), tf.constant(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "But we can force the tape to watch any tensors we like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "\n",
    "gradients = tape.gradient(z, [c1, c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If given a vector, `tape.gradient()` will compute the gradient of the vector’s sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.0)\n",
    "    z2 = f(w1, w2 + 5.0)\n",
    "    z3 = f(w1, w2 + 7.0)\n",
    "\n",
    "tape.gradient([z1, z2, z3], [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=136.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=30.0>]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows that we get the same result as the previous cell\n",
    "with tf.GradientTape() as tape:\n",
    "    z1 = f(w1, w2 + 2.0)\n",
    "    z2 = f(w1, w2 + 5.0)\n",
    "    z3 = f(w1, w2 + 7.0)\n",
    "    z = z1 + z2 + z3\n",
    "\n",
    "tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "How to compute the jacobians and the hessians:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "hessians = [\n",
    "    hessian_tape.gradient(jacobian, [w1, w2]) for jacobian in jacobians\n",
    "]\n",
    "del hessian_tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=36.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       "  <tf.Tensor: shape=(), dtype=float32, numpy=2.0>],\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hessians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In some cases we may want to stop gradients from backpropagating through some part of our neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(w1: AnyTensorLike, w2: AnyTensorLike) -> TensorLike:\n",
    "    return 3 * w1**2 + tf.stop_gradient(2 * w1 * w2)\n",
    "\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    # Same result as without stop_gradient()\n",
    "    z = f(w1, w2)\n",
    "\n",
    "gradients = tape.gradient(z, [w1, w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We may occasionally run into some numerical issues when computing gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(), dtype=float32, numpy=inf>]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(1e-50)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = tf.sqrt(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "To solve this, it’s often a good idea to add a tiny value to $x$ (such as \n",
    "$10^{–6}$) when computing its square root.\n",
    "\n",
    "The exponential function is also a frequent source of headaches, as it grows \n",
    "extremely fast. e.g. the way `my_softplus()` was defined earlier is not \n",
    "numerically stable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T15:32:20.604508Z",
     "start_time": "2023-11-26T15:32:20.511435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=inf>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.math.log(tf.exp(tf.constant(100.0, dtype=tf.float32)) + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-26T15:33:14.798039Z",
     "start_time": "2023-11-26T15:33:14.539226Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([1.0e30])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "But it’s possible to rewrite the function to make it numerically stable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z: AnyTensorLike) -> tf.Tensor:\n",
    "    return tf.math.log(1 + tf.exp(-tf.abs(z))) + tf.maximum(0.0, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the proof that this equation is equal to $\\log(1+\\exp(z))$:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "\\text{softplus}(z)&=\\log(1+\\exp(z))\n",
    "\\\\&=\\log(1+\\exp(z))-\\log(\\exp(z))+\\log(\\exp(z))\n",
    "\\\\&=\\log\\left[(1+\\exp(z))/\\exp(z)\\right]+\\log(\\exp(z))\n",
    "\\\\&=\\log\\left[(1+\\exp(z))/\\exp(z)\\right]+z\n",
    "\\\\&=\\log\\left[1/\\exp(z)+\\exp(z)/\\exp(z)\\right]+z\n",
    "\\\\&=\\log\\left[\\exp(–z)+1\\right]+z\n",
    "\\\\&=\\text{softplus}(–z)+z\n",
    "\\\\&=\\text{softplus}(–|z|)+\\max(0,z)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "If we consider both cases, $z<0$ or $z\\geq0$, we will see that this works.\n",
    "\n",
    "In some rare cases, a numerically stable function may still have numerically \n",
    "unstable gradients. In such cases, we will have to tell TensorFlow which \n",
    "equation to use for the gradients, rather than letting it use autodiff. For \n",
    "this, we must use the `@tf.custom_gradient`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def my_softplus(\n",
    "    z: AnyTensorLike,\n",
    ") -> tuple[tf.Tensor, Callable[[tf.Tensor], tf.Tensor]]:\n",
    "    def my_softplus_gradients(\n",
    "        # grads is backprop'ed from upper layers\n",
    "        grads: tf.Tensor,\n",
    "    ) -> tf.Tensor:\n",
    "        # Stable grads of softplus\n",
    "        return grads * (1 - 1 / (1 + tf.exp(z)))\n",
    "\n",
    "    result = tf.math.log(1 + tf.exp(-tf.abs(z))) + tf.maximum(0.0, z)\n",
    "    return result, my_softplus_gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " The derivative of $\\log(1+\\exp(z))$ is $\\exp(z)/(1+\\exp(z))$. But this form is \n",
    " not stable. With a bit of algebraic manipulation, we can show that it’s also \n",
    " equal to $1–1/(1+\\exp(z))$, which *is* stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1000.], dtype=float32)>,\n",
       " [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows that the function is now stable, as well as its gradients\n",
    "x = tf.Variable([1000.0])\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "\n",
    "z, tape.gradient(z, [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Training Loops\n",
    "**Tip**: Unless we’re learning or we really need the extra flexibility, we should prefer using the `fit()` method rather than implementing our own training loop, especially if we work in a team.\n",
    "\n",
    "There’s no need to compile it, since we will handle the training loop manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To ensure reproducibility\n",
    "keras.utils.set_random_seed(42)\n",
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(\n",
    "            30,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            kernel_regularizer=l2_reg,\n",
    "        ),\n",
    "        keras.layers.Dense(1, kernel_regularizer=l2_reg),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Next, let’s create a tiny function that will randomly sample a batch of instances from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(\n",
    "    X: np.ndarray, y: np.ndarray, batch_size: int = 32\n",
    ") -> np.ndarray:\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let’s also define a function that will display the training status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metric = keras.metrics.Metric\n",
    "\n",
    "\n",
    "def print_status_bar(\n",
    "    step: int, total: int, loss: Metric, metrics: Optional[list[Metric]] = None\n",
    ") -> None:\n",
    "    metrics = ' - '.join(\n",
    "        [f'{m.name}: {m.result():.4f}' for m in [loss] + (metrics or [])]\n",
    "    )\n",
    "    end = '' if step < total else '\\n'\n",
    "    print(f'\\r{step}/{total} - ' + metrics, end=end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Using `\\r` (carriage return) along with `end=''` ensures that the status bar always gets printed on the same line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.MeanAbsoluteError()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "362/362 - mean: 0.6219 - mean_absolute_error: 0.4975\n",
      "Epoch 2/5\n",
      "362/362 - mean: 0.6272 - mean_absolute_error: 0.5049\n",
      "Epoch 3/5\n",
      "362/362 - mean: 0.6019 - mean_absolute_error: 0.4951\n",
      "Epoch 4/5\n",
      "362/362 - mean: 0.6088 - mean_absolute_error: 0.4971\n",
      "Epoch 5/5\n",
      "362/362 - mean: 0.6159 - mean_absolute_error: 0.5032\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f'Epoch {epoch}/{n_epochs}')\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch, training=True)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # If our model has variable constraints\n",
    "        for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "\n",
    "        # Update the mean loss and the metrics\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "\n",
    "        print_status_bar(step, n_steps, mean_loss, metrics)\n",
    "\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Inside the `tf.GradientTape()` block we compute the loss: it is equal to the \n",
    "main loss plus the other losses (in this model, there is one regularization \n",
    "loss per layer). Since the `mean_squared_error()` function returns one loss \n",
    "per instance, we compute the mean over the batch using `tf.reduce_mean()` (if \n",
    "we wanted to apply different weights to each instance, this is where we would \n",
    "do it). The regularization losses are already reduced to a single scalar each, \n",
    "so we just need to sum them (using `tf.add_n()`, which sums multiple tensors of \n",
    "the same shape and data type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0425ac6b66024c7d83d98459be6f1811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac07a118bd649158e28c73591809f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162f6cd2e9b4491d9a3b1bc378990eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116af880df174758bf744dc1fe5fa81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20afe56af0b54d12be3dd84e29e9f0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662afff06af24ded83a719eabc1a8a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shows how to use the tqdm package to display nice progress bars\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "with trange(1, n_epochs + 1, desc='All epochs') as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=f'Epoch {epoch}/{n_epochs}') as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(\n",
    "                    zip(gradients, model.trainable_variables)\n",
    "                )\n",
    "\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))\n",
    "\n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status['loss'] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "\n",
    "                steps.set_postfix(status)\n",
    "\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If we want to apply gradient clipping, set the optimizer’s `clipnorm` or `clipvalue` hyperparameter. If we want to apply any other transformation to the gradients, simply do so before calling the `apply_gradients()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Functions and Graphs\n",
    "Back in TensorFlow 1, graphs were unavoidable (as were the complexities that came with them) because they were a central part of TensorFlow’s API. Since TensorFlow 2 (released in 2019), graphs are still there, but not as central, and they’re much (much!) simpler to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x: TensorLike) -> TensorLike:\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, let’s use `tf.function()` to convert this Python function to a *TensorFlow function*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x7f83d1c22a90>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Under the hood, `tf.function()` analyzed the computations performed by the `cube()` function and generated an equivalent computation graph!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can use it as a decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x: TensorLike) -> tf.Tensor:\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The original Python function is still available via the TF function’s \n",
    "`python_function` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf_cube.python_function(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow optimizes the computation graph, pruning unused nodes, simplifying expressions (e.g., 1 + 2 would get replaced with 3), and more. Once the optimized graph is ready, the TF function efficiently executes the operations in the graph, in the appropriate order (and in parallel when it can). As a result, a TF function will usually run much faster than the original Python function, especially if it performs complex computations.\n",
    "\n",
    "If we set `jit_compile=True` when calling `tf.function()`, then TensorFlow will use *accelerated linear algebra* (XLA) to compile dedicated kernels for our graph, often fusing multiple operations. Not only will this be much faster, it will also use dramatically less RAM.\n",
    "\n",
    "In Keras we just need to set `jit_compile=True` when calling the `compile()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Function Rules\n",
    "- If we call any external library, including NumPy or even the standard library, this call will run only during tracing; it will not be part of the graph. Indeed, a TensorFlow graph can only include TensorFlow constructs (tensors, operations, variables, datasets, and so on).\n",
    "  - We can wrap arbitrary Python code in a `tf.py_function()` operation, but doing so will hinder performance, as TensorFlow will not be able to do any graph optimization on this code. It will also reduce portability, as the graph will only run on platforms where Python is available (and where the right libraries are installed).\n",
    "- We can call other Python functions or TF functions, but they should follow the same rules, as TensorFlow will capture their operations in the computation graph. Note that these other functions do not need to be decorated with `@tf.function`.\n",
    "- If the function creates a TensorFlow variable (or any other stateful TensorFlow object, such as a dataset or a queue), it must do so upon the very first call, and only then, or else we will get an exception. It is usually preferable to create variables outside of the TF function (e.g., in the `build()` method of a custom layer).\n",
    "- The source code of our Python function should be available to TensorFlow. If the source code is unavailable (e.g. if we define our function in the Python shell, which does not give access to the source code, or if we deploy only the compiled *\\*.pyc* Python files to production), then the graph generation process will fail or have limited functionality.\n",
    "- TensorFlow will only capture for loops that iterate over a tensor or a `tf.data.Dataset`.\n",
    "- As always, for performance reasons, we should prefer a vectorized implementation whenever we can, rather than using loops.\n",
    "\n",
    "\n",
    "**Note:** The rest of the code in this section is in appendix D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Functions and Concrete Functions\n",
    "TF functions are polymorphic, meaning they support inputs of different types (and shapes). Every time we call a TF function with a new combination of input types or shapes, it generates a new *concrete function*, with its own graph specialized for this particular combination. Such a combination of argument types and shapes is called an *input signature*.\n",
    "\n",
    "If we call the TF function with an input signature it has already seen before, it will reuse the concrete function it generated earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConcreteFunction tf_cube(x) at 0x7F843148D910>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "concrete_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function is tf_cube.get_concrete_function(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure below shows the `tf_cube()` TF function, after we called `tf_cube(2)` and `tf_cube(tf.constant(2.0))`:\n",
    "\n",
    "<center>\n",
    "  <img \n",
    "    src=\"../images/12/tf_function.png\" \n",
    "    onerror=\"\n",
    "      this.onerror = null;\n",
    "      const repo = 'https://github.com/alirezatheh/handson-ml3-notes/blob/main';\n",
    "      this.src = repo + this.src.split('..')[1];\n",
    "    \"\n",
    "  >\n",
    "</center>\n",
    "\n",
    "Two concrete functions were generated, one for each signature, each with its own optimized *function graph* (`FuncGraph`) and its own *function definition* (`FunctionDef`).\n",
    "\n",
    "A function definition points to the parts of the graph that correspond to the function’s inputs and outputs. In each `FuncGraph`, the nodes (ovals) represent operations (e.g., power, constants, or placeholders for arguments like `x`), while the edges (the solid arrows between the operations) represent the tensors that will flow through the graph.\n",
    "\n",
    "The concrete function on the left is specialized for `x=2`, so TensorFlow managed to simplify it to just output 8 all the time (note that the function definition does not even have an input).\n",
    "\n",
    "The tensors in these graphs are *symbolic tensors*, meaning they don’t have an actual value, just a data type, a shape, and a name. They represent the future tensors that will flow through the graph once an actual value is fed to the placeholder `x` and the graph is executed. Symbolic tensors make it possible to specify ahead of time how to connect operations, and they also allow TensorFlow to recursively infer the data types and shapes of all tensors, given the data types and shapes of their inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Function Definitions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.func_graph.FuncGraph at 0x7f8441219040>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'pow/y' type=Const>,\n",
       " <tf.Operation 'pow' type=Pow>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ops = concrete_function.graph.get_operations()\n",
    "ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In this example, the first operation represents the input argument `x` (it is called a *placeholder*), the second “operation” represents the constant 3, the third operation represents the power operation (**), and the final operation represents the output of this function (it is an identity operation, meaning it will do nothing more than copy the output of the power operation. It is only here for technical reasons, to ensure that TF functions don’t leak internal structures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'x:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'pow/y:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op = ops[2]\n",
    "list(pow_op.inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'pow:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pow_op.outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<center>\n",
    "  <img \n",
    "    src=\"../images/12/computation_graph.png\" \n",
    "    onerror=\"\n",
    "      this.onerror = null;\n",
    "      const repo = 'https://github.com/alirezatheh/handson-ml3-notes/blob/main';\n",
    "      this.src = repo + this.src.split('..')[1];\n",
    "    \"\n",
    "  >\n",
    "</center>\n",
    "\n",
    "Note that each operation and each tensor has a name. tensor’s name is always the name of the operation that outputs this tensor, plus `:0` if it is the operation’s first output, or `:1` if it is the second output, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'x' type=Placeholder>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_operation_by_name('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Identity:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.graph.get_tensor_by_name('Identity:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The concrete function also contains the function definition (represented as a protocol buffer), which includes the function’s signature. This signature allows the concrete function to know which placeholders to feed with the input values, and which tensors to return:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"__inference_tf_cube_3515915\"\n",
       "input_arg {\n",
       "  name: \"x\"\n",
       "  type: DT_FLOAT\n",
       "}\n",
       "output_arg {\n",
       "  name: \"identity\"\n",
       "  type: DT_FLOAT\n",
       "}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_function.function_def.signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Closer Look at Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube(x: TensorLike) -> tf.Tensor:\n",
    "    print(f'x = {x}')\n",
    "    return x**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Tensor(\"x:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "result = tf_cube(tf.constant(2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This is because the `print()` function is not a TensorFlow operation, so it will only run when the Python function is traced, which happens in graph mode, with arguments replaced with symbolic tensors. Since the `print()` function was not captured into the graph, the next times we call `tf_cube()` with float32 scalar tensors, nothing is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 2\n"
     ]
    }
   ],
   "source": [
    "# New Python value: trace!\n",
    "result = tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 3\n"
     ]
    }
   ],
   "source": [
    "# New Python value: trace!\n",
    "result = tf_cube(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Tensor(\"x:0\", shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# New shape: trace!\n",
    "result = tf_cube(tf.constant([[1.0, 2.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Tensor(\"x:0\", shape=(2, 2), dtype=float32)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x7f84312f51f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function tf_cube at 0x7f84312f51f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# New shape: trace!\n",
    "result = tf_cube(tf.constant([[3.0, 4.0], [5.0, 6.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same shape: no trace\n",
    "result = tf_cube(tf.constant([[7.0, 8.0], [9.0, 10.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to specify a particular input signature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images: tf.Tensor) -> tf.Tensor:\n",
    "    # Shows when tracing happens\n",
    "    print('Tracing', images)\n",
    "    # Drop half the rows and columns\n",
    "    return images[:, ::2, ::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This TF function will accept any float32 tensor of shape `[*, 28, 28]`, and it \n",
    "will reuse the same concrete function every time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing Tensor(\"images:0\", shape=(None, 28, 28), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "# Works fine, traces the function\n",
    "preprocessed_images = shrink(img_batch_1)\n",
    "# Works fine, same concrete function\n",
    "preprocessed_images = shrink(img_batch_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python inputs incompatible with input_signature:\n",
      "  inputs: (\n",
      "    tf.Tensor(\n",
      "[[[0.7413678  0.62854624]\n",
      "  [0.01738465 0.3431449 ]]\n",
      "\n",
      " [[0.51063764 0.3777541 ]\n",
      "  [0.07321596 0.02137029]]], shape=(2, 2, 2), dtype=float32))\n",
      "  input_signature: (\n",
      "    TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name=None))\n"
     ]
    }
   ],
   "source": [
    "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
    "try:\n",
    "    # ValueError! Incompatible inputs\n",
    "    preprocessed_images = shrink(img_batch_3)\n",
    "except ValueError as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Autograph To Capture Control Flow\n",
    "A “static” `for` loop using `range()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x: TensorLike) -> tf.Tensor:\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'add/y' type=Const>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'add_1/y' type=Const>,\n",
       " <tf.Operation 'add_1' type=AddV2>,\n",
       " <tf.Operation 'add_2/y' type=Const>,\n",
       " <tf.Operation 'add_2' type=AddV2>,\n",
       " <tf.Operation 'add_3/y' type=Const>,\n",
       " <tf.Operation 'add_3' type=AddV2>,\n",
       " <tf.Operation 'add_4/y' type=Const>,\n",
       " <tf.Operation 'add_4' type=AddV2>,\n",
       " <tf.Operation 'add_5/y' type=Const>,\n",
       " <tf.Operation 'add_5' type=AddV2>,\n",
       " <tf.Operation 'add_6/y' type=Const>,\n",
       " <tf.Operation 'add_6' type=AddV2>,\n",
       " <tf.Operation 'add_7/y' type=Const>,\n",
       " <tf.Operation 'add_7' type=AddV2>,\n",
       " <tf.Operation 'add_8/y' type=Const>,\n",
       " <tf.Operation 'add_8' type=AddV2>,\n",
       " <tf.Operation 'add_9/y' type=Const>,\n",
       " <tf.Operation 'add_9' type=AddV2>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A “dynamic” loop using `tf.while_loop()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows how to use tf.while_loop (usually @tf.function is simpler)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def add_10(x: TensorLike) -> tf.Tensor:\n",
    "    def condition(i: tf.Tensor, x: TensorLike) -> tf.Tensor:\n",
    "        return tf.less(i, 10)\n",
    "\n",
    "    def body(i: tf.Tensor, x: TensorLike) -> tf.Tensor:\n",
    "        return tf.add(i, 1), tf.add(x, 1)\n",
    "\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=15>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10(tf.constant(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'Const' type=Const>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(5)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A “dynamic” `for` loop using `tf.range()` (captured by autograph):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def add_10(x: TensorLike) -> tf.Tensor:\n",
    "    for i in tf.range(10):\n",
    "        x = x + 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'x' type=Placeholder>,\n",
       " <tf.Operation 'range/start' type=Const>,\n",
       " <tf.Operation 'range/limit' type=Const>,\n",
       " <tf.Operation 'range/delta' type=Const>,\n",
       " <tf.Operation 'range' type=Range>,\n",
       " <tf.Operation 'sub' type=Sub>,\n",
       " <tf.Operation 'floordiv' type=FloorDiv>,\n",
       " <tf.Operation 'mod' type=FloorMod>,\n",
       " <tf.Operation 'zeros_like' type=Const>,\n",
       " <tf.Operation 'NotEqual' type=NotEqual>,\n",
       " <tf.Operation 'Cast' type=Cast>,\n",
       " <tf.Operation 'add' type=AddV2>,\n",
       " <tf.Operation 'zeros_like_1' type=Const>,\n",
       " <tf.Operation 'Maximum' type=Maximum>,\n",
       " <tf.Operation 'while/maximum_iterations' type=Const>,\n",
       " <tf.Operation 'while/loop_counter' type=Const>,\n",
       " <tf.Operation 'while' type=StatelessWhile>,\n",
       " <tf.Operation 'Identity' type=Identity>]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_10.get_concrete_function(tf.constant(0)).graph.get_operations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Variables and Other Resources in TF Functions\n",
    "In TensorFlow, variables and other stateful objects, such as queues or datasets, are called *resources*. TF functions treat them with special care: any operation that reads or updates a resource is considered stateful, and TF functions ensure that stateful operations are executed in the order they appear (as opposed to stateless operations, which may be run in parallel, so their order of execution is not guaranteed).\n",
    "\n",
    "Moreover, when we pass a resource as an argument to a TF function, it gets passed by reference, so the function may modify it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def increment(counter: tf.Variable, c: int = 1) -> tf.Variable:\n",
    "    return counter.assign_add(c)\n",
    "\n",
    "\n",
    "# Counter is now equal to 1\n",
    "increment(counter)\n",
    "# Counter is now equal to 2\n",
    "increment(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"counter\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function(counter).function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = tf.Variable(0)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def increment(c: int = 1) -> tf.Variable:\n",
    "    return counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "increment()\n",
    "increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"assignaddvariableop_resource\"\n",
       "type: DT_RESOURCE"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_def = increment.get_concrete_function().function_def\n",
    "function_def.signature.input_arg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    def __init__(self) -> None:\n",
    "        self.counter = tf.Variable(0)\n",
    "\n",
    "    @tf.function\n",
    "    def increment(self, c: int = 1) -> tf.Variable:\n",
    "        return self.counter.assign_add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=2>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter()\n",
    "c.increment()\n",
    "c.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__add(x: TensorLike) -> TensorLike:\n",
      "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
      "        do_return = False\n",
      "        retval_ = ag__.UndefinedReturnValue()\n",
      "\n",
      "        def get_state():\n",
      "            return (x,)\n",
      "\n",
      "        def set_state(vars_):\n",
      "            nonlocal x\n",
      "            (x,) = vars_\n",
      "\n",
      "        def loop_body(itr):\n",
      "            nonlocal x\n",
      "            i = itr\n",
      "            x = ag__.ld(x)\n",
      "            x += 1\n",
      "        i = ag__.Undefined('i')\n",
      "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
      "        try:\n",
      "            do_return = True\n",
      "            retval_ = ag__.ld(x)\n",
      "        except:\n",
      "            do_return = False\n",
      "            raise\n",
      "        return fscope.ret(retval_, do_return)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def add_10(x: TensorLike) -> tf.Tensor:\n",
    "    for i in tf.range(10):\n",
    "        x += 1\n",
    "    return x\n",
    "\n",
    "\n",
    "print(tf.autograph.to_code(add_10.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows how to display the autograph code with syntax highlighting\n",
    "\n",
    "\n",
    "def display_tf_code(func: Callable) -> None:\n",
    "    from IPython.display import Markdown, display\n",
    "\n",
    "    if hasattr(func, 'python_function'):\n",
    "        func = func.python_function\n",
    "    code = tf.autograph.to_code(func)\n",
    "    display(Markdown(f'```python\\n{code}\\n```'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def tf__add(x: TensorLike) -> TensorLike:\n",
       "    with ag__.FunctionScope('add_10', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:\n",
       "        do_return = False\n",
       "        retval_ = ag__.UndefinedReturnValue()\n",
       "\n",
       "        def get_state():\n",
       "            return (x,)\n",
       "\n",
       "        def set_state(vars_):\n",
       "            nonlocal x\n",
       "            (x,) = vars_\n",
       "\n",
       "        def loop_body(itr):\n",
       "            nonlocal x\n",
       "            i = itr\n",
       "            x = ag__.ld(x)\n",
       "            x += 1\n",
       "        i = ag__.Undefined('i')\n",
       "        ag__.for_stmt(ag__.converted_call(ag__.ld(tf).range, (10,), None, fscope), None, loop_body, get_state, set_state, ('x',), {'iterate_names': 'i'})\n",
       "        try:\n",
       "            do_return = True\n",
       "            retval_ = ag__.ld(x)\n",
       "        except:\n",
       "            do_return = False\n",
       "            raise\n",
       "        return fscope.ret(retval_, do_return)\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_tf_code(add_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TF Functions with Keras (or Not)\n",
    "By default, any custom function, layer, or model we use with Keras will automatically be converted to a TF function! However, in some cases we may want to deactivate this automatic conversion:\n",
    "- If our custom code cannot be turned into a TF function.\n",
    "- If we just want to debug our code (which is much easier in eager mode). \n",
    "\n",
    "To do this, we can simply pass `dynamic=True` when creating the model or any of its layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function\n",
    "\n",
    "\n",
    "def my_mse(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "    print('Tracing loss my_mse()')\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom metric function\n",
    "\n",
    "\n",
    "def my_mae(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "    print('Tracing metric my_mae()')\n",
    "    return tf.reduce_mean(tf.abs(y_pred - y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom layer\n",
    "\n",
    "\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self, units: int, activation: Optional[str | Callable] = None, **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, input_shape: tf.TensorShape) -> None:\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel',\n",
    "            shape=(input_shape[1], self.units),\n",
    "            initializer='uniform',\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.biases = self.add_weight(\n",
    "            name='bias',\n",
    "            shape=(self.units,),\n",
    "            initializer='zeros',\n",
    "            trainable=True,\n",
    "        )\n",
    "\n",
    "    def call(self, X: tf.Tensor) -> tf.Tensor:\n",
    "        print('Tracing MyDense.call()')\n",
    "        return self.activation(X @ self.kernel + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom model\n",
    "\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = MyDense(30, activation='relu')\n",
    "        self.hidden2 = MyDense(30, activation='relu')\n",
    "        self.output_ = MyDense(1)\n",
    "\n",
    "    def call(self, input: tf.Tensor) -> tf.Tensor:\n",
    "        print('Tracing MyModel.call()')\n",
    "        hidden1 = self.hidden1(input)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input, hidden2])\n",
    "        output = self.output_(concat)\n",
    "        return output\n",
    "\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer='nadam', metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "296/363 [=======================>......] - ETA: 0s - loss: 1.5172 - my_mae: 0.8562Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3255 - my_mae: 0.7900 - val_loss: 0.5569 - val_my_mae: 0.4819\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 792us/step - loss: 0.4419 - my_mae: 0.4767 - val_loss: 0.4664 - val_my_mae: 0.4576\n",
      "162/162 [==============================] - 0s 460us/step - loss: 0.4164 - my_mae: 0.4639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4163525104522705, 0.4639028012752533]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=2,\n",
    "    validation_data=(X_valid_scaled, y_valid),\n",
    ")\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel(dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=my_mse, optimizer='nadam', metrics=[my_mae])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the custom code will be called at each iteration. Let’s fit, validate and evaluate with tiny datasets to avoid getting too much output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.507260322570801, 2.0566811561584473]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled[:64],\n",
    "    y_train[:64],\n",
    "    epochs=1,\n",
    "    validation_data=(X_valid_scaled[:64], y_valid[:64]),\n",
    "    verbose=0,\n",
    ")\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can compile a model with `run_eagerly=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=my_mse, optimizer='nadam', metrics=[my_mae], run_eagerly=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n",
      "Tracing MyModel.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing MyDense.call()\n",
      "Tracing loss my_mse()\n",
      "Tracing metric my_mae()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.507260322570801, 2.0566811561584473]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled[:64],\n",
    "    y_train[:64],\n",
    "    epochs=1,\n",
    "    validation_data=(X_valid_scaled[:64], y_valid[:64]),\n",
    "    verbose=0,\n",
    ")\n",
    "model.evaluate(X_test_scaled[:64], y_test[:64], verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Material – Custom Optimizers\n",
    "Defining custom optimizers is not very common, but in case we are one of the happy few who gets to write one, here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMomentumOptimizer(keras.optimizers.Optimizer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        learning_rate: float = 0.001,\n",
    "        momentum: float = 0.9,\n",
    "        name: str = 'MyMomentumOptimizer',\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        super().__init__(name, **kwargs)\n",
    "        self._learning_rate = self._build_learning_rate(learning_rate)\n",
    "        self.momentum = momentum\n",
    "\n",
    "    def build(self, var_list: list[tf.Variable]) -> None:\n",
    "        super().build(var_list)\n",
    "        if getattr(self, '_built', False):\n",
    "            return\n",
    "        self.momentums = []\n",
    "        for var in var_list:\n",
    "            self.momentums.append(\n",
    "                self.add_variable_from_reference(\n",
    "                    model_variable=var, variable_name='m'\n",
    "                )\n",
    "            )\n",
    "        self._built = True\n",
    "\n",
    "    def update_step(self, gradient: tf.Tensor, variable: tf.Variable) -> None:\n",
    "        lr = tf.cast(self.learning_rate, variable.dtype)\n",
    "        m = None\n",
    "        var_key = self._var_key(variable)\n",
    "        momentum = tf.cast(self.momentum, variable.dtype)\n",
    "        m = self.momentums[self._index_dict[var_key]]\n",
    "        if m is None:\n",
    "            variable.assign_add(-gradient * lr)\n",
    "        else:\n",
    "            m.assign(-gradient * lr + m * momentum)\n",
    "            variable.assign_add(m)\n",
    "\n",
    "    def get_config(self) -> dict[str, Any]:\n",
    "        base_config = super().get_config()\n",
    "        print('Config!')\n",
    "        return {\n",
    "            **base_config,\n",
    "            'learning_rate': self._serialize_hyperparameter(\n",
    "                self._learning_rate\n",
    "            ),\n",
    "            'momentum': self.momentum,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 0s 660us/step - loss: 1.1844\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 625us/step - loss: 0.5635\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 609us/step - loss: 0.9703\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 627us/step - loss: 0.5678\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 640us/step - loss: 0.6350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19c821210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = MyMomentumOptimizer()\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(1, input_shape=[8])])\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "model.fit(X_train_scaled, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. to 12.\n",
    "1. How would we describe TensorFlow in a short sentence? What are its main features? Can we name other popular deep learning libraries? \n",
    "> TensorFlow is an open-source library for numerical computation, particularly well suited and fine-tuned for large-scale machine learning. Its core is similar to NumPy, but it also features GPU support, support for distributed computing, computation graph analysis and optimization capabilities (with a portable graph format that allows us to train a TensorFlow model in one environment and run it in another), an optimization API based on reverse-mode autodiff, and several powerful APIs such as Keras, tf.data, tf.image, tf.signal, and more. Other popular Deep Learning libraries include PyTorch, JAX, MXNet, Microsoft Cognitive Toolkit, Theano, Caffe2, and Chainer.\n",
    "2. Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two? \n",
    "> Although TensorFlow offers most of the functionalities provided by NumPy, it is not a drop-in replacement, for a few reasons. First, the names of the functions are not always the same (e.g., `tf.reduce_sum()` versus `np.sum()`). Second, some functions do not behave in exactly the same way (e.g., `tf.transpose()` creates a transposed copy of a tensor, while NumPy’s `T` attribute creates a transposed view, without actually copying any data). Lastly, NumPy arrays are mutable, while TensorFlow tensors are not (but we can use a `tf.Variable` if we need a mutable object).\n",
    "3. Do we get the same result with `tf.range(10)` and `tf.constant(np.arange(10))`?\n",
    "> Both `tf.range(10)` and `tf.constant(np.arange(10))` return a one-dimensional tensor containing the integers 0 to 9. However, the former uses 32-bit integers while the latter uses 64-bit integers. Indeed, TensorFlow defaults to 32 bits, while NumPy defaults to 64 bits.\n",
    "4. Can we name six other data structures available in TensorFlow, beyond regular tensors?\n",
    "> Beyond regular tensors, TensorFlow offers several other data structures, including sparse tensors, tensor arrays, ragged tensors, queues, string tensors, and sets. The last two are actually represented as regular tensors, but TensorFlow provides special functions to manipulate them (in `tf.strings` and `tf.sets`).\n",
    "5. We can define a custom loss function by writing a function or by subclassing the `keras.losses.Loss` class. When would we use each option?\n",
    "> When we want to define a custom loss function, in general we can just implement it as a regular Python function. However, if our custom loss function must support some hyperparameters (or any other state), then we should subclass the `keras.losses.Loss` class and implement the `__init__()` and `call()` methods. If we want the loss function’s hyperparameters to be saved along with the model, then we must also implement the `get_config()` method.\n",
    "6. Similarly, we can define a custom metric in a function or as a subclass of `keras.metrics.Metric`. When would we use each option?\n",
    "> Much like custom loss functions, most metrics can be defined as regular Python functions. But if we want our custom metric to support some hyperparameters (or any other state), then we should subclass the `keras.metrics.Metric` class. Moreover, if computing the metric over a whole epoch is not equivalent to computing the mean metric over all batches in that epoch (e.g., as for the precision and recall metrics), then we should subclass the `keras.metrics.Metric` class and implement the `__init__()`, `update_state()`, and `result()` methods to keep track of a running metric during each epoch. We should also implement the `reset_states()` method unless all it needs to do is reset all variables to 0.0. If we want the state to be saved along with the model, then we should implement the `get_config()` method as well.\n",
    "7. When should we create a custom layer versus a custom model?\n",
    "> We should distinguish the internal components of our model (i.e., layers or reusable blocks of layers) from the model itself (i.e., the object we will train). The former should subclass the `keras.layers.Layer` class, while the latter should subclass the `keras.models.Model` class.\n",
    "8. What are some use cases that require writing our own custom training loop?\n",
    "> Writing our own custom training loop is fairly advanced, so we should only do it if we really need to. Keras provides several tools to customize training without having to write a custom training loop: callbacks, custom regularizers, custom constraints, custom losses, and so on. We should use these instead of writing a custom training loop whenever possible: writing a custom training loop is more error-prone, and it will be harder to reuse the custom code we write. However, in some cases writing a custom training loop is necessary. e.g. if we want to use different optimizers for different parts of our neural network, like in the [Wide & Deep paper](https://homl.info/widedeep). A custom training loop can also be useful when debugging, or when trying to understand exactly how training works.\n",
    "9. Can custom Keras components contain arbitrary Python code, or must they be convertible to TF functions?\n",
    "> Custom Keras components should be convertible to TF Functions, which means they should stick to TF operations as much as possible and respect all the rules listed in [TF Function Rules](#tf-function-rules) section. If we absolutely need to include arbitrary Python code in a custom component, we can either wrap it in a `tf.py_function()` operation (but this will reduce performance and limit our model’s portability) or set `dynamic=True` when creating the custom layer or model (or set `run_eagerly=True` when calling the model’s `compile()` method).\n",
    "10. What are the main rules to respect if we want a function to be convertible to a TF function?\n",
    "> Please refer to [TF Function Rules](#tf-function-rules) section.\n",
    "11. When would we need to create a dynamic Keras model? How do we do that? Why not make all our models dynamic?\n",
    "> Creating a dynamic Keras model can be useful for debugging, as it will not compile any custom component to a TF Function, and we can use any Python debugger to debug our code. It can also be useful if we want to include arbitrary Python code in our model (or in our training code), including calls to external libraries. To make a model dynamic, we must set `dynamic=True` when creating it. Alternatively, we can set `run_eagerly=True` when calling the model’s `compile()` method. Making a model dynamic prevents Keras from using any of TensorFlow’s graph features, so it will slow down training and inference, and we will not have the possibility to export the computation graph, which will limit our model’s portability.\n",
    "12. Implement a custom layer that performs *layer normalization* (We will use this type of layer in Chapter 15):\n",
    "- **a.** The `build()` method should define two trainable weights $\\boldsymbol{\\alpha}$ and $\\boldsymbol{\\beta}$, both of shape `input_shape[-1:]` and data type `tf.float32`. $\\boldsymbol{\\alpha}$ should be initialized with 1s, and $\\boldsymbol{\\beta}$ with 0s.\n",
    "- **b.** The `call()` method should compute the mean $\\mu$ and standard deviation $\\sigma$ of each instance’s features. For this, we can use `tf.nn.moments(inputs, axes=-1, keepdims=True)`, which returns the mean $\\mu$ and the variance $\\sigma^2$ of all instances (compute the square root of the variance to get the standard deviation). Then the function should compute and return $\\boldsymbol{\\alpha}\\otimes(\\mathbf{X}-\\mu)/(\\sigma+\\varepsilon)+\\mathbf{β}$, where $\\varepsilon$ is a smoothing term (small constant to avoid division by zero, e.g., 0.001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNormalization(keras.layers.Layer):\n",
    "    def __init__(self, eps: float = 0.001, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "\n",
    "    def build(self, batch_input_shape: tf.TensorShape) -> None:\n",
    "        self.alpha = self.add_weight(\n",
    "            name='alpha',\n",
    "            shape=batch_input_shape[-1:],\n",
    "            initializer='ones',\n",
    "        )\n",
    "        self.beta = self.add_weight(\n",
    "            name='beta',\n",
    "            shape=batch_input_shape[-1:],\n",
    "            initializer='zeros',\n",
    "        )\n",
    "\n",
    "    def call(self, X: tf.Tensor) -> tf.Tensor:\n",
    "        mean, variance = tf.nn.moments(X, axes=-1, keepdims=True)\n",
    "        std = tf.sqrt(variance + self.eps)\n",
    "        return self.alpha * (X - mean) / std + self.beta\n",
    "\n",
    "    def get_config(self) -> dict[str, Any]:\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'eps': self.eps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: it’s preferable to compute `tf.sqrt(variance + self.eps)` rather than `tf.sqrt(variance) + self.eps`. Indeed, the derivative of $\\sqrt{z}$ is undefined when $z=0$, so training will bomb whenever the variance vector has at least one component equal to 0. Adding $\\varepsilon$ within the square root guarantees that this will never happen.\n",
    "\n",
    "- **c.** Ensure that our custom layer produces the same (or very nearly the same) output as the `keras.layers.LayerNormalization` layer.\n",
    "> Let’s create one instance of each class, apply them to some data (e.g., the training set), and ensure that the difference is negligeable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=5.6045884e-08>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X_train.astype(np.float32)\n",
    "\n",
    "custom_layer_norm = LayerNormalization()\n",
    "keras_layer_norm = keras.layers.LayerNormalization()\n",
    "\n",
    "tf.reduce_mean(\n",
    "    keras.losses.mean_absolute_error(keras_layer_norm(X), custom_layer_norm(X))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Yep, that’s close enough. To be extra sure, let’s make $\\boldsymbol{\\alpha}$ and $\\boldsymbol{\\beta}$ completely random and compare again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.2921004e-08>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_alpha = np.random.rand(X.shape[-1])\n",
    "random_beta = np.random.rand(X.shape[-1])\n",
    "\n",
    "custom_layer_norm.set_weights([random_alpha, random_beta])\n",
    "keras_layer_norm.set_weights([random_alpha, random_beta])\n",
    "\n",
    "tf.reduce_mean(\n",
    "    keras.losses.mean_absolute_error(keras_layer_norm(X), custom_layer_norm(X))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Still a negligeable difference! Our custom layer works fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. \n",
    "Train a model using a custom training loop to tackle the Fashion MNIST dataset.\n",
    "- **a.** Display the epoch, iteration, mean training loss, and mean accuracy over each epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    (X_train_full, y_train_full),\n",
    "    (X_test, y_test),\n",
    ") = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full.astype(np.float32) / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901e5649b50840538874aed5bab0d4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f29690a5ade4bd8a6d164d106ba2d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ea6579132c48c087c7f59e6309387a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fa1527062c4cf7a277a548bbddc855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcfc9a0c4b64151a18cf27080872dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3831d9b98e488c837ba9644bf4b94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with trange(1, n_epochs + 1, desc='All epochs') as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=f'Epoch {epoch}/{n_epochs}') as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape() as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(\n",
    "                    zip(gradients, model.trainable_variables)\n",
    "                )\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))\n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status['loss'] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status['val_loss'] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status['val_accuracy'] = np.mean(\n",
    "                keras.metrics.sparse_categorical_accuracy(\n",
    "                    tf.constant(y_valid, dtype=np.float32), y_pred\n",
    "                )\n",
    "            )\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **b.** Try using a different optimizer with a different learning rate for the upper layers and the lower layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_layers = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Flatten(input_shape=[28, 28]),\n",
    "        keras.layers.Dense(100, activation='relu'),\n",
    "    ]\n",
    ")\n",
    "upper_layers = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Dense(10, activation='softmax'),\n",
    "    ]\n",
    ")\n",
    "model = keras.Sequential([lower_layers, upper_layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_optimizer = keras.optimizers.SGD(learning_rate=1e-4)\n",
    "upper_optimizer = keras.optimizers.Nadam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "mean_loss = keras.metrics.Mean()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e81cf85cf7548748ec760afcbd71aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "All epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475109b927d044a7bba030f234c67838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0a22afae4f47359f8fdfbac96e38bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5519ec96e42f4281987a84a5434a0734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed04f31b3a7d4b3b9a0cd63b644e2ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc4b1b4d40f4003ab8a3140a68ec883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/5:   0%|          | 0/1718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with trange(1, n_epochs + 1, desc='All epochs') as epochs:\n",
    "    for epoch in epochs:\n",
    "        with trange(1, n_steps + 1, desc=f'Epoch {epoch}/{n_epochs}') as steps:\n",
    "            for step in steps:\n",
    "                X_batch, y_batch = random_batch(X_train, y_train)\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    y_pred = model(X_batch)\n",
    "                    main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "                    loss = tf.add_n([main_loss] + model.losses)\n",
    "                for layers, optimizer in (\n",
    "                    (lower_layers, lower_optimizer),\n",
    "                    (upper_layers, upper_optimizer),\n",
    "                ):\n",
    "                    gradients = tape.gradient(loss, layers.trainable_variables)\n",
    "                    optimizer.apply_gradients(\n",
    "                        zip(gradients, layers.trainable_variables)\n",
    "                    )\n",
    "                del tape\n",
    "                for variable in model.variables:\n",
    "                    if variable.constraint is not None:\n",
    "                        variable.assign(variable.constraint(variable))\n",
    "                status = OrderedDict()\n",
    "                mean_loss(loss)\n",
    "                status['loss'] = mean_loss.result().numpy()\n",
    "                for metric in metrics:\n",
    "                    metric(y_batch, y_pred)\n",
    "                    status[metric.name] = metric.result().numpy()\n",
    "                steps.set_postfix(status)\n",
    "            y_pred = model(X_valid)\n",
    "            status['val_loss'] = np.mean(loss_fn(y_valid, y_pred))\n",
    "            status['val_accuracy'] = np.mean(\n",
    "                keras.metrics.sparse_categorical_accuracy(\n",
    "                    tf.constant(y_valid, dtype=np.float32), y_pred\n",
    "                )\n",
    "            )\n",
    "            steps.set_postfix(status)\n",
    "        for metric in [mean_loss] + metrics:\n",
    "            metric.reset_states()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
